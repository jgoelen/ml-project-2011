@relation text
@attribute docs string
@attribute class {work,no_work}

@data
'Memoing in hProlog Bart Demoen Bart Demoen Bart Demoen Memoing bestaat erin om een doel samen met zijn antwoorden teonthouden en later die antwoorden te hergebuiken wanneer hetzelfdedoel wordt geactiveerd. Memoing bestaat ook in Java: een Memoizerclass kan dat implementeren. Memoing komt uit de functionele wereld enwerd in Prolog geintroduceerd zowat 25 jaar geleden. Ondertussen staathet als tabling bekent en is onmisbaar in heel wat applicaties. Voortabling in de Prolog context zijn drie componenten nodig: de triescomponent (die de producer-doelen met hun antwoord opslaat), descheduler (die producerende en consumerende doelen plant) en eencompletion component (die zo vroeg mogelijk producers en consumersafsluit). Onlangs is de tries component van Yap naar hProlog gedragen(hProlog is een eigen systeem dat we voor diverse implementatieexperimenten gebruiken sinds een tiental jaren): die tries zijn nuttigop zichzelf ook zonder tabling. De volgende logische stap is de anderetwee componenten van tabling te implementeren. Dat gebeurthoofdzakelijk in C. De design en implementatie van memoing in hProlog, met evaluatie. Het werk bestaat uit - literatuurstudie over tabling in Prolog - design van een implementatie van de scheduler en completion binnen  hProlog - implementatie van die modules - uitgebreide evaluatie van het systeem Voorkennis: Prolog, C of een C-verwante taal Programmeren zal in C en Prolog gebeuren.   Tabulation Techniques for Recursive Programs, Richard S. Bird, ACM Computing Surveys. 12(4) 1980  http://en.wikipedia.org/wiki/Memoization  http://www.cs.sunysb.edu/~warren/xsbbook/node14.html',no_work
'Multi-core programmeren in Prolog. Bart Demoen Bart Demoen Bart Demoen Een recente rij workshops over "Declarative Aspects of MulticoreProgramming" (DAMP) sluit aan bij de huidige trend om in een processormeerdere cores te steken die dan ook "aan de praat" moeten gehoudenworden: declaratieve methoden zijn daarvoor heel geschikt. Inacademiejaar 2010-2011 is in het kader van een bachelorproef eenimplementatie gemaakt van threading in hProlog (een Prolog systeemontwikkeld door de promotor). Tezamen levert dat genoeg stof voormeerdere interessante onderwerpen voor een masterproef: hetontwikkelen van een methode voor het schrijven van multicore Prologprogrammas; de transformatie van single core naar multicoreprogrammas, gebaseerd op declaraties of analyse; de optimalisatie vande thread-implementatie zelf; een vergelijking met wat andereprogrammeertalen aanbieden; het uitwerken van nieuwe applicaties... het is een domein waarin we veel interessante kanten op kunnen. Het uitwerken van ondersteuning van multi-code programmeren in Prolog m.b.v. een methodologie en programmatransformaties. Het werk bestaat uit - literatuurstudie over wat al bestaat, in het bijzonder de papers van  de afgelopen DAMP workshops, en implementaties van threading  libraries hProlog, en bijvoorbeeld SWI Prolog, XSB/Yap en B-Prolog,  en andere declaratieve talen zoals Erlang of Haskell - een verzameling van test programmas (benchmarks, show cases ...)  bestuderen en daaruit besluiten trekken voor een methodologie - programmatransformaties bedenken, al dan niet gebaseerd op declaraties - evaluatie  Programmeren is niet het hoofddoel van deze masterproef, maar als hetgebeurt is dat vooral in Prolog, en in C. Voorkennis: Prolog, noties van threads, kennis van C is niet essentieel. http://en.wikipedia.org/wiki/Multi-core_processor www.intel.com/intelpress/samples/mcp_samplech01.pdf http://damp2011.cs.uchicago.edu/',no_work
'Een garbage collector voor GNU-Prolog Bart Demoen Bart Demoen Bart Demoen GNU-Prolog is een van de meest gebruikte Prolog systemen en zoals zijnnaam aangeeft is het open-source. Sterke punten aan GNU-Prolog zijn o.a.(1) het genereert zeer compacte binaries en is dus geen emulator zoalsandere systemen (2) het heeft zeer efficiente constraint solvers (3)het is volledig conform aan de ISO standaard. Er zijn twee zwakkepunten aan GNU-Prolog: het heeft geen modulesysteem, en zijngeheugenbeheer is rudimentair. Aan dat laatste willen we iets doen inhet kader van deze masterproef, in het bijzonder willen we een garbagecollector voor GNU-Prolog ontwikkelen voor de runtime datastructuren(de Prologtermen) die op de heap staan. In de loop der jaren hebben weheel wat ervaring met het bouwen van garbage collectors voor Prologsystemen gekregen: Prolog-by-BIM, BinProlog, XSB, hProlog ... Weverwachten dat dit dus goed afloopt. Het werk bestaat uit - inwerken in de principes en algoritmen voor garbage collection (boek  van Lins-Jones) - inwerken in het compilatie- en uitvoeringsschema van GNU-Prolog (diverse  artikels van Diaz-Codognet) - Prolog-specifieke gc vereisten begrijpen (artikels van Bruynooghe/Demoen/Carlsson) - de root-set van een lopend GNU-Prolog volledig beschrijven (in  overleg met de auteurs van GNU-Prolog) - een gc algoritme kiezen (in overleg met de auteurs van GNU-Prolog) - de implementatie ervan - een evaluatie op een benchmarkset De GNU-Prolog implementatie wordt nog dagelijks verder ontwikkeld (inParijs door D. Diaz); het is dus belangrijk dat een duidelijkeinterface met de garbage collector gemaakt wordt. Een goed resultaat zal als artikel ingediend worden in een workshop ofconferentie, en leidt bijna zeker tot publicatie. Het ontwerp en de implementatie van een garbage collector voor GNU-Prolog, en de evaluatie van die implementatie.  - inwerken in de principes en algoritmen voor garbage collection (boek  van Lins-Jones) - inwerken in het compilatie- en uitvoeringsschema van GNU-Prolog (diverse  artikels van Diaz-Codognet) - Prolog-specifieke gc vereisten begrijpen (artikels van Bruynooghe/Demoen/Carlsson) - de root-set van een lopend GNU-Prolog volledig beschrijven (in  overleg met de auteurs van GNU-Prolog) - een gc algoritme kiezen (in overleg met de auteurs van GNU-Prolog) - de implementatie ervan - een evaluatie op een benchmarkset Liefst studenten die willen werken aan een open-source project encontact met de makers van GNU-Prolog verwelkomen.  Garbage Collection: Algorithms for Automatic Dynamic Memory Management; Richard JonesRafael D. Lins http://arxiv.org/abs/1012.2496 user.it.uu.se/~kostis/Papers/padl02.ps.gz',no_work
'Heuristieken en polynome reducties. Bart Demoen Bart Demoen Bart Demoen Vermits we er nog niet in slagen om NP-complete problemen in polynometijd op te lossen, zijn er heel wat heuristieken bedacht die voor eenspecifiek probleem toch dikwijls snel tot een oplossing komen (almoeten we altijd rekening houden met de no-free-lunch stelling vanWolpert en Macready). Nu kan elk NP-compleet probleem L1 polynoomgereduceerd worden naar elk (ander) NP-compleet probleem L2, en dankan je een heuristiek voor L2 combineren via die polynome reductie toteen heuristiek voor L1. Daarbij is er geen garantie dat die heuristiekvoor L1 zich goed gedraagt. Dat willen we juist onderzoeken in dezemasterproef. Eerst moet het probleem in algemene termen exactbeschreven worden. Daarna kan een specifiek probleem L1 en L2 gekozenworden (bijvoorbeeld Hamiltoniaanse Kring en SAT) om meer inzicht tekrijgen in de verbanden tussen de heuristieken voor die twee problemen. Het werk bestaat uit - literatuurstudie ivm heuristieken en polynome reducties - algemene formulering van het probleem - uitwerken van een concreet voorbeeld - besluiten ivm het concreet voorbeeld en eventuele veralgemening Het concrete voorbeeld geeft bijna zeker aanleiding tot programmeerwerk. De studie van het verband tussen heuristiek, specifiek probleem, polynome reductie en subset van problemen waarvoor een heuristiek werkt.  Het werk bestaat uit - literatuurstudie ivm heuristieken en polynome reducties - algemene formulering van het probleem - uitwerken van een concreet voorbeeld - besluiten ivm het concreet voorbeeld en eventuele veralgemening Het concrete voorbeeld geeft bijna zeker aanleiding tot programmeerwerk. Een of twee studenten met interesse voor theorie; veel voorkennis vanpolynome reducties of heuristieken is niet nodig; programmeren zalgebeuren in C of een declaratieve taal (Prolog/Haskell ...). De paper van Wolpert+Macready: http://ic.arc.nasa.gov/people/dhw/papers/78.pdf iets over polynome reducties: http://en.wikipedia.org/wiki/Polynomial_reducibility',no_work
'Model Checking Type Systems Dave Clarke Ilya Sergey Dave Clarke Dave Clarke Type systems are used to enforce a range of properties of programs, from simple type safety to the absence of data races in multi-threaded code. Programmers, compilers, run-time systems and other tools rely on type systems doing what they claim to do. If the type system is faulty, then extremely difficult to track down errors appear, leading to security holes and costly bug hunting. Small-sized type systems (such as those appearing in research papers) are often proven sound, but type systems for full-scale programming languages rarely undergo such scrutiny. Lightweight techniques are required to assist a type system designer to remove bugs from the type system in order to give more confidence in its correctness in the absence of a mechanically verified soundness proof. The goal of this project is to develop model checking techniques and a supporting tool for debugging type system specifications. The following results are expected:1. Techniques for translating a programming language s type system and operational semantics into input suitable for a model checking tool2. A tool to automate this process.3. An evaluation of the developed techniques using a number of case studies, in particular to determine the limitations of the approach. A good understanding and interest in the more theoretical aspects of computer science, such as automata theory and logic. Interest in programming languages, especially type systems. Willingness to learn a functional language (Haskell, OCaml or Scala). Daily supervision will be in English    Efficient Software Model Checking of Soundness of Type Systems   Type systems   Model checking',no_work
'Oplossen van grootschalige niet-lineaire eigenwaardenproblemen door middel van operaties op functies Wim Michiels Elias Jarlebring Wim Michiels Elias Jarlebring  De nood aan nauwkeurige wiskundige modellen heeft het onderzoek rond eigenwaardenproblemen gestuurd in de richting van zeer grote matrices enerzijds en niet-lineaire problemen anderzijds. Die niet-lineariteit verschijnt bijvoorbeeld in modellen voor systemen met tijdsvertragingen en systemen beschreven door differentiaalvergelijkingen van een hoge orde, die relevant zijn in heel wat toepassingen.   Recent onderzoek heeft aangetoond dat een willekeurig niet-lineair eigenwaardenprobleem geherformuleerd kan worden als een oneindig-dimensionaal lineair eigenwaardenprobleem. Het is oneindig-dimensionaal in de zin dat de eigenvector vervangen wordt door een continue functie, de zgn. eigenfunctie, en een operatie van een matrix op een vector door het integreren van een functie.   De zogenaamde Arnoldi methode is zeer populaire methode voor het oplossen van grootschalige lineaire eigenwaardenproblemen, gerelateerd aan de methode van de machten. Omdat de Arnoldi methode gebaseerd is op operaties op vectoren en het matrix-vector product, kan ze conceptueel uitgebreid worden naar oneindig-dimensionale eigenwaardenproblemen (geassocieerd met het niet-lineaire eigenwaardenprobleem), waarbij de operaties op vectoren vertaald worden naar bewerkingen op functies.  Het nieuwe Matlab pakket chebfun (Univ. Oxford) bevat numerieke (niet symbolische) software voor het manipuleren van functies met zeer hoge precisie. Het doel van de thesis is om de Arnoldi methode uit te werken en te implementeren voor oneindig-dimensionale lineaire eigenwaardenprobleem, daarbij steunend op het pakket chebfun. Dit opent perspectieven om grootschalige en niet-lineaire eigenwaardenproblemen zeer efficient en nauwkeurig op te lossen, en in een algemeen raamwerk. Bij het eindwerk komen eveneens heel wat wiskundige aspecten kijken, zoals het gebruik van verschillende scalaire producten en herstarten. Experimenten op verschillende types eigenwaardenproblemen zullen verder inzicht leveren in de werking van de methode.     literatuurstudie: de Arnoldi methode en niet-lineaire eigenwaardenproblemen   uitwerken van de methode en implementatie met behulp van chebfun   experimenten op toepassingen uit systemen en controle     Zowel theoretische als implementatie-aspecten. Software in MATLAB.  Voorkennis: basis lineaire algebra. Het kan nuttig zijn om in het 2de masterjaar het vak "Numerieke lineaire algebra" te volgen.    Het pakket chebfun .  Enkele artikels.',no_work
'Snelle methodes voor het oplossen van afstandsproblemen in de lineaire algebra Wim Michiels Wim Michiels Karl Meerbergen Jeroen DeVlieger Wim Michiels Afstandsproblemen zijn zeer belangrijk in de numerieke lineaire algebra en hebben zeer veel toepassingen in ingenieursdisciplines.  Modellen voor dynamische systemen worden immers vaak gekenmerkt door onzekerheid op parameters. Het is dan bijvoorbeeld belangrijk om na te gaan hoe groot de onzekerheid maximaal mag zijn zonder dat het systeem onstabiel wordt. Deze stabiliteitseis kan vertaald worden in een gewenste positie van eigenwaarden.  De bestaande methodes voor het oplossen van afstandsproblemen zijn bijzonder rekenintensief. Recent is een iteratieve methode voorgesteld die veelbelovend is om afstandsproblemen op een veel efficientere manier dan met de bestaande technieken op te lossen. Ze is gebaseerd op het herhaaldelijk berekenen van geselecteerde eigenwaarden van matrices. Het doel van de thesis is om deze methode uit te werken, te implementeren en te vergelijken met bestaande methodes. Daarbij kunnen zowel lineaire als niet-lineaire eigenwaardenproblemen (bijvoorbeeld veeltermeigenwaardenproblemen die voorkomen bij de analyse van trillingen) worden beschouwd.    literatuurstudie; experimenteren met software  uitwerken van de methode en implementatie   toepassing, benchmarking    Omvat zowel theoretische als implementatie-aspecten. Afhankelijk van de interesse van de student kan de nadruk naar een bepaalde richting verschoven worden.  Software in MATLAB.  Voorkennis: basis lineaire algebra.   Enkele artikels.',no_work
'Blocking Gibbs: het efficient combineren van logisch en probabilistisch redeneren Daan Fierens Nima Taghipour Hendrik Blockeel Daan Fierens Daan Fierens Nima Taghipour  Een van de grote uitdagingen binnen de artificiele intelligentie is het redeneren met zogenaamde  probabilistische logica s . In dit eindwerk maken we gebruik van  Markov Logic , wat eerste orde logica combineert met kansrekenen. Het redeneren ("inferentie") met Markov Logic heeft vele toepassingen in onder andere computer vision en analyse van sociale netwerken. Een van de voornaamste algoritmen voor inferentie met Markov Logic is het  MC-SAT  algoritme. MC-SAT maakt gebruik van zowel probabilistische technieken (sampling) als logische technieken (voor satisfiability of SAT solving). In de DTAI onderzoeksgroep zijn recent ideeen ontwikkeld voor een alternatief algoritme, gebaseerd op MC-SAT en het principe van  blocking Gibbs  sampling. Het doel van dit eindwerk is om dit algoritme verder uit te werken, efficient te implementeren, en experimenteel te testen. De uitwerking van dit eindwerk bestaat uit drie onderdelen.   Je implementeert een basis-algoritme. De grote lijnen van dit algoritme zijn reeds in ons onderzoek vastgelegd; daardoor is dit onderdeel voornamelijk implementatie-gericht. We hechten hierbij belang aan een efficiente en goed ontworpen implementatie (in C++ of eventueel Java, ...).   Je onderzoekt of het algoritme kan verbeterd worden met bijvoorbeeld slimmere heuristieken. Dit onderdeel is iets meer onderzoeksgericht, al krijg je hierbij wel ideeen aangereikt door je begeleiders.  Je voert experimenten uit waarin je de efficientie en nauwkeurigheid van je algoritme evalueert en vergelijkt met het bestaande MC-SAT algoritme. Datasets die hiervoor typisch gebruikt worden, hebben betrekking op collectieve classificatie van webpagina s en entiteitsresolutie in gegevensbanken (zie het  MC-SAT artikel ).   Je hebt interesse in artificiele intelligentie. Je bent goed in het efficient en overzichtelijk implementeren van algoritmen. Het MC-SAT artikel ( http://www.cs.washington.edu/homes/pedrod/papers/aaai06a.pdf , en de referenties daarin) biedt een goede introductie tot het onderzoeksgebied van probabilistisch-logische inferentie.',no_work
'Efficienter redeneren met probabilistische Prolog programma s Daan Fierens Maurice Bruynooghe Daan Fierens Daan Fierens Stef DePooter  ProbLog  is een probabilistische uitbreiding van logic programming of "pure Prolog". ProbLog heeft allerlei toepassingen binnen de artificiele intelligentie, zoals analyse van sociale netwerken, classificatie van webpagina s, .... Een ProbLog programma is een logisch programma plus een aantal "probabilistische feiten" (feiten die slechts met een bepaalde kans waar zijn). Het redeneren met een ProbLog programma, en de kansverdeling die het beschrijft, noemt men probabilistische inferentie. Gegeven een bepaalde inferentie-taak is de eerste stap vaak het  grounden  van het ProbLog programma. Omwille van efficientie-redenen zoekt men het kleinst mogelijke ground ProbLog programma dat toch nog alle informatie bevat die nodig is om de gegeven inferentie-taak op te lossen. De huidige "grounder" is echter heel eenvoudig en vindt een groter programma, wat tot tragere inferentie leidt. Je ontwikkelt en implementeert een geoptimaliseerde grounder voor ProbLog en test je grounder experimenteel uit. Er zijn twee strategieen om het ground programma zo klein mogelijk te maken. De bedoeling van het eindwerk is dat je beide strategieen bekijkt, aangezien ze complementair zijn.  De eerste strategie is om kennis van de waarheidswaarde van sommige atomen zoveel mogelijk uit te buiten door deze kennis te propageren doorheen het programma (dit kan toelaten bepaalde clauses/regels te schrappen of te verkorten en dus het programma kleiner te maken). Je kan hiervoor uitgaan van bestaande code van  GidL , de grounder voor de logische taal  FO(.) .  Het  eerste deel  van dit eindwerk bestaat uit het combineren van de GidL code met het ProbLog systeem, en het uitbreiden hiervan waar nodig (bijvoorbeeld aanpassen aan de probabilistische context). De tweede strategie is om het programma te beperken tot die regels die relevant zijn voor de gegeven inferentie-taak (de gegeven queries). Momenteel gebruiken we in ProbLog een eerder naieve methode hiervoor. Het  tweede deel  van de thesis bestaat dan ook uit het verder uitwerken en implementeren hiervan. Inspiratie hiervoor kan gehaald worden uit onder andere het  BayesBall  algoritme voor Bayesiaanse netwerken.    Het  derde deel  van het eindwerk bestaat uit het uitvoeren van experimenten met je grounder, om de efficientie te evalueren. Typische datasets voor zulke experimenten hebben betrekking op sociale netwerken, classificatie van webpagina s, ... . Je hebt interesse in logisch programmeren. Je hebt een basiskennis van Prolog en C++, of bent bereid dit te leren. Informatie over ProbLog vind je op de ProbLog website,  http://dtai.cs.kuleuven.be/problog/ .',no_work
'Snel en efficient een voxelrepresentatie genereren van een textielmodel Bart Verleye Dirk Roose stepan.lomov+mtm.kuleuven.be Dirk Roose stepan.lomov+mtm.kuleuven.be Bart Verleye Bart Verleye De permeabiliteit van textiel is een belangrijke parameter voor het simuleren van vloeistofinjectieprocessen. Deze processen worden gebruikt voor het aanmaken van composietmaterialen, toegepast in bijvoorbeeld snelle wagens en lichte vliegtuigen. De permeabiliteit van het textiel wordt berekend aan de hand van textielmodellen. Een vectorvoorstelling van het textiel is voorhanden voor mechanische (sterkte-)berekeningen. Maar om de permeabiliteit efficient te berekenen moet het vectormodel van het textiel omgezet worden in een voxelrepresentatie. Dit laatste betekent dat op een regelmatig 3D-rooster voor elke punt beslist moet worden of het al dan niet binnen een draad ligt. Voor fijne roosters leidt dit tot enorm veel rekentijd. Gegeven een vectormodel van een textiel, op een snelle manier tot een voxelrepresentatie komen.  1) Inzicht krijgen in het probleem, en in het huidige vectormodel. 2) Een nieuwe datastructuur ontwerpen, zodat de zoekopdracht veel efficienter kan gebeuren. 3) Samen met het vorige: ontwerp van een zoekalgoritme. 4) Implementatie van de datastructuur en zoekalgoritme in het huidige softwarepakket. Het softwarepakket werd reeds verkocht aan verschillende bedrijven en universiteiten. Dit is een zeer toegepaste thesis. C++;Niet nodig maar handig: Artificiele intelligentie, Graphics',no_work
'Een model voor gestructureerde sociale netwerken Jan Ramon Maurice Bruynooghe Jan Ramon Sociale netwerken zoals Facebook en citatienetwerken volgen vaak een zogenaamd "power-law" model, dat op een statistische manier beschrijft hoe deze netwerken evolueren.  Vaak zijn deze modellen echter enkel uitgewerkt voor ongerichte, ongelabelde grafen.   Deze thesis heeft tot doel om een meer verfijnd model op te stellen dat netwerken beschrijft met structuur, bv. netwerken met verschillende types knopen (voor facebook: gebeurtenissen, groepen, personen, ...) of knopen met eigenschappen (bv. geslacht, interesses, ...) De thesis bestaat uit volgende stappen:   Een beperkte literatuurstudie   Het uitwerken van een theoretisch model   Een implementatiefase waarin een algoritme ontworpen wordt om parameters en lokale structuur van dit model te leren   Toepassing van het algoritme op een aantal reele wereld domeinen zoals Facebook en DBLP.     Analyze van de resultaten, verbetering van model en algoritme, en bijkomende experimenten  Het onderwerp kan twee keer toegekend worden.  In dat geval zal een student zich focussen op de lokale structuur (bv. hoe hangt de kans dat X en Y vriend worden af van bestaande vriendschappen van X met vrienden van Y?), terwijl de andere student zich zal focussen op eigenschappen van knopen van het netwerk (bv. de invloed van interesses van een persoon op toekomstige activiteit). Interesse in data mining en statistische modellen.     Barabasi-Albert model    Random graphs with arbitrary degree sequences',no_work
'Strategische shuttle positionering voor een badminton spelende robot Wannes Meert Luc DeRaedt Wannes Meert kurt.driessens+maastrichtuniversity.nl Andrei.Bartic+fmtc.be Het Flanders  Mechatronics Technology Center ( FMTC ) focust zich op systemen die een synergistische combinatie zijn van verschillende ingenieursdisciplines zoals mechanica, controle theory, micro-elektronica en computerwetenschappen. Een van de beschikbare demonstratieopstellingen is Jada, een robot die badminton kan spelen. Op dit moment past Jada haar spelstrategie niet aan aan haar tegenstanders speelstijl, vaardigheid of locatie (momenteel is de robot zelfs onwetend over de positie van de tegenstander maar er zijn eventueel videobeelden beschikbaar). Het domain van machine learning focust zich op algoritmes die het gedrag van een machine aanpassen aan de huidige context en laat toe om een machine te laten leren uit fouten. Zulke algoritmes zijn goed geschikt om Jada uit te breiden om op een intelligentere manier badminton te spelen.     Het doel van deze thesis is tweevoudig, het eerste doel is om algoritmes te bestuderen om spelstrategien te leren voor badminton en deze te simularen in een off-line fase. Het tweede doel is om de beste strategien verder te ontwikkelen en te implementeren op de robot zelf. De student moet strategien om badminton te spelen onderzoeken, implementeren en vergelijken in een prototype. Het prototype mag gemaakt worden in een programmeertaal naar keuze. De uiteindelijke implementatie op de robot gebeurt in C/C++ (geen expertkennis vereist). Interesse in machine learning is belangrijk. Aangezien dit een praktische thesis is zijn goede programmeervaardigheden een voordeel.   YouTube: JADA, The first badminton robot  Introduction to Jada  ( English ) J. Stoev, A. Bartic, S. Gillijns, and W. Symens.  Badminton playing robot - a multidisciplinary test case in mechatronics . In Proceedings of the 5th IFAC Symposium on Mechatronic Systems, 2010.',no_work
'Verification of secrecy with a whitebox fuzzer Dave Clarke Dimiter Milushev Dave Clarke Dimiter Milushev Fuzzing is an effective technique, generally used for low-level security vulnerabilities discovery. It can be applied even if the source code is not available. However, when one has access to the source code, a more sophisticated version of the technique can be applied, namely white-box fuzzing. Such an approach typically starts by running the program with a well-formed input and gathers constraints on that input (characterizing the trace). By systematically varying combinations of these constraints, one produces a set of inputs that cover different control paths of the inspected program. As a result, higher execution-path coverage is achieved and the chance to find vulnerabilities increases. In principle, this technique gives the possibility to verify higher level security policies, such as information flow and the more realistic and interesting case of information flow in the presence of declassification. The goal of this project is to get a thorough understanding of the problem, including the theoretical foundations, to devise a sound conceptual solution and finally to check that it works in practice,by verifying nontrivial programs.  The following results are expected: 1. Get familiar with research results (techniques and software) concerning the problem.2. Explore the possibility to integrate all or some of the following dimensions of declassification: what, who, where and when. 3. Develop techniques for the feasible ones.4. Apply the techniques to realistic programs.     General interest in security and verification.  Specific interest in fuzzing, static analysis, symbolic execution.    Excellent working knowledge of C and optionally Perl.    Willingness to learn new concepts and tools.    Daily supervision will be in English    Grammar-based Whitebox Fuzzing    Principles of secure information flow analysis    Declassification: Dimensions and Principles',no_work
'An empirical workbench for Eclipse Riccardo Scandariato Wouter Joosen Riccardo Scandariato Riccardo Scandariato An empirical experiment often consists of a set of tasks (e.g., refactor some Java code or modify a UML diagram) that a number of subjects must carry out according to a given methodology (e.g., using a specific tool, technique, etc.).To analyze the results, information and measurements need to becollected during the experiment. For instance, it is important to measure the time spent by the subjects on each task.The collection and submission of these data should happen transparently for the experiment subjects. Implement a framework (integrated in Eclipse) to define and execute empirical experiments related to software engineering.The framework should be extensible, so that it can be usedfor various kinds of experiments. The thesis consists of the following parts:  Study the relevant literature on experimental software engineering (e.g., typical experiment designs)  Analyze existing tool support for experimental studies  Develop the framework Possible features to develop are:   A model to define the process that the subjects have to follow   A model to define the tasks that the subjects have to perform  Define variations in the process or tasks, based on the group of thesubject  A GUI, integrated in the IDE, to display the tasks to the subject  A GUI, integrated in the IDE, to assist the subject in executing the process  Automatic collection of information during an experiment run, e.g., the actions performed by the subject, intermediate results, the time spent by the subject on each task, the time spent by the subject on each phase on the process, the modifications made by the subject, the resources (files, editors, views, ...) that a subject uses  Support subjects that work in groups (and thus collaborate using different instances of the tool)  Utilities for processing the collected data (aggregating, filtering, exporting, etc.)  Proficiency in Java. Knowledge of the Eclipse architecture is a plus (but not required).  Hackystat',no_work
'Hoe je privacy-instellingen verenigen met de vereisten van andere stakeholders? Kim Wuyts Wouter Joosen Riccardo Scandariato Kim Wuyts Meer en meer data wordt gedigitalizeerd, daarom wordt toeganscontrole voor gedistribueerde systemen alsmaar belangrijker. Ook al bestaan er al een aantal gevestigde standaarden, zoals XACML die reeds gedetailleerde toegangscontrole ondersteunt, toch is de huidige tool-support voor het aanmaken van dergelijke regels beperkt.Een belangrijk nadeel dat gepaard gaat met deze digitalizering is het verlies van controle die de gebruikers hebben over hun eigen informatie. We zien dan ook een duidelijke verschuiving ontstaan die, weg van de gesloten toegangscontrole die volledig door de platform providers wordt bepaald, evolueert naar toegangscontrole waar de gebruiker centraal staat (bijvoorbeeld de gebruikersinstellingen in Facebook die uitgebreid worden, patient-empowerment in e-health, etc.).  Uiteraard zijn niet alle stakeholders te vinden voor deze ontwikkeling. In het geval van e-health zijn vele artsen terughoudend, aangezien zij verantwoordelijk zijn voor de informatie die ze zelf creeren. Ze willen dus de invloed die patienten hebben om de toegangsregels toch beperkt zien. In dit geval is het mogelijk om de artsen te laten bepalen in welke gevallen een patient de toegang tot zijn gegevens mag uitbreiden (bv. zijn eigen apotheker ook toegang geven tot zijn medicatie geschiedenis) en wanneer een patient de toegang mag beperken (bv.  een bepaalde aankoop van medicatie verbergen voor zijn buur die apotheker is). Dit sluit uit dat de patient onrealistische beperkingen oplegt die zijn gezondheid kunnen schaden (bv. verbergen van medicatie-geschiedenis bij een spoed-opname) of door te open regels zijn privacy in gedrang brengt (bv. medicatie-geschiedenis delen met een ver familielid of buur). Deze beperkingen zullen voorgedefinieerd zijn en moeten uiteraard meegedeeld worden aan de patient wanneer deze zijn persoonlijke toegangsregels opstelt.  Maak een toegangscontrole raamwerk dat zorgt voor eenvoudige creatie en ondersteuning van algemene (platform-specifieke) regels, gebruikersvoorkeuren en beperkingen op deze voorkeuren. Dit raamwerk moet kunnen gebruikt worden voor verschillende platformen in verschillende toepassingsdomeinen.    Literatuur studie  Vergelijking van de implementatiemogelijkheden voor gebruikersvoorkeuren en berperkingen hierop  Implementatie: ondersteuning voor algemene regels, gebruikersvoorkeuren en beperkingen op deze voorkeuren  	 Kennis van java. Interesse in security.  XACML version 3.0 working draft',no_work
'Predict vulnerabilities in mobile applications Riccardo Scandariato Wouter Joosen Riccardo Scandariato Riccardo Scandariato waldenj+nku.edu By the end of 2010, more smartphones were sold than personal computers.  The growing prevalence of these devices has produced an explosion in the number of mobile applications available, and mobile devices are becoming essential tools for people to bank, shop, and communicate.  However, most of these applications are developed outside of a secure software development lifecycle, and the security environment of mobile devices is immature compared with personal computers, leading to events such as Google s recent announcement of the removal of multiple malware applications from the Android app store.  To improve the security of mobile software, developers need tools to indicate which software components on which to focus their efforts to remove or prevent vulnerabilities. Identify security vulnerabilities in mobile applications and develop prediction models based on code features to predict which applications and application components are likely to contain vulnerabilities. The goal of the proposed research is to develop models to predict which software components and applications are likely to contain or evolve to contain security vulnerabilities.  To accomplish this goal, the research will need (1) to find a method to identify vulnerabilities in mobile applications (e.g., via static analysis or via vulnerability databases), (2) to select a pool of applications to be studied, (3) to analyze the source code of those applications in order to determine which code features are correlated with the presence of vulnerabilities, and (4) to develop a model based on those code features to predict the presence of vulnerabilities in other mobile applications.  The expected results of the research are a corpus of mobile application vulnerability data and a prediction model for mobile vulnerabilities. Proficiency in a scripting language (e.g., Ruby and Bash) James Walden, Maureen Doyle, Grant Welch, Michael Whelan, Security of Open Source Web Applications, International Workshop on Security Measurements and Metrics (MetriSec), October 2009',no_work
'Distributed synchronous coordination Jose Proenca Dave Clarke Dave Clarke Jose Proenca  Coordination languages describe when and where data can flow among the computational parts, which can be, for example, components or web-services. In this context, synchrony means that a coordinated entity cannot execute independently of the other coordinated entities.   This project focuses on the synchronous coordination language Reo. An existing concurrent implementation for Reo based on Erlang-like actors allows multiple threads to execute Reo connectors. However, the execution of these threads over multiple computers requires a non-trivial deployment process that has only been superficially tackled. Furthermore, failure is not considered in the current approach.   The goal of this project is to distribute several executing threads, cooperating using asynchronous message passing, that coordinate a collection of web-services and components. The student will develop tools to guide the deployment and reconfiguration of the coordination layer over a distributed network. The deployment should be optimised according to the behaviour of each concurrent block and to the network, and validated by measuring the performance of the tool.  The student will:    improve an existing concurrent implementation of Reo;     deploy threads over a network to coordinate the communication between web-services;     develop tools to automatise the deployment process;     develop tools to analyse the runtime execution of the coordination layer;     optimise the deployed components and the deployment plan.        Java programming experience     Basis of concurrent programming     Scala programming experience and Eclipse plug-in development are a plus     The supervision will be in English        Coordination model Reo      Reo: a channel-based coordination model for component composition , by Farhad Arbab    Synchronous coordination of distributed components , by Proen?a    Scala Actors: Unifying thread-based and event-based programming , by Haller and Odersky    Programming in Scala    Eclipse plug-in development website     Eclipse plug-in tutorial',no_work
'Constraint-based synchronous coordination  Jose Proenca Dave Clarke Dave Clarke Jose Proenca Dave Clarke   Coordination languages describe when and where data can flow among the computational parts, which can be, for example, components or web-services. In this context, synchrony means that a coordinated entity cannot execute independently of the other coordinated entities.    This project focuses on the synchronous coordination language Reo. Current implementations of Reo do not use the value of the exchanged data tokens to route the data, unlike the original descriptions of Reo suggest.An existing approach to model coordination based boolean constraints presents an increased performance when executing a large class of connectors with respect to other approaches. However, aspects such as data and locality are not covered any constraint-based approach.  The goal of this project is to extend existing tools and techniques based on constraint satisfaction for coordination, using data-constraints and partial satisfaction of constraints.For that purpose, the student will study existing SMT and/or CSP solvers, and find how they can be used to implement synchronous coordination language based on constraints. He will also analyse how SMT and CSP solving are used in other domains of computer science.The constraint-solving process can be later optimised to the constraints that describe the coordination, which follow some common patterns.Further optimisations include the use of locality properties to reduce the size of the constraints being solved.An existing Eclipse plug-in can also be used to execute Reo connectors, and test the proposed methodology.     Learn the Reo language and its constraint-based approach.     Learn about SMT and CSP, and get familiarised with existing solvers.     Develop a tool that, given the constraints for coordination, finds a solution describing how and where data can flow.     Divise a logic and a solver that allows local constraint solving.         Basic knowledge of logic programming     Acquaintance with the constraint-satisfaction problem     The supervision will be in English        Coordination model Reo      Reo: a channel-based coordination model for component composition , by Farhad Arbab    Deconstructing Reo , by Clarke, Proen?a, Lazovik, and Arbab     Satisfiability Modulo Theories: An Appetizer , by Leonardo de Moura and Nikolaj Bj?rner    Solving SAT and SAT Modulo Theories , by Robert Nieuwenhuis and Albert Oliveras    Foundations of Constraint Satisfaction , by Edward Tsang     Coordination via Interaction Constraints I: Local Logic , by Clarke and Proen?a',no_work
'Opsporen van fouten in programma s voor smart cards Jan Smans Bart Jacobs Frank Piessens Bart Jacobs Frank Piessens Jan Smans  Vandaag de dag draagt iedereen een hele boel smartcards met zich mee: een digitale identiteitskaart, een bankkaart, een SIS-kaart, een studentenkaart, enz. De correcte en veilige werking van programma s die draaien op smartcards is van cruciaal belang omdat de kaart toegang geeft tot gevoelige informatie (zoals biometrische gegevens en je bankrekening) en omdat software updates moeilijk en kostelijk zijn nadat de smartcard is afgeleverd aan de gebruiker.   JavaCard is een technologie om smartcard applicaties te schrijven in (een subset van) Java.   VeriFast is een programma verificator voor Java en C. VeriFast neemt een Java-bestand geannoteerd met pre- en postcondities, lusinvarianten, etc als invoer en gaat na of het Java-programma vrij is van run-time-fouten (zoals ArrayOutOfBoundsExcepties) en of de condities beschreven in de annotaties (bijvoorbeeld bij iedere methode oproep gaat de tool na of de preconditie geldt) voldaan zijn.   Het doel van deze thesis is om een bestaande programma verificator, VeriFast, te evalueren en uit te breiden met het oog op verificatie (dwz aantonen van afwezigheid van onder andere "ArrayIndexOutOfBoundsException" of "ongeldige-array-index-fouten" en oneindige lussen) van JavaCard smart card applicaties.  De uitwerking van deze thesis omvat volgende stappen:   Studie van JavaCard. Na deze studie kan je zelf kleine JavaCard applicaties schrijven en bestaande applicaties begrijpen.  Studie van de VeriFast programma verificator. Deze studie bestaat uit het doornemen van de VeriFast tutorial. Deze tutorial wordt ook gebruikt in de lessen Capita Selecta Veilige Software en Capita Selecta Software Engineering.  Toepassen, uitbreiden en evalueren van VeriFast om de afwezigheid van fouten in kleine JavaCard applicaties aan te tonen.  Toepassen, uitbreiden en evalueren van VeriFast om de afwezigheid van fouten in een groot JavaCard programma aan te tonen. VeriFast bevat momenteel slechts specificaties voor een subset van de volledige JavaCard API. Je zal hierbij onder andere nieuwe specificaties (bijvoorbeeld methode contracten) moeten schrijven voor de JavaCard API.   /   Programma verificatie is een van  grand challenges  in computerwetenschappen. Algemene informatie over de uitdaging kan je hier terugvinden: http://qpq.csl.sri.com/vsr/private/ieee-computer-final.pdf  De  JavaCard website  bevat de JavaCard development kit en een hele boel documentatie en tutorials.  VeriFast is beschikbaar op de  VeriFast website',no_work
'Study the Use of Multiple Dispatch in Object-Oriented Programming Practice Radu Muschevici Dave Clarke Radu Muschevici Multiple dispatch or multimethods or function overloading is the featureof some object-oriented programming languages in which a function ormethod can be dynamically dispatched based on the run time (dynamic)type of more than one of its arguments. This is an extension of singledispatch polymorphism where a method call is dispatched based only onthe type of the object. Multiple dispatch generalises the dynamicdispatch to work with a combination of two or more objects.Mainstream languages such as Java and C',no_work
'An Eclipse plug-in for Variability Radu Muschevici Dave Clarke Jose Proenca Dave Clarke Radu Muschevici Jose Proenca Software product line engineering (SPLE) is a methodology aimed atdeveloping several software products simultaneously. These productstypically share a set of common functionality, but are also variable:some features can be present in some products and absent in others. TheAbstract Behavioural Specification (ABS) language is a newobject-oriented language that supports the SPLE methodology andvariability modelling.  Develop an Eclipse plug-in to support the variability modelling features of the ABS language. The goal is to extend the existing Eclipse plug-in for ABS to support a number of extensions that have been added to the language. Theseextensions add support for software product line engineering to ABS. The expected support includes syntax and error highlighting, and an outline view of the extensions. Other more advanced functionality based on analysis of the feature model is also desirable. Possible tasks include automatic validation of products with respect to a feature model, generation of run configurations based on the selection of products, verification of valid product line configurations, introduction of debugging information to the generated code to find runtime errors in the variability description, and the derivation of variability blocks based on changes to the code. The thesis plan includes:  learn plug-in development for the Eclipse platform (in Java) implement Eclipse plug-in for extended ABS models    Java programming experience Eclipse plugin development experience is a plus The supervision will be in English    Variability Modelling in the ABS Language  Variability Modelling for Model-Driven Development of Software Product Lines  Eclipse plug-in development website  Eclipse plug-in tutorial',no_work
'Visual Editor for Feature Models Radu Muschevici Jose Proenca Dave Clarke Dave Clarke Radu Muschevici Jose Proenca  Software product line engineering is a methodology aimed at developing several software products simultaneously. These products typically share a set of common functionality, but are also variable: some features can be present in some products and absent in others. Such variability is commonly modelled using feature models. These are often represented visually using feature diagrams.  The Abstract Behavioural Specification (ABS) language is a newobject-oriented language which supports Software product lineengineering. Variability is described in ABS by a textual representation of feature models.  Develop an Eclipse plug-in for editing and analysing feature diagrams The thesis will follow these steps:  Familiarise yourself with feature models and diagrams using relevant literature Learn about plugin development for the Eclipse platform (in Java) Implement Eclipse plugin for feature diagrams with attributes Implement analysis and transformation techniques for feature diagrams Implement feature model views    Java programming experience Eclipse plugin development experience is a plus The supervision will be in English    Variability Modelling in the ABS Language  FeatureIDE Project  Eclipse plug-in development website  Eclipse plug-in tutorial',no_work
'Delta Modelling Evaluation using ABS Language Radu Muschevici Dave Clarke Jose Proenca Dave Clarke Radu Muschevici Jose Proenca Delta Modelling is a programming approach to developing software productlines in which modifications to a program are encapsulated using deltas. Deltas can be seen as patches to a core program. Upon compilation, deltas are incrementally applied to the core program, thereby adding, removing or modifying its functionality. Delta modelling is supported in the ABS language, a modern object-oriented programming language currently under development. The goal is to evaluate delta modelling by using the ABS language toimplement a software product line. In doing this, you will identify design patterns and best practices related to delta-oriented programming; uncover code smells and anti-patterns; expose weaknesses and limitations, and propose improvements to the delta modelling approach. The thesis plan includes  implementing  a medium-sized software product line using deltas in ABS. Through  practical evaluation  of the delta-oriented language ABS, you will be able to contribute ideas and shape the features of this new programming language.   Interest in programming languages in general Interest in program design and writing "good" code  The supervision will be in English    Variability Modelling in the ABS Language  Variability Modelling for Model-Driven Development of Software Product Lines',no_work
'Parallelle algoritmen voor lineaire algebra uit het machinaal leren Karl Meerbergen Luc DeRaedt Karl Meerbergen Luc DeRaedt Jeroen DeVlieger Siegfried Nijssen In het kader van het ExaScience Lab (Intel Labs Europe) werken we algoritmen uit voor grootschalige problemen uit de lineaire algebra van allerlei toepassingen. De nadruk ligt hierbij op algoritmen voor toekomstige supercomputers. Voor dergelijke computers is het aantal processoren (of kernen) zeer groot (meer dan 100000). We wensen met deze masterproef een zicht te krijgen op technieken voor grootschalige matrixproblemen, die gebruikt worden in allerlei toepassingen van machinaal leren, waaronder eigenwaardenoptimalisatie, niet-negatieve matrixontbindingen of tensorontbindingen. Het doel van deze terreinverkennende masterproef is  enerzijds een literatuurstudie te maken rond het gebruik van grootschalige matrixproblemen in het machinaal leren, en  anderzijds voor een nader te bepalen probleem uit het machinaal leren een parallelle oplossing te ontwikkelen.   Op het departement is recent een algoritme ontwikkeld voor eigenwaardenoptimalisatie. Dit zijn eigenwaarden van grote ijle symmetrische matrices (orde 100000 of meer) waarvan de coefficienten afhangen van vele parameters. De student zal een parallel algoritme uitwerken van dit algoritme. Problemen uit machinaal leren zullen worden opgelost op de VIC3-cluster van de K.U.Leuven. De student kan zelf ook een ander voorstel formuleren na een literatuurstudie en in overleg met de promotoren. Dit is eerder een implementatie-opdracht. Het is aan te raden het OPO Parallelle algoritmen te volgen. Om goede parallelle algoritmen te ontwerpen, is soms fundamenteel werk nodig. Inzichten verwerven in numerieke lineaire algebra kan daarom belangrijk zijn, afhankelijk van de specifieke invulling van de masterproef.',no_work
'Een implementatie van automatische differentiatie via templates in C++ Karl Meerbergen Dirk Abbeloos Karl Meerbergen Dirk Abbeloos Dirk Nuyens Industriele processen worden vaak beschreven door een stelsel stijve, niet-lineaire differentiaalvergelijkingen. Voor het simuleren van een dergelijke systeem maken we dan ook gebruik van impliciete integratieformules zoals bijvoorbeeld  BDF methoden. Deze methoden vereisen echter  het oplossen van een stelsel niet-lineaire vergelijkingen in elke tijdsstap. Dit stelsel kan vaak efficient worden opgelost met een Newton-achtige methode, indien de nodige informatie over de afgeleiden beschikbaar is.  Voor het berekenen van deze afgeleiden gebruikt men vaak een van de volgende drie methoden: eindige differenties, het opgeven van expliciete formule of automatische differentiatie. De eerste methode is bijna altijd toepasbaar, maar is vaak onnauwkeurig, duur en potentieel onstabiel. De tweede vraagt veel werk van de gebruiker, is tevens gevoelig voor menselijke fouten en vraagt bij elk nieuw probleem een nieuwe afleiding. Aangezien de uitdrukkingen voor de afgeleiden echter wel beschikbaar zijn tijdens het compileren, kan de compiler deze optimaliseren, wat hopelijk resulteert in een zeer efficiente simulatiecode. Automatische differentiatie is zowel nauwkeurig als betrouwbaar. De efficientie van deze methode kan echter sterk varieren, afhankelijk van de gebruikte implementatie. Een object georienteerde implementatie zal bijvoorbeeld resulteren in een relatief trage code in vergelijking met de tweede methode, omwille van de overerving en het aanroepen van de bijhorende virtuele functies. Een implementatie gebaseerd op templates heeft dit nadeel niet en zou dus bijna even efficient moeten zijn als het manueel opgeven van de afgeleide informatie. De masterproef heeft als doel het implementeren van een automatische differentiatie-toolbox met behulp van templates in de programmeertaal C++. Templates bieden hier het voordeel dat alle extra berekeningen afkomstige van de automatische differentiatie, gekend zijn tijdens het compileren, waardoor de compiler deze ook zal optimaliseren alsof de gebruiker ze manueel had ingegeven. We wensen te experimenteren met het bovenstaande idee en staan dus open voor voorstellen van de student zelf. Natuurlijk is programmeren een van de hoofdcomponenten in deze masterproef. Als eindresultaat verwachten we een kleine toolbox waarin verschillende functionaliteiten zitten voor het integreren van niet-lineaire differentiaalvergelijkingen.  Interesse in het simuleren van differentiaalvergelijkingen en het programmeren met C++ zijn vereist.',no_work
'Kunnen we dat programma correct bewijzen? Nou en of! Jan Smans Bart Jacobs Frank Piessens Bart Jacobs Jan Smans  Programma verificatie is het formeel bewijzen van de correctheid van een programma. Correctheid kan verwijzen naar de afwezigheid van run-time fouten (zoals ArrayOutOfBoundsExceptions, NullPointerExceptions of data races), maar ook naar applicatie-afhankelijke eigenschappen (zoals het slagen van bepaalde assert statements). Programma verificatie is een van de  grand challenges  in computerwetenschappen en een erg actief onderzoeksgebied.  VeriFast is een programma verificator voor Java en C. VeriFast neemt een bronbestand geannoteerd met precondities, postcondities, lusinvarianten, etc als invoer en gaat na of het C of Java programma vrij is van run-time fouten (zoals ArrayIndexOutOfBoundsExceptions) en voldoet aan de opgegeven specificatie. Zo controleert de tool bijvoorbeeld bij iedere methode oproep dat de target expressie nooit gelijk kan zijn aan null en dat dat de preconditie geldt.  Hoewel programma verificatie grote vooruitgang geboekt heeft in de voorbije jaren blijven er nog steeds een hele boel uitdagingen over. Twee onderzoekers van Microsoft Research, Rustan Leino en Michal Moskal, hebben een aantal dergelijke uitdagingen beschreven in een  paper . In deze thesis ga je de uitdagingen beschreven in deze paper aan en tracht je oplossingen te formuleren. Meer bepaald beschrijft de paper een aantal voor verificatie uitdagende datastructuren en algoritmen. Het is aan jou om (1) specificaties (preconditions, postcondities, lusinvarianten, etc) te schrijven voor deze datastructuren en algoritmen en (2) aan te tonen met behulp van VeriFast dat de implementatie voldoet aan de opgegeven specificatie.  Het doel van deze thesis is om de correctheid aan te tonen van een aantal  voor verificatie uitdagende datastructuren en algoritmen  met behulp een programma verificator (VeriFast). De uitwerking van deze thesis omvat volgende stappen:  Studie van de VeriFast programma verificator. Deze studie bestaat uit het doornemen van de  VeriFast tutorial . Deze tutorial wordt ook gebruikt in de lessen Capita Selecta Veilige Software en Capita Selecta Software Engineering.   Correctheid bewijzen van eenvoudige algoritmen en datastructuren met behulp van VeriFast. In deze stap bewijs je bijvoorbeeld de correctheid van bubblesort en van een stack geimplementeerd als een gelinkte lijst. Om deze bewijzen te maken zal je een specificatie (onder andere pre- en postcondities) moeten schrijven voor het algoritme of de data structuur.  Correctheidsbewijzen van uitdagende algoritmen en datastructuren. Bewijs de correctheid van rood-zwart bomen, union find, een binary heap, etc.  Identificatie van nieuwe uitdagingen voor verificatie en mogelijk verbeteringen aan de VeriFast programma verificator. Als er voldoende tijd overblijft, kan je de voorgestelde uitbreidingen implementeren en evalueren.     Interesse in praktische toepassingen van logica en formele systemen.  Goede kennis van Java of C. VeriFast neemt Java en/of C programma s als invoer.  Kennis van OCaml of een functionele programmeertaal is meegenomen, maar absoluut geen vereiste. VeriFast is geimplementeerd in OCaml.     Programma verificatie is een van de  grand challenges  in computerwetenschappen.  Rustan Leino en Michal Moskal zijn twee onderzoekers aan Microsoft Research die enkele uitdagingen voor verificatie hebben geidentificeerd. Een overzicht van deze uitdagingen kan je  hier  terugvinden.  De VeriFast programma verificator en bijhorende documentatie kan je  online  terugvinden. Geef ons gerust een seintje als je meer informatie wil over VeriFast of als je een demo wil bekijken van de tool.',no_work
'Modulaire foutenafhandeling in een shallow parsing DSL Frank Piessens Dominique Devriese Frank Piessens Dominique Devriese Een van de moeilijkste aspecten van het implementeren van goedeparsers is het opvangen van fouten. Daarbij is het de bedoeling om zogoed mogelijke foutmeldingen te geven, zonder het parse algoritmeonnodig traag te maken. Vaak worden bepaalde heuristieken gebruikt omna het detecteren van een fout bijvoorbeeld de rest van een regelskippen en dan een volgend statement te proberen te vinden.Veelgebruikte compilers zijn vaak ooit begonnen van een abstractegrammatica, en de parser die tools zoals YACC of ANTLR hiervan maken,maar zijn deze later met de hand beginnen aanpassen om goed fouten tekunnen signaleren. Een elegantere strategie is om voor eenzelfde grammatica verschillendeparsers te genereren. Een snelle parser zonder foutenrapportage zoutelkens eerst kunnen geprobeerd worden op een file, en wanneer diefaalt, kan er een tragere parser de foutenrapportage doen. Voorinteractieve syntax completion in een IDE zou je zelfs een derde, nogwat tragere, maar incrementele parser alle mogelijke resterende parseskunnen laten uitzoeken. In deze thesis werk je deze ideeen uit in de grammar-combinatorslibrary. Dit is een recente Haskell parsing library, die wij recenthebben ontwikkeld met behulp van geavanceerde Haskell type systemtechnieken. De library laat toe om grammatica s te modelleren in deelegante stijl van parser combinators, maar zonder de fundamentelebeperkingen van die libraries. Je breidt de library uit met modulaire technieken voor foutenafhandeling. Voor deze thesis zoeken we een student met interesse in elegante,functionele talen zoals Haskell en geavanceerde type-systemtechnieken, alsook een interesse in moderne parsing technieken. Explicitly Recursive Grammar Combinators, Dominique Devriese enFrank Piessens, PADL 2011.http://projects.haskell.org/grammar-combinators/',no_work
'Ontwerp en implementatie van language features in een puur functionele dependently-typed programmeertaal/bewijsassistent Dominique Devriese Frank Piessens Frank Piessens Dominique Devriese  Agda is een state-of-the-art puur functionele dependently typedprogrammeertaal/bewijsassistent. Dat betekent dat het een functioneleprogrammeertaal is die lijkt op Haskell, maar met een heel krachtigtypesysteem. Zo krachtig zelfs dat het mogelijk wordt om willekeurigecorrectheidseigenschappen van je code te definieren, te gebruiken ente bewijzen. Dit soort talen wordt daarom ook vaak gebruikt als eenbewijsassistent die wiskundige bewijzen op een formele manier nakijkt.  Wij hebben onlangs een bepaalde feature toegevoegd aan Agda, tervervanging van Haskell type classes. Onze feature heet "non-canonicalimplicit arguments" en laat toe om bepaalde argumenten van functiesniet te geven als ze uniek kunnen afgeleid worden uit de context vande oproep.  In deze thesis ontwikkel je (een) niet-triviale uitbreiding(en) van deAgda programmeertaal, die verder bouwen op non-canonical implicits.Wij denken in de eerste plaats aan "overloaded literals": dit is eenelegante feature van Haskell, die toelaat om constante waarden(literals: getallen, strings, karakters, floating points etc.) in codete interpreteren als polymorfe waarden, gedefinieerd voor alle typesdie een bepaalde interface aanbieden. Dit stelt verschillendemoeilijkheden: de interface die de types aanbieden moet de compilertoelaten om na te kijken of een bepaalde literal past binnen hetdatatype (bijvoorbeeld de literal 15 past niet in een voorstelling vangetallen modulo 7). Een orthogonaal probleem is om literals ook toe telaten bij het pattern matchen. Afhankelijk van de interesse envorderingen van de student kan er binnen deze thesis ook gekekenworden naar het toevoegen van een equivalent voor Haskell s do-notatieof Idris  idiom-syntax. Ook mogelijk is dat je werkt aan uitbreidingenvan non-canonical implicits zelf. De uitwerking van deze thesis is een ontwerp van overloaded literalsen evt. extra language features, en een uitbreiding van de Agdaimplementatie (open source, geschreven in Haskell) met deze nieuwefeatures. Indien dit goed lukt, zullen we proberen om dit teintegreren in de upstream versie van Agda. Voor deze thesis zoeken we een sterke student met interesse inprogramming language design en next-generation researchprogrammeertalen als Agda. Agda is geimplementeerd in Haskell, en wevertrekken van Haskell features, dus affiniteit met Haskell is eenpluspunt.   Agda tutorial: http://www.cse.chalmers.se/~ulfn/papers/afp08/tutorial.pdf  Non-canonical implicits:  http://people.cs.kuleuven.be/~dominique.devriese/agda-non-canonical-implicits/   en de submitted paper onder Further Reading.',no_work
'Veilige IO API s voor Agda met separation logic Dominique Devriese Frank Piessens Frank Piessens Dominique Devriese  Agda is een state-of-the-art puur functionele dependently typedprogrammeertaal/bewijsassistent. Dat betekent dat het eenfunctionele programmeertaal is die lijkt op Haskell, maar met eenheel krachtig typesysteem. Zo krachtig zelfs dat het mogelijk wordtom willekeurige correctheidseigenschappen van je code te definieren,te gebruiken en te bewijzen. Dit soort talen wordt daarom ook vaakgebruikt als een bewijsassistent die wiskundige bewijzen op eenformele manier nakijkt.  In deze thesis bekijken we Agda als een programmeertaal, die kangecompileerd worden naar Haskell code of Epic code, die op hun beurtverder compileren naar C of machine-code. Een open vraag is nuechter hoe je API interfaces van de onderliggende talen bestbeschikbaar maakt in Agda.  Een beloftevolle aanpak is recent onderzocht in de YNot library voorCoq (een andere dependently typed functionele programmeertaal). Dezemodelleren imperatieve code met behulp van een geparameteriseerdemonad (bekend uit Haskell). Voor de specificaties gebruiken ze"separation logic": een formalisme voor het specifieren van hetgedrag van imperatieve functies op een modulaire manier (d.w.z.zodat code makkelijk kan opgesplitst worden in verschillendeonafhankelijke delen, die gecombineerd worden als het nodig is).  In deze thesis implementeer je een equivalent voor de YNot libraryin Agda. Hierbij komen enkele interessante vragen aan bod, zoals deinteractie met Agda features zoals computational irrelevance ennon-canonical implicits. Vervolgens onderzoek je hoe bekende HaskellIO API s veilig kunnen worden aangeboden in Agda. Afhankelijk van jeinteresse en vorderingen, kan er dan gekeken worden naar hetbeschikbaar maken van imperatieve API s voor parallellisme(fork-join, MVars etc.) met behulp van bekende technieken uitseparation logic (fractional heap chunks etc.). Nog een interessanterichting is het onderzoeken van de interactie met technieken voorhet modulair maken van functies die imperatieve API s gebruiken. Je werkt deze ideeen uit aan de hand van een implementatie op de grens van Haskell en Agda. Je vertrekt van een geparametriseerde monad in Agda, waarbinnen je dan met behulp van de Agda Foreign Function Interface naar Haskell de Haskell IO API s in modelleert. Heel belangrijk is dat je grondig reflecteert over de voor- en nadelen van je modellering en verschillende mogelijkheden in detail bestudeert en evalueert. Je valideert aan de hand van de implementatie van bewijsbaar correcte imperatieve programma s. Voor deze thesis zoeken we een sterke student met een interesse infunctionele talen zoals Haskell en de specificatie van imperatieveprogramma s.  Agda tutorial: http://www.cse.chalmers.se/~ulfn/papers/afp08/tutorial.pdf  YNot: http://ynot.cs.harvard.edu/papers/ynot08.pdf',no_work
'Visualization of Probabilistic Graphs Dimitar Shterionov Gerda Janssens Dimitar Shterionov Knowledge discovery in graph structured data (Graph Mining) is a popular topic in machine learning (ML). Graph mining focuses on extracting useful information from graph structured relational data. Often we are interested in probabilistic graphs, and therefore annotate the relations (i.e., the edges of the graph) with probabilities to model uncertainty in the data. Learning from and reasoning about probabilistic graphs requires powerful tools, such as ProbLog ? a Prolog-based system, which combines probabilities with logic and also supports learning. We are often interested in tackling large scale graphs (e.g., protein-protein interactions), which involve many different entities (e.g., proteins). Consequently, it is difficult for a human user to visualize the structure without the support of special tools. The inability to ?see the big picture? can lead to difficulties in properly encoding and feeding the data into the system. This thesis focuses on building a 3D visualization tool that allows the user to model and explore the probabilistic graph in order to get a better understanding of its characteristics. In addition, when a system such as ProbLog  answers queries, sometimes it uses only a part of the whole probabilistic graph. Therefore, our visualization tool also provides feedback on the relevant parts of the graph needed to answer a query.  implement support for transforming (graph) structured data (eg. files with extension .graph, .net, .xml, etc.) into a ProbLog program study different AI approaches for determining nodes  position in 3D space and implement the most suitable one(s) program the visualization (rendering) in JAVA 3D, OpenGL, or other preferred 3D modeling language; extend the tool with support for ProbLog interaction;  For this thesis you will use logic programming as well as graphics tool/language, such as JAVA 3D or Open GL, to design and write a graphical tool for modeling graph structured data. For the layout of the graphs, a study of algorithms (including AI-based ones) has to be made. The time/work load is expected to be divided as 25% literature and 75% coding. - http://graphics.stanford.edu/papers/munzner_thesis/ - http://warriors.eecs.umich.edu/viz_tools/ - http://www.graphviz.org/ - http://www.caida.org/tools/visualization/walrus/ - http://www.cytoscape.org - http://cgi.cse.unsw.edu.au/~wyos/skyrails/',no_work
'Mining Facebook Dimitar Shterionov Gerda Janssens Dimitar Shterionov Nowadays, social networks are ubiquitous. The amount of data they involve (communication, interests, evolution of relationships,...) is enormous and continuously growing. Therefore, extracting knowledge from social networks is a challenging business. That is why sampling techniques aim to lower the size of a network, while keeping its specifics unchanged. Such methods, as for example random walks, can provide us with representative snapshots, from which we can extract important and reliable information. Consequently, typical characteristics of the social network can be determined and interesting problems such as influence propagation can be modeled. With this thesis we target to tackle problems related to sampling, propagation and prediction in social networks, in particular Facebook. Here we define four main approaches for dealing with these issues:First, we want to investigate sampling methods for creating realistic snapshots. Second, we want to search for most probable groups by combining cliques of friends, present in the snapshot. Also, we want to identify important users, for example, users that serve to bridge two distinct groups. Third, we want to investigate the problem of influence propagation ? what role different users play in mediating information. Forth, we want to predict the evolution of the network, by studying consequent snapshots. Fields of interest at this point are prediction of relationship, friendship, joining or leaving a group, etc. /a selection can be made out of the following topics/ study of different snapshot methods and implementation of selected ones detecting probable (friendship, relationship, etc.) links between users design and development of algorithms for joining cliques of users study of influence propagation and implementation of learning methods related to it suggesting methods for modeling the evolution of the network, based on snapshots taken in distinct time intervals and implementing models for predicting the network s relational aspects  For this thesis, you will use techniques from graph theory and graph mining. Also should be interested in Prolog and probabilistic logic programming. Work load - 50% literature, 50% coding. - Minas Gjoka, Maciej Kurant, Carter T. Butts, Athina Markopoulou ? A Walk in Facebook: Uniform Sampling of Users in Online Social Networks (http://arxiv.org/abs/0906.0060) - Ian A. McCulloh, Joshua Lospinoso, Kathleen Carley ? Social Network Probability Mechanics (www.wseas.us/e-library/conferences/2007egypt/papers/568-496.pdf)  - Amit Goyal, Francesco Bonchi, Laks V. S. Lakshmanan ? Learning Influence Probabilities In Social Networks (http://www-personal.umich.edu/~mejn/netdata/)  - Christos Faloutsos, Kevin S. McCurley, and Andrew Tomkins ? Fast Discovery of Connection Subgraphs (http://portal.acm.org/citation.cfm?id=1014068)  - A. Kimmig, et. al ? On the Implementation of the Probabilistic Logic Programming Language ProbLog.',no_work
'Facebook zonder zorgen: vang hackers in een JavaScript sandbox Steven vanAcker Lieven Desmet Frank Piessens Frank Piessens Lieven Desmet Steven vanAcker De laatste jaren duiken meer en meer webgebaseerde applicaties op ophet internet zoals GMail, Facebook, Twitter, ... Als krachtige enflexibele taal speelt JavaScript in deze webapplicaties eenbelangrijke rol om de interactie met de gebruiker aan de browserkantaangenamer te maken. De keerzijde van deze kracht en flexibiliteit isdat JavaScript ook door aanvallers gebruikt kan worden om bvb. cookieste stelen of een denial-of-service aanval op te zetten.Vanuit de optiek van het "least privilege" principe is het raadzaam omeen applicatie niet meer functionaliteit aan te bieden dan ze nodigheeft. In de praktijk wordt hiervoor gebruik gemaakt van een "sandbox"waarin de applicatie draait. De aangeboden functionaliteit in diesandbox is dan gelimiteerd tot het strikt noodzakelijke. Het doel van deze thesis is om een dergelijke sandbox te ontwikkelen. In eerste instantie zal in deze thesis nagegaan worden welke soortensandboxes er voor web applicaties bestaan en hoe effectief die zijn.Daarna volgt een implementatie of een uitbreiding van een bestaandsandbox mechanisme in Firefox. Met behulp van deze sandbox kan danonderzocht worden wat voor functionaliteit enkele typische webapplicaties zoal nodig hebben, en belangrijker: wat voorbeveiligingskritische functionaliteit kan verwijderd worden uit eentypische sandbox. Voor deze thesis heb je best interesse in veilige software, web browsers en web toepassingen. Aangezien bij deze thesis ook een implementatie hoort, heb je kennis van C++ en JavaScript nodig.',no_work
'Debugging Using Graphical Representations of Probabilistic Logical Programs Theofrastos Mantadelis Gerda Janssens Theofrastos Mantadelis  Lately we have seen an increase of interest in probabilistic logical programming formulations and systems such as PRISM, ProbLog, MLNs, etc.. These systems lack of comprehensive debugging tools. Conventional debugging is applied but does not give any information about the probabilistic nature of the program.  We aim to investigate how the probabilistic nature of such a program should be represented and shown to the programmer to help him find erroneous programs and wrong formulations.   The purpose of this thesis is to first investigate possible ways for modelling the execution of probabilistic logical programs. We will use those to provide debugging information and probabilistic model checking. The final goal of the thesis is to implement a debugger for ProbLog.     Research existing literature.   Choose and motivate a suitable general representation.   Implementation.   Integration with ProbLog.   Investigation of debugging properties.   Implementation of monitored execution.   Interested in Prolog, machine learning, and graphical representations. Strong programming skills (Java).     Sato, T. and Kameya, Y.: PRISM: A symbolic-statistical modeling language. Proceedings of the 15th International Joint Conference on Artificial Intelligence (IJCAI97), pp.1330?1335, 1997.    Domingos, Pedro and Richardson, Matthew (2007). Markov Logic: A Unifying Framework for Statistical Relational Learning. In L. Getoor and B. Taskar (eds.), Introduction to Statistical Relational Learning (pp. 339-371), 2007. Cambridge, MA: MIT Press.    A. Kimmig, B. Demoen, L. De Raedt, V. Santos Costa, and R. Rocha. On the Implementation of the Probabilistic Logic Programming Language ProbLog. Theory and Practice of Logic Programming, accepted, 2010.    Andreas Zeller, Dorothea L?tkehaus: DDD - a free graphical front-end for UNIX debuggers. ACM SIGPLAN Notices (1996).',no_work
'Most Probable Shortest Path Theofrastos Mantadelis Gerda Janssens Angelika Kimmig Dimitar Shterionov Theofrastos Mantadelis  Lately there is a surge of interest in problems that combine stochastic and logic information. Finding the most probable shortest path in a stochastic graph is such a problem. This problem has applications in intelligent transportation systems, bio-informatics, networks etc.. The context of this thesis is to investigate the most probable shortest path problem.   The thesis aims to investigate the most probable shortest path problem. We plan to develop efficient algorithms to solve this problem. We also want to investigate the best ways to solve this problem in ProbLog - a probabilistic programming language developed by the K.U. Leuven.      Study literature related with the shortest path problem on stochastic graphs.    Study literature related with ProbLog and familiarize with it.    Design algorithms that solve the most probable shortest path problem with ProbLog.    Implement the state-of-art solutions of the problem and the designed algorithms.    Perform a thorough comparison of the different approaches.   Interested in Prolog, Probabilistic Logic Programming, Machine Learning.     S. K. Peer, Dinesh K. Sharma - Finding the shortest path in stochastic networks. Computers & Mathematics with Applications 2007.    Y. Y. Fan, et. al - Shortest Paths in Stochastic Networks with Correlated Link Costs. Computers & Mathematics with Applications 2005.    G Polychronopoulos, et. al - Stochastic shortest path problems with recourse. Networks 1996.    Liping Fu, L. R. Rilett - Expected shortest paths in dynamic and stochastic traffic networks. Transportation Research 1998.    Ye Yuan, et. al - Efficient Answering Probability Threshold-Based SP Queries over Uncertain Graphs. DASFAA 2010.    A. Kimmig, et. al - On the Implementation of the Probabilistic Logic Programming Language ProbLog. TPLP 2010.',no_work
'Exploring Relational Binary Decision Diagrams Theofrastos Mantadelis Gerda Janssens Luc DeRaedt Theofrastos Mantadelis  Machine learning is the subfield of Artificial Intelligence that explores algorithms that learn from data. A major research topic within machine learning is statistical relational learning (SRL) that assigns probabilities to relational data and answers probabilistic queries. Inference in such models is NP-hard or worse. The current trend is to compile the model to a structure where inference is polynomial. Some structures that allow compilation are: Arithmetic Circuits, Reduced Ordered Binary Decision Diagrams, Zero Suppressed Decision Diagrams.  ROBDDs represent a Boolean function. They are somewhat similar to binary or Boolean decision trees though they have a graph structure. ROBDDs are used for many different AI applications such as: efficient inference, planning, learning. However, the usual ROBDDs can only represent propositional Boolean functions, but not relational or first order ones. Recently there have been some attempts to extend ROBDDs to work with relational or first order logic but it still remains an open research topic.   The purpose of this thesis is to explore and evaluate these proposals, possibly extend and adapt them, and optionally to investigate whether they can be used in combination with our probabilistic Prolog framework.    Understand Binary Decision Diagrams and other data structures.  Define how to apply Relational BDDs in inference tasks.  Prototype implementations of each chosen relational structure.  Comparison of structures.  [Optional] Integration of best performing structure in ProbLog.   Interested in data structures, machine learning.    Adnan Darwiche and Pierre Marquis - A Knowledge Compilation Map   Henrik Reif Andersen - An Introduction to Binary Decision Diagrams   Shin-ichi Minato, et al. - Compiling Bayesian Networks by Symbolic Probability Calculation Based on Zero-suppressed BDDs   Chenggang Wang, Saket Joshi, Roni Khardon - First Order Decision Diagrams for Relational MDPs   R. Bahar, E. Frohm, C. Gaona, G. Hachtel, E. Macii, A. Pardo, and F. Somenzi - Algebraic decision diagrams and their applications',no_work
'Versterk de grondvesten van het web Philippe DeRyck Lieven Desmet Frank Piessens Frank Piessens Lieven Desmet Philippe DeRyck  In het moderne web wordt er aan een hoog tempo nieuwe functionaliteit geintroduceerd. Hierbij wordt zeker rekening gehouden met veiligheid, maar is het niet altijd mogelijk om alle aspecten in beschouwing te nemen. In recent onderzoek [1] wordt er een formeel alloy-model [2] voorgesteld, waarmee het mogelijk wordt om na te gaan of nieuwe functionaliteit geen nieuwe kwetsbaarheden introduceert. De auteurs ontdekken met behulp van hun model een kwetsbaarheid in een beschermingsmaatregel die zij zelf ontworpen hebben, waarmee het nut op praktische wijze wordt aangetoond. Dit model wordt gebruikt met de Alloy analyzer, een model finder, vergelijkbaar met de IDP solver uit de cursus Modellering van Complexe Systemen.  Het voorgestelde alloy-model kan ook gebruikt worden om bestaande aanvallen en hun beschermingsmaatregelen te modelleren. Voorbeelden hiervan zijn Cross-Site Request Forgery, Session Hijacking, Session Fixation, ... Zo kan nagegaan worden of een beschermingsmaatregel voldoende bescherming biedt tegen de aanval in kwestie. Wanneer er ook legitieme scenarios worden gemodelleerd, kan er zelfs aangetoond worden of de beschermingsmaatregel deze scenarios ondersteunt, wat niet altijd het geval is.  Het doel van deze thesis is om specifiek gedrag van het web te modelleren, samen met mogelijke aanvallen, beschermingsmaatregelen en legitieme scenarios. Bij deze modellering kunnen enerzijds nieuwe aanvalsvectoren ontdekt en geaddresseerd worden, of kan er anderzijds aangetoond worden dat een beschermingsmaatregel veilig en/of bruikbaar is. De thesis start met het inwerken in het alloy-model, wat zeer intuitief is voor wie enigszins vertrouwd is met modelleringstechnieken. De inwerkingsfase focust zich op Cross-Site Request Forgery en reeds bestaande beschermingsmaatregelen. Naarmate de opgedane ervaring worden er nieuwe webtechnologieen en aanvallen aan het model toegevoegd. Gedreven. Deze thesis gaat uit van een natuurlijke interesse in software beveiliging, web applicaties en logica. De thesis vereist geen specifieke voorkennis, en bevat zowel een literatuurstudie als een ontwikkelsgedeelte. Het vak "Modellering van Complexe Systemen" en interesse in het werken met tools als de Alloy Analyzer is een pluspunt.  [1] Devdatta Akhawe, Adam Barth, Peifung Eric Lam, John Mitchell, Dawn Song. Towards a Formal Foundation of Web Security. Proceedings of the 23rd IEEE Computer Security Foundations Symposium, Edinburgh 2010.   [2]  http://alloy.mit.edu/community/',no_work
'Veilige web 2.0 applicaties: GWT to the rescue? Lieven Desmet Frank Piessens Frank Piessens Lieven Desmet Lieven Desmet Frank Piessens De ontwikkeling van web applicaties wordt meer en meer complex, en omvat zowel de programmatie van de client-side (HTML en Javascript), de server-side (PHP, Servlets, JSF, RubyOnRails, ASP.NET, ...) en de mogelijk asynchrone communicatie tussenbeide (AJAX). Verschillende Javascript libraries en frameworks bieden reeds extra abstracties aan om over de verschillende browsers heen op een uniforme manier de client-side scripts te ontwikkelen. Multi-tier talen (zoals GWT, Volta, Links, SELinks) gaan nog een stap verder, en komen aan de complexiteit tegemoet door een uniforme programmeeromgeving aan te bieden over de verschillende tiers (client tier, web tier, business tier, database tier). Google Web Toolkit (GWT) laat bijvoorbeeld toe om de applicatie in Java te programmeren, en genereert dan server-side automatisch de nodige Javascript. Het doel van deze thesis is om verschillende multi-tier talen voor web applicaties te bestuderen, en te vergelijken met elkaar op basis van de aangeboden security features. Daarnaast zal er ook een multi-tier taal uitgebreid worden om een ontbrekende web beveiligingstechniek (bv bescherming tegen CSRF, veiliger session management, veilige integratie van 3rd party gadgets) toe te voegen aan de taal. Om zowel de veiligheidsvereisten van web 2.0 applicaties in kaart te brengen als de aangeboden functionaliteit van multi-tier talen beter te begrijpen, zal in een eerste stap van de thesis een web 2.0 applicatie worden gebouwd (bv een eigen sociale netwerksite) met behulp van een dergelijke multi-tier taal (bv GWT). Deze web 2.0 applicatie zal verder in de thesis gebruikt worden om de verschillende multi-tier talen te beoordelen zowel op functionele eigenschappen als security features. Vervolgens wordt een van de talen uitgebreid om een ontbrekende beveiligingstechniek toe te voegen aan de taal. Interesse in ontwikkeling van veilige software en meer specifiek web applicatie beveiliging.De thesis is een gezonde mix van literatuurstudie, implementatie en onderzoek.   GWT:  http://code.google.com/webtoolkit/  SELinks:  http://www.cs.umd.edu/projects/PL/selinks/  Links:  http://groups.inf.ed.ac.uk/links/  Secure Compilation of a Multi-Tier Web Language:  http://www.cl.cam.ac.uk/~ib249/research/links-tldi09-submission.pdf',no_work
'Comparing Structure Learning Approaches for Probabilistic Models Wannes Meert Jesse Davis Jesse Davis Wannes Meert Models, such as Bayesian networks, dependency networks, Markov networks and kernel density estimators, are able to compactly represent the joint probability distribution over a set of variables. They have been successfully applied to tasks such as spam filtering, medical diagnosis, image recognition, and so on. These types of models gain their power by being able to exploit (conditional) independences among sets of variables in the data.One of the primary learning setting is given a data set, is it possible to automatically discover these independence relations. Many different learning algorithms have been proposed for each formalism (e.g., Bayesian networks or Markov networks). However, learning algorithms have been largely compared against competitors from the same formalism. What is lacking is a more comprehensive evaluation that makes comparison across the different formalism. This thesis will focus on taking off-the-shelf algorithms (most of which are publicly available) and applying them to a wide range of benchmark problems. This should lead to a better empirical understanding about the relative strengths and weaknesses of both the various learning algorithms and formalisms. The tasks involved with this thesis are the following: 	 Investigate what the current popular learning algorithms are for each formalism. Decide on a relevant subset of algorithms to include in the analysis.	 Create a set of benchmark datasets. These may also be drawn from publicly available source such as the UCI machine learning repository.	 Decide on a set of experiments that will help elucidate various properties of each algorithm and formalism.	 Run the experiments.  Interest in machine learning techniques.   Daniel Lowd and Jesse Davis. Learning Markov Network Structure with Decision Trees. Proceedings of the 10th IEEE International Conference on Data Mining (ICDM), 2010. Sydney, Australia. N. Friedman, D. Pe&apos;er and I. Nachman. Learning Bayesian network structure from massive datasets: The ?Sparse Candidate? algorithm. Proceedings of the 15th Conference on Uncertainty in Artificial Intelligence, 1999.',no_work
'Distributie en segregatie van cellulaire schade in bacteriele populaties Philip Dutre Abram.Aertsen+biw.kuleuven.be Philip Dutre Abram.Aertsen+biw.kuleuven.be Philip Dutre Abram.Aertsen+biw.kuleuven.be Dit project streeft naar een nieuwe en meer gedetailleerde analysemethode van microbiele processen, die gebaseerd is op de combinatie van gesofistikeerde microscopie met hoge doorvoer beeldanalyse. Door het gebruik van time-lapse fluorescentiemicroscopie kunnen immers essentiele gegevens zoals de morfologie, groeisnelheid, deling en genexpressie van een groot aantal individuele cellen gelijktijdig gedocumenteerd worden doorheen de tijd, zelfs met inbegrip van de onderlinge genealogische verwantschap tussen de cellen. Om deze massa aan relevante informatie efficient en adequaat af te leiden van het bekomen beeldmateriaal, zullen nieuwe algoritmen voor hoge doorvoer beeldanalyse ontwikkeld worden.  Uit videosequenties die via automatische micrsoscopie verkregen werden, zal getracht worden om allerhande karakteristieken uit beelden af te leiden. Dit zal gebeuren a.d.h.v. algoritmen die gebaseerd op beeldherkenning en zogenaamde shape grammars. Deze laten toe om geometrische vormen (in deze toepassing cellen) in beelden op te sporen. De finale eindbedoeling is om na te gaan in hoeverre essentiele tools voor micro-biologen kunnen ontwikkeld worden.  Deze masterproef is in samenwerking met de afdeling Levensmiddelentechnologie van de Faculteit bio-ingenieurswetenschappen.',no_work
'Probabilistische Visibiliteit in Computer Graphics Rendering Algoritmen Philip Dutre Philip Dutre Philip Dutre De visibiliteitsfunctie is een belangrijke component in vele 3D rendering algoritmen. De visibiliteitsfunctie op zich neemt meestal 2 vormen aan: ofwel wil men vanuit een punt en in een bepaalde richting te weten komen welk geometrisch object men waarneemt (cfr primaire zichtstralen in ray tracing); ofwel wil men weten of 2 punten in de 3D ruimte onderling zichtbaar zijn zonder tussenligende objecten (cfr. schaduwstraal in ray tracing). In dit laatste geval kan men de visibiliteitsfunctie beschouwen als een binaire of booleaanse functie, met als resultaat 0 (niet zichtbaar) of 1 (wel zichtbaar)In globale belichtingsalgoritmen komt de visibiliteitsfunctie echter dikwijls voor als onderdeel van de te integreren belichtingsfunctie. Bijvoorbeeld, indien men de belichting van een oppervlaktelichtbron voor een te shaden punt wil kunnen, moet men integreren over het oppervlak van de lichtbron. Omdat sommige delen van de lichtbron al dan niet zichtbaar kunnen zijn  voor het punt dat men wil shaden, zit de visibiliteitsfunctie vervat in de integrand.In dergelijke gevallen speelt de exacte waarde van de visibiliteitsfunctie (0 of 1) minder een rol, omdat we geinteresseerd zijn in de gemiddelde geintegreerde visibiliteit: welke fractie van de lichtbron is zichtbaar(getal tussen 0 en 1).Integralen in computer graphics worden dikwijls uitgerekend met stochastische processen (Monte Carlo integratie). Het kan dus een nut hebben om ook de visibiliteitsfunctie voor een gegeven paar punten ook als een stochastische functie te gaan beschouwen. Bvb. in plaats van alle geometrische primitieven op mogelijke intersectie met een schaduwstraal te testen, kunnen we slechts een subset testen. Het resultaat zal dan stochastisch van aard zijn met een zeker betrouwbaarheidsinterval. Omdat men finaal toch de functie als geheel wil gaan integreren, kunnen deze stochastische afwijkingen elkaar opheffen en kan men toch een nauwkeurige integraalwaarde (en dus belichtingswaarde voor een pixel) bekomen.Een en ander zou er toe moeten kunnen leiden dat men sneller een zelfde kwaliteit beeld kan genereren, met globaal gezien minder straal-object intersecties - niet door een spatiale gegevensstructuur te gebruiken, maar wel door op een stochastische manier slechts een subset van objecten op intersectie te testen. Het doel van deze masterproef is om enkele denkpistes i.v.m. het probabilistisch evalueren van de visibiliteitsfunctie te onderzoeken. Omdat dit een experimenteel en onderzoeksgedreven onderwerp is, staan de resultaten niet bij voorbaat vast.Het is tevens de bedoeling om een wetenschappelijk paper op basis van dit onderwerp in te dienen voor het Eurographics Symposium on Rendering 2012 (deadline: April 2012, en een van de toonaangevende fora voor rendering onderzoek in computer graphics). Indien het paper aanvaard wordt, zal de student dit mogen presenteren op dit symposium. Als dusdanig zal er bij dit onderwerp ook nauw worden samengewerkt met prof. Philip Dutre die een lange ervaring heeft met de ontwikkeling van rendering engines voor globale belichting. Omwille van de timing wordt er verwacht dat het zwaartepunt van de hoeveelheid werk in het 1ste semester komt te liggen. Vermits het de bedoeling is om te werken op de evaluatie van de visibiliteitsfunctie, zal er gestart worden van bestaande ray tracing implementaties (bvb. PBRT, http://www.pbrt.org/).De implementatie zal gebeuren in C/C++. Indien de student hier geen voorkennis van heeft, wordt verwacht dat de student deze zelf verwerft geudrende de zomervakantie. Uitzonderlijk kan overwogen worden dit project in een andere programmeertaal te maken (contacteer hiervoor ph. Dutre). Student met sterke interesse in experimentele en onderzoeksaspecten van globale belichtingsalgoritmen in computer graphics. Ook een gezonde interesse in numerieke technieken en probabiliteitstheorie is een must. Een inleidend vak Computer Graphics moet reeds gevolgd zijn.Omdat er gestreefd wordt naar het indienen van een wetenschappelijk paper, wordt verwacht dat de student sterk gemotiveerd is wetenschappelijk onderzoek samen met de promotor van de masterproef. Algemene literatuur i.v.m. 3D rendering algoritmen en globale belichting. Advanced Global Illumination  (boek), uitgever A K Peters, Ph. Dutre, K. Bala, Ph. Bekaert. Physically-based Rendering  (boek), uitgever Morgan Kaufmann, M. Pharr, G. Humphreys',no_work
'There is safety in numbers: Protecting programs by duplicating their parts Nick Nikiforakis Frank Piessens Wouter Joosen Nick Nikiforakis Despite the extensive research in security countermeasures for memory-unsafe languages (such as C and C++), vulnerabilities are still being discovered and exploited. While memory-safe languages exist, performance, compatibility and control reasons still place C and C++ as the 2nd and 3rd most used programming language. A characteristic example is the Linux kernel, which is almost entirely writtenin C. In this thesis, the student is called to explore the most well-knowncountermeasures that are suggested and/or deployed on modern OS and then develop his own. The countermeasure itself is based on the duplication of certain elements of a running program that can transform the control-flow of a program in a more static, and thus more secure version.  The following are expected:1)The student will have to explore and become familiar with the most popular research around low-level C vulnerabilities.2)The student will have to become familiar enough with C, x86 assembly and a transformation system to successfully design and implement the defense mechanism described earlier The student must be already familiar with C (use of pointers, dynamic memory etc.) and must be willing to learn all the rest.     Smashing the stack for fun and profit       Simple Stack-smashing protection for GCC      Defeating Return-Oriented Rootkits with "Return-less" Kernels',no_work
'Low-level computer bugology Nick Nikiforakis Wouter Joosen Nick Nikiforakis Despite the extensive research in security countermeasures for memory-unsafe languages (such as C and C++), vulnerabilities are still being discovered and exploited. While memory-safe languages exist, performance, compatibility and control reasons still place C and C++ as the 2nd and 3rd most used programming language. A characteristic example is the Linux kernel, which is almost entirely written in C. In this thesis, the student is called to explore the latest bugs insoftware products, categorise them and discover their significance. A very important part of this study will be to classify them according to their locality. That is, given a vulnerable program, can the bug be temporarily mitigated by commenting out the function and return a default error value? Or is it inherently connected to a large part of the program, and switching off its function would mean a complete break-down of a program s functionality? The following are expected: 1) The student will have to become familiar with basic hacking techniques. 2) The student will have to do an extensive study of vulnerable programs and categorize their vulnerabilities using various metrics 3) The student will have to attempt to "fix" some of them, using specific guidelines The student must be already familiar with C (use of pointers, dynamic memory etc.) and must be willing to learn all the rest.    Milk or Wine? Does software Security improve with Age?   US-CERT Vulnerability Notes Database',no_work
'Securing the foundations of Web applications Nick Nikiforakis Frank Piessens Lieven Desmet Nick Nikiforakis In an ever-growing Internet, more and more people utilize Web servicesto conduct more and more online transactions. From e-shopping and e-mail to e-banking and e-health, users trust Web applications with their financial, private and medical data without really understanding the loss that they would suffer if someone impersonated them to these applications. Due to the value of this information, a plethora of attacks have been devised against Web applications and specifically against their session management functions, both at client-sideand at the server-side. Existing countermeasures provide protection against specific attacktechniques, but fail to provide comprehensive session security.The objective of the thesis is to propose an improved design forsecuring session management by combining and or extending these existing countermeasures. The student will propose a design, implement it in Firefox, and evaluate the security, compatibility and/or performance. The student will be expected to: 1) Become familiar with basic Web hacking techniques related to session identifiers 2) Become familiar with the extension framework of Mozilla Firefox 3) Design, implement and extend session security mechanisms  The student must feel comfortable with server-side and client-side Web programming languages (e.g. PHP and JavaScript).     CsFire: Transparent client-side mitigation of malicious cross-domain requests  SessionShield: Lightweight protection against session hijacking',no_work
'The quick Firefox jumps over the Internet Nick Nikiforakis Frank Piessens Lieven Desmet Nick Nikiforakis The Mozilla Firefox is a free, open-source Internet browser whichcurrently holds 30% of the world-wide browser usage. One of its main attractive characteristics is its expandability, i.e. the fact that users and programmers can extend the functionality of the browser by coding new "extensions" that can be added, without recompilation, to the browser. For the same reason, Firefox has also been used a lot by academics who can, relatively easily, implement a prototype for their systems and test them on a real fully-functional browser. In this thesis, the student is called to study the extension-related functionality of Firefox and to use it, in combination with other systems of his choice to create an interactive Web crawler. The resulting system should be able to start from a given list of URLs, autonomously browse the Web and click on links to navigate from page to page. The crawler will then be evaluated by putting it to use for a variety of purposes, ranging from simple statistic gathering to testing new attacks/defenses. The student will be expected to: 1) Become familiar with the mechanisms used in existing crawlers 2) Become familiar with the extension framework of Mozilla Firefox and 3) Design and implement the various extensions and systems that will allow a browser to autonomously browse through the Internet and perform basic interactions with each Web page The student must be willing to discover and configure existing mechanisms as well as design and implement all the necessary missing components for an autonomous interactive Web crawler   A Solution for the Automated Detection of Clickjacking Attacks  Chickenfoot',no_work
'Formele modellering en kennisrepresentatie in  robotica Hanne Vlaeminck Marc Denecker Marc Denecker Hanne Vlaeminck  Een van de belangrijkste challenges van de komende tien jaar inrobotica is de integratie van hoog niveau informatie en commonsense kennis in robotten wat deze moet toelaten om meerintelligentie en zelfstandigheid te verwerven.  Op dit ogenblikmoet het gedrag van robotten nog tot in de kleinste detailsgeprogrammeerd worden.  Nu succesvolle methododiekenwerden ontwikkeld voor concrete laag-niveau handelingen (bewegenvan een arm, vastnemen van een object,... ) verlegt de aandachtzich naar inbouwen van gezond verstand in robotten (zoals dat eenglas breekt als het losgelaten wordt op een zekere hoogte, of datmenselijke omstaanders niet geraakt mogen worden tijdens eenbeweging, ... )  Hiervoor zal gebruik gemaakt moeten worden vanallerhande expressieve kennisrepresentatietalen (met of zonderprobabiliteiten) voor het modelleren van kennis op een hoogabstractieniveau. Deze thesis is een experiment hierrond.  De initiele setting vande thesis is een verkeersituatie bestaande uit een paar robottendie zich autonoom voortbewegen in een verkeerspark dat voorhandenis op werktuigkunde. De kennisbank van deze robotten zal bestaanuit verschillende lagen. Op het hoogste niveau vinden we bv. deverkeersregels, dit zijn de "constraints" die opgelegd wordendoor de "Environment".  Daarnaast komen de constraints dieopgelegd worden door de "Task": wat wil een bepaalde individuelerobot doen? Welke optimisatie wil men bereiken voor het gehelekruispunt?  Enz. Vervolgens komen de constraints opgelegd doorde "Robots", met name: hoeveel ruimte is er nodig, welkesnelheden zijn mogelijk en gepast, enz.  Diedriehoek "Environment-Task-Robot" komt altijd terug, en eenbelangrijk deel van de kennis bestaat juist uit hoe die driekunnen, mogen of moeten interageren. De rest van de kennis gaatover de (vertegenwoordigers van) drie genoemde componenten. Ditbetreft o.a., specificatie van hoog niveau acties(effecten van beweging, draaien, van objecten oprapen ofvoortduwen, botsen, boetes bij het rijden door een rood licht,enz). Ook hier zijn er kennisrepresentatie-vereisten voorEnvironment, Task en Robot, apart en in interactie. Het is opdeze niveaus dat plannen berekend worden op basis van intentiesen specieke doelen.  Wat er nog bijkomt is de kennis over hoe ditlagere niveau interageert met het hogere (en met zijn eigenlagere niveau, namelijk dat van de controllers en estimators vlakrond de hardware (motoren en sensoren).  Modelleren van en testen met robotten die zich in een verkeerspark voortbewegen.  Wat de studenten moeten kunnen bereiken in het eindwerk: er moeteen modellering worden gebouwd van de diversekennisbankcomponenten met voldoende informatie om om een echteverkeerssituatie uit te testen, bijvoorbeeld twee ofdrie "wagens" die elkaar kruisen op een kruispunt. In een laterstadium zal gekeken worden naar meer complexe taken zoalsassemblage. Voor de kennisrepresentatietaal en inferentiesysteemwordt uitgegaan van FO(.) en het IDP systeem (confer de cursusModelleren van Complexe Systemen).  Werktuigkunde zorgt voor decontrole en de perceptie, tot op het niveau dat nodig is voor dekennisrepresentatie.  Interesse voor modeleren, logica, programmeren en robotica.  http://homepages.laas.fr/slemaign/official/myself/myself.html  http://ias.cs.tum.edu/research-areas/cram/cram',no_work
'Bio-inspired scheduling for smartphone and tablet platforms  ZubairWadood Bhatti Davy Preuveneers Yolande Berbers ZubairWadood Bhatti Davy Preuveneers Modern smartphone and tablet platforms feature heterogeneous cores with multiple operational modes, complex memory hierarchies and multi-hop on-chip interconnects. Efficient scheduling such that all these features are exploited is computationally complex. State-of-the-art operating systems that decide everything at run-time are not able to target aggressive scheduling optimizations because of the run-time overhead they incur. Therefore, two-phase approaches to the scheduling problem have recently appeared. At design-time, scheduling decisions for the application are made off-line. At run-time, these precompiled schedules are dynamically activated depending on the runtime context. This approach allows for flexibility and less overhead for the run-time manager to minimize the system energy consumption. This thesis will investigate how bio-inspired techniques such as genetic algorithms can be applied for scheduling. For example, in genetic algorithm based scheduling, the starting times of tasks can represented as genomes, the initial population would consist of genomes with some random start times. These genomes can then be mutated to find better solutions.  A branch and bound based scheduler will be provided to the student(s). This tool finds schedules for tasks onto cores and their corresponding modes, schedules of data objects in different memories (on-chip scratchpads, off-chip RAM, flash etc.) and schedules for data transfers on the interconnect. The thesis will investigate the application of bio-inspired techniques to the problem of design-time scheduling exploration. The goal is to propose a fast, scalable and efficient exploration technique for this problem, and to compare the efficiency with the branch and bound based scheduler. The first phase of the thesis will consist of a literature study on evolutionary search heuristics and scheduling for multiprocessor systems. The second phase of the thesis will design and implement search algorithms for this problem. The third phase will use the algorithms for scheduling exploration of multimedia applications (HD video, MP3 player) on a Smartphone platform Texas Instruments OMAP (used in some Smartphones and Tablets from Nokia, Motorola, Sony Ericsson and Samsung). The results of the exploration (speed, scalability and efficiency) will be compared to a baseline of branch and bound based search.  A strong interest in embedded systems.The daily supervision will be partially in English',no_work
'Formele beschrijving van ontwerppatronen voor coordinatie in multi-agent systemen Tom Holvoet Tony VanBeers Tom Holvoet Tom Holvoet Tony VanBeers Ontwerppatronen worden erkend als vooraanstaande instrumenten voor hergebruik van generische oplossingen voor specifieke problemen binnen een bepaalde context [GHJ95]. Patronen beschrijven oplossingen, en ondersteunen bovendien het communiceren van complexe ontwerpen met verschillende belanghebbende partijen. Beschrijvingen van ontwerppatronen blijven echter informeel, wat al te vaak leidt tot ambigu?teit en zelfs verkeerd gebruik van patronen. Hierdoor gaan de voordelen die de patronen met zich meebrengen vaak verloren. Sinds een 15-tal jaar wordt dan ook onderzocht hoe ontwerppatronen meer formeel kunnen beschreven worden, inclusief het beschrijven hoe patronen gecombineerd en geenstantieerd kunnen worden. Een recent boek [T97] bundelt de aanpakken die zijn voorgesteld. Een specifieke verzameling van patronen die binnen de onderzoeksgroep worden bestudeerd zijn patronen voor coordinatie in multi-agent systemen voor het ontwikkelen van grootschalige, gedistribueerde systemen, met specifieke aandacht voor applicatiedomeinen binnen logistiek, verkeer, en slimme elektriciteitsnetten. In het bijzonder worden omgevingsgebaseerde coordinatie-mechanismes bestudeerd, zoals het gebruik van gradient fields, virtuele feromoonsporen, en delegate MAS [WBH08,HV07,HWV09]. Recent werd een eerste poging ondernomen om het delegate MAS coordinatie mechanisme als een set van patronen te beschrijven. Het mag echter duidelijk zijn dat deze informele beschrijving (te)veel ruimte voor interpretatie openlaat, waardoor hergebruik sterk bemoeilijkt wordt. In deze masterproef wordt onderzocht hoe deze patronen op formele manier beschreven kunnen worden. De concrete activiteiten van deze masterproef zijn dan ook:1/ het bestuderen van formalisatie-technieken voor ontwerppatronen2/ het voorstellen van een formele onderbouw voor delegate MAS patronen (incl. het specificeren van de patronen op een formele manier, de integratie en instantiatie van de patronen) - hierbij gaat bijzondere aandacht naar het garanderen van kwaliteitseigenschappen van de oplossingen die door de patronen worden voorgesteld3/ het evalueren van de aanpak door het specificeren van verschillende instantiaties van de delegate MAS patronen (bv. bij oplossingen in de MAS-DisCoSim simulatie-omgeving). Voor dit onderwerp zijn we op zoek naar gemotiveerde studenten met een creatieve maar kritische ingesteldheid, en uiteraard affiniteit voor formele specificatie. Het vak  multi-agent systems  gevolgd hebben is meegenomen maar geen strikte voorwaarde. Kom zeker langs indien je geinteresseerd bent.   [GHJ95] Erich Gamma, Richard Helm, Ralph Johnson and John Vlissides, Design Patterns: Elements of Reusable Object-Oriented Software (ISBN 0-201-63361-2), Addison-Wesley Professional, 1995 [HV07] Tom Holvoet, Paul Valckenaers, Exploiting the environment for coordinating agent intentions, Lecture Notes in Computer Science, volume 4389, pages 51-66, November 2007 [HWV09] Tom Holvoet, Danny Weyns, Paul Valckenaers, Patterns of Delegate MAS. Proceedings of 2009 Third IEEE International Conference on Self-Adaptive and Self-Organizing Systems, San Francisco, California, USA, September 2009 [MASD] http://distrinet.cs.kuleuven.be/software/agentwise/mas-discosim/ [WBH08] Danny Weyns, Nelis Bouck?, Tom Holvoet, A field-based versus a protocol-based approach for adaptive task assignment, Autonomous agents and multi-agent systems, volume 17, issue 2, pages 288-319, October 2008 [T07] Toufik Taibi, Design Patterns Formalization Techniques, IGI Publishing, 2007',no_work
'Een event-gebaseerd communicatieplatform voor mechatronicasystemen Sam Michiels Klaas Thoelen Wouter Joosen Herman.Bruyninckx+mech.kuleuven.be Sam Michiels Klaas Thoelen  Om vlot gebruik te kunnen maken van de beschikbare rolstoelen in een ziekenhuis, zou het handig zijn als deze zich autonoom kunnen begeven naar de kamer van een patient die vervoerd moet worden. De rolstoel wordt hierbij geholpen door camera s in de gangen van het ziekenhuis die het traject van de rolstoel observeren en zonodig bijsturen om deze omheen obstakels te leiden. De huidige stand van zaken binnen de robotica laat dit maar gedeeltelijk toe, en zelfs enkel maar in een zeer statische omgeving waarin alle camera s gekend zijn. Een van de problemen is dat er in de besturingscode van de rolstoel hard-coded staat geprogrammeerd met welke camera s geenterageerd kan worden en op welke manier. De huidige stand van zaken laat bijgevolg niet toe dat er dynamisch nieuwe camera s worden toegevoegd aan het systeem die de rolstoel kan detecteren en vragen voor assistentie.  De uitdaging is om de communicatie tussen een rolstoel en zijn naburige camera s te beheren, zodat er dynamisch connecties opgestart, geconfigureerd en afgesloten kunnen worden. Middleware wordt traditioneel gebruikt om dit soort problemen aan te pakken; de toepassing ervan op mechatronica systemen is echter niet triviaal gezien de verschillen in vereisten qua real-time gedrag, robuustheid en betrouwbaarheid.   Het doel van de thesis is om een middlewareplatform te ontwikkelen dat toelaat om dynamisch de communicatie tussen een robot en een camera te beheren. De thesis evalueert twee bestaande modellen:  Orocos , een componentenmodel voor real-time controle van mechatronica systemen (zonder ondersteuning voor gedistribueerde interacties);  LooCI , een middleware platform voor embedded systemen (zonder ondersteuning voor mechatronicasystemen).  Het platform moet toelaten om communicatieparameters te configureren en logging functionaliteit toe te voegen (om bv. alarmboodschappen te bewaren), zonder de Orocos componenten te moeten wijzigen.   De thesis start met een literatuurstudie van controle software (Orocos, ROS, OpenRTM, OPRoS) en middleware (LooCI, Orca, RTMiddleware) voor mechatronicasystemen. Je werkt samen met experten van FMTC en de departementen Mechanica en Computerwetenschappen om de belangrijkste interactievereisten in kaart te brengen. Je werkt je in in Orocos en LooCI en brengt de voornaamste sterktes en zwaktes in kaart. Op basis van de verzamelde vereisten ontwerp en ontwikkel je een gedistribueerd communicatieplatform voor 2 robots, en je evalueert in hoeverre je prototype tegemoet komt aan de gestelde vereisten. Deze thesis is eerder op industrie georienteerd onderzoek.  Ervaring met Java en C (C++ is een plus), sterke interesse voor embedded systemen. Een brede kennis van gedistribueerde systemen, netwerken en infrastructuur is aangewezen.   Orocos:  http://www.orocos.org/  LooCI:  http://code.google.com/p/looci/  http://people.cs.kuleuven.be/~klaas.thoelen/thesis11-12/index.html',no_work
'Een zelf-controlerende automatische bewijstool voor ongelijkheden en congruence closure Bart Jacobs Bart Jacobs Bart Jacobs Een heleboel hulpprogramma s voor programma-analyse en programmaverificatie, zoals onze eigen verificatietool VeriFast, maken gebruik van een zogenaamde SMT solver, een programma voor het automatisch bewijzen van gelijkheden en ongelijkheden over arithmetica en functiesymbolen. De betrouwbaarheid van de SMT solver is cruciaal voor de betrouwbaarheid van de toepassing. In deze thesis breid je onze bestaande SMT solver genaamd Redux uit met een controlecomponent, geschreven en correct bewezen met het bewijshulpprogramma Coq, die nagaat dat de uitvoer van Redux klopt. Eerst maak je je vertrouwd met O Caml (de programmeertaal waarin Redux geschreven is), met Redux zelf, en met Coq. Dan schrijf je de controlecomponent in Coq, en bewijs je de correctheid ervan. De controlecomponent moet zo geschreven zijn 1) dat hij geexporteerd kan worden naar voldoende performante O Caml-code, en 2) dat je er zo gemakkelijk mogelijk de correctheid van kunt bewijzen in Coq. Deze thesis vereist zowel een aanleg voor theorie als voor implementatie.   O Caml (http://caml.inria.fr/)  Redux is een gedeeltelijke herimplementatie van de SMT solver Simplify (http://www.hpl.hp.com/techreports/2003/HPL-2003-148.pdf)  Coq (http://coq.inria.fr/)  (Onze toepassing: VeriFast (http://www.cs.kuleuven.be/~bartj/verifast/))',no_work
'Hoe veilig zijn online sociale netwerken? Frank Piessens Frank Piessens Lieven Desmet Frank Piessens Online sociale netwerken zoals Facebook en Netlog zijn uitgegroeid totde populairste software toepassingen ooit, maar ze geven ook aanleidingtot belangrijke bezorgdheden op het vlak van veiligheid en privacy,bijvoorbeeld met betrekking tot het lekken van persoonlijke gegevens,cyberstalking en identity theft.Beveiligingsproblemen in OSN s hebben zowel te maken met het feit datdit bijzonder complexe gedistribueerde toepassingen zijn, als met hetfeit dat ze typisch draaien op een onderliggende web infrastructuurdie zelf ook zwakheden bevat. Het doel van deze thesis is om een fundamentele analyse te maken vande veiligheid van OSN s, en om op basis van deze analyse een voorstelte maken voor een aantal beveiligingsmaatregelen. De beveiligings-analyse zal op twee manieren aangepakt worden: enerzijdsdoor het uitvoeren van een threat analyse op een model van een OSN, bvgebruik makend van een methodologie als STRIDE, en anderzijds door eenliteratuurstudie rond de bestaande aanvallen en bedreigingen tegen OSN s.Daarna volgt een ontwerp en een evaluatie van een tegenmaatregeldie een of meerdere van de geidentificeerde beveiligingsproblemenaanpakt. Interesse in ontwikkeling van veilige software en in veiligheid van webapplicaties. Sterke analytische en synthetische skills. Een heel brede intro tot veiligheidsaspecten van OSN s wordt gegeven inhet ENISA rapport over sociale netwerken:http://www.enisa.europa.eu/act/res/other-areas/social-networks/security-issues-and-recommendations-for-online-social-networksDit rapport behandelt zowel sociale als legale als technische aspecten.In deze thesis zal natuurlijk in eerste instantie gefocused worden opde technische aspecten.',no_work
'Een debugger voor het IDP systeem Johan Wittocx Marc Denecker Hanne Vlaeminck Stef DePooter  De enorm toegenomen efficientie van SAT en constraint solvers maakt het mogelijk om steeds meer problemen op te lossen op basis van logische specificaties. Dergelijke systemen worden nu al systematisch gebruikt in verificatie van hardware en software, en worden steeds meer ingezet voor configuratie, scheduling, planning, enz. De studenten die de cursus Modelering van complexe systemen (MCS) hebben gevolgd zijn vertrouwd met een dergelijke state-of-the-art inferentie-systeem: het IDP systeem dat eindige modellen berekent voor (uitbreidingen van) eerste orde logica.  Zoals de meeste studenten wel ondervonden zullen hebben tijdens het practicum van MCS, is het debuggen van foute specificaties toch vaak verre van eenvoudig is. Als de solver besluit dat er geen model is, terwijl de gebruiker er wel een had verwacht, zit er vaak niks anders op dan zin per zin de specificatie te overlopen op zoek naar mogelijke fouten.   Het doel van deze thesis is om het debuggingsproces beter te ondersteunen door 1 of meerdere debuggingtechnieken voor IDP te ontwikkelen. Er zijn verschillende mogelijkheden. Zo bestaan er diverse technieken voor het debuggen van een theorie die tegen de verwachting in inconsistent blijkt te zijn of die te weinig oplossingen heeft. Andere technieken zijn geschikt voor onderzoeken van de correctheid van een model, bv. door het ondervragen ervan.   Het implementeren en evalueren van een debuggingtool voor IDP. De student maakt zich eerst vertrouwd met het werk rond debugging technieken voor logica, alsook met de debugging methodes die ontwikkeld werden voor Answer Set Programming systemen. Vervolgens worden een (of meerdere) van deze methodes geimplementeerd. De tool wordt geevalueerd op verschillende voorbeelden. Interesse voor logica. Kennis van C/C++.   Debugging for Model Expansion, Johan Wittocx, Hanne Vlaeminck and Marc Denecker.  Martin Gebser, Jorg Puhrer, Torsten Schaub, and Hans Tompits. A metaprogramming technique for debugging answer-set programs.  Felix Chang. Alloy analyzer 4.0 (http://alloy.mit.edu/alloy4/), 2007.  Tommi Syrjanen. Debugging inconsistent answer set programs.',no_work
'Een catalogus van patronen voor het objectgericht programmeren  Eric Steegmans Eric Steegmans Eric Steegmans Bij het objectgericht programmeren worden een reeks standaardpatronen toegepast. Voorbeelden hiervan zijn eigenschappen die toegeschreven worden aan objecten en aan klassen. Dergelijke eigenschappen kunnen wijzigbaar of onwijzigbaar zijn, enkelvoudig of meervoudig, ... Voor dergelijke eigenschappen worden o.a. getters, setters en checkers voorzien. Naast eigenschappen worden ook patronen toegepast bij het uitwerken van associaties. Hier zijn variaties mogelijk in de multipliciteit, in de nagivatie, ... Patronen worden ingevoerd om ontbrekende concepten op een gestructureerde manier te ondersteunen in programmeertalen. In deze studie richten we ons in eerste instantie op Java, maar een verruiming naar andere talen behoort tot de mogelijkheden. De eerste doelstelling van deze masterproef is een inventaris op te bouwen van gekende patronen voor het objectgericht programmeren in Java. Dit houdt een volledige en correcte beschrijving in van het patroon, aangevuld met een illustratie ervan in een of andere klasse.  De catalogus zal elektronisch worden aangeboden. Vervolgens moet de software ingenieur ondersteuning krijgen bij het toepassen van dergelijke patronen in de ontwikkeling van Java programma s. Daarbij wordt onderzocht hoe dergelijke patronen kunnen aangeboden worden in Eclipse. In een tweede stap wordt gezocht naar bijkomende patronen. Patronen worden immers ingevoerd om ontbrekende concepten op een gestructureerde manier te simuleren in bestaande programmeertalen. Zo heeft Java geen expliciete ondersteuning voor eigenschappen (properties), en worden ze gesimuleerd door getters en setters. Andere programmeertalen zoals C',no_work
'Evaluatie van GoogleAppEngine en het RESTful integratiemodel voor bedrijfstoepassingen (ism met Cegeka) Adhemar Bultheel Tim.Pijpops+cegeka.be Eddy Truyen Wouter Joosen Eddy Truyen Tim.Pijpops+cegeka.be  Meer en meer toepassingen die we in onze vrije tijd gebruiken worden als een cloud service aangeboden. Denk maar aan de applicaties die Google aanbiedt zoals GMail, Documents en Calendar, maar ook aan Facebook, Twitter, Flickr, en nog een heleboel andere. Toepassingen die van overal en op eender welk device gebruikt kunnen worden, die automatisch meegroeien met de hoeveelheid gegevens die je erin stopt, die frequent nieuwe functionaliteiten aanbieden, met een intuitieve en interactieve web interface, tegen een lage kostprijs en vaak zelfs helemaal gratis.  Het verschil met de meeste toepassingen die vandaag in bedrijven gebruikt worden kan dan ook niet groter zijn: dure pakket- of maatwerktoepassingen waarvan het gebruiksgemak vaak jaren achterloopt op hetgeen we thuis gewoon zijn; upgraden naar een nieuwe versie is meestal een moeizaam proces. Toepassingen ook die de gebruiker in een keurslijf proberen te dwingen, inflexibel zijn en meestal ook enkel te gebruiken binnen het bedrijfsnetwerk.  Een belangrijke categorie van bedrijfstoepassingen is gebouwd rond het concept ?dossier?: het dossier van een werknemer in een bedrijf, het dossier van een zelfstandige bij een sociaal verzekeringsfonds, het dossier van een gedetineerde in een gevangenis, het dossier van een bouwaanvraag bij een overheidsdienst, etc. Dergelijke dossiers moeten beheerd worden door de toepassing (dossiermanagement) en wijzigingen zijn vaak aan bepaalde regels (business rules) onderhevig.  Dikwijls moet het dossier ook een aantal stappen doorlopen die door de toepassing gestuurd worden (workflow) of worden er bepaalde taken gegenereerd die door een dossierbehandelaar afgewerkt moeten worden (takenmanagement). Naast de gestructureerde informatie (bv. signaletische gegevens) bevat een dossier ook bijna altijd ongestructureerde informatie (bv. documenten), die evenzeer snel doorzoekbaar moet zijn (text search). Ten slotte moet er ook gerapporteerd worden over de dossiers heen (business intelligence).  Dergelijke toepassingen worden vandaag bijna altijd als grote (en dus dure) maatwerkoplossingen gebouwd. Daarbij wordt de regie vooral door het systeem gevoerd (bv. gestuurde workflow) en niet door de eindgebruiker. Door de aanzienlijke onderhoudskosten kan dit soort toepassingen ook moeilijk gelijke tred houden met de laatste trends in usability (bv. Ajax) en sociale media (bv. Web 2.0).    Deze thesis heeft als doel om na te gaan of de cloud gebruikt kan worden voor de ontwikkeling en operationalisering van een realistische dossiergebaseerde applicatie door hergebruik te maken van bestaande services (SaaS) en die te combineren met maatwerk ontwikkeling op een cloud platform (PaaS) tot een gedistribueerd, service-georienteerd (RESTful) systeem.  Je onderzoekt welke beperkingen opgelegd worden op het bestaande JEE model door het onderliggende cloud platform (bijvoorbeeld omwille van het CAP theorem). Ook ga je na hoe typische SaaS aspecten als multi-tenancy en federated login gerealiseerd kunnen worden. Tenslotte  bekijk je hoe integratie met Web2.0 toepassingen mogelijk is en dit kan leiden tot meer gepersonaliseerde, flexibelere workflows voor dossiermanagement.    Je analyseert de functionele vereisten (b.v. beschrijving van de vereiste stappen in een workflow voor update van een dossier) en de niet-functionele vereisten (b.v privacy van data)  die representatief zijn voor het typische bedrijfssoftwarepakket voor dossiermanagement.   Je bestudeert het Google cloud platform en gaat na op welke manier deze vereisten gerealiseerd kunnen worden door services van bestaande GoogleApps te herbruiken. Denk bijvoorbeeeld aan Google Calendar feeds voor inplanning van taken, Contacts voor personenbeheer, Mail/Talk voor notificaties, Docs voor opslag en search binnen ongestructureerde informatie, Sites voor informatiesharing, App Engine voor maatwerk, etc.  Je ontwikkelt een proof-of-concept dossiermanagement-toepassing gebruikmakende van het Google cloud platform (Google App Engine) en de services van Google Apps binnen een RESTful integratiemodel.Aan de hand hiervan, valideer je in welke mate het totaalpakket van de vereisten gerealiseerd werd en documenteer je de sterkes en beperkingen van het Google App Engine platform en het RESTful integratiemodel..  Tenslotte ga je na hoe integratie van je toepassing met sociale Web2.0 media kan leiden tot een meer flexibele en gepersonaliseerde workflow.    Zelfstandig kunnen werken aan de analyse, het ontwerp en de implementatie van een softwaresysteem is onontbeerlijk. Verder is een stevige interesse en kennis van gedistribueerde systemen en software architectuur  vereist.    Google Apps, http://www.google.com/apps/  Google App Engine, http://code.google.com/appengine/  Google Apps Script, http://code.google.com/googleapps/appsscript/  Distributed programming the Google way, http://parleys.com/',no_work
'Leren uit Wikipedia Jan Ramon Maurice Bruynooghe Jan Ramon Online fora zoals Wikipedia bevatten veel informatie in een netwerkstructuur.  Tot nu toe spitste onderzoek naar dit soort netwerken zich vooral toe ofwel op het analyseren van de tekst op een pagina, ofwel op het analyseren van de netwerkstructuur zonder veel belang te hechten aan de inhoud (bv. enkel trefwoorden). Het doel van deze thesis is om datastrukturen op te zetten en basisalgorimen om te kunnen redeneren met informatie aanwezig in wikipedia. Belangrijke stappen in de thesis zullen zijn:   Literatuurstudie, o.a. over graph en text mining    Het extraheren van de data aanwezig in wikipedia.   Het definieren van een taal voor een aantal belangrijke concepten en relaties   Het minen van patronen en leren van een predictief model   Evaluatie aan de hand van een aantal benchmark predictietaken.   Interesse in data mining in grote netwerken. Kennis van een scripting taal is een pluspunt tijdens de dataverzameling stap.     Wikipedia    Mining and learning with graphs',no_work
'My Text Meets Wikipedia Ivan Vulic Sien Moens Sien Moens Ivan Vulic  How many times has it already happened to you - while reading a text, you wanted to find more about the specific subject, a phrase, a person, a concept or a historical event teasing your brain. But the procedure is so complicated - you must find the corresponding article in encyclopedia, or spend a lot of time googling etc. Shouldn t it be more convenient if everything is already given to you automatically? Encyclopedias are smart, but  Wikipedia  knows even more. And it?s faster. And interactive.   Wikipedia, being a huge, ubiquitous, pervasive and freely available source of knowledge, gets more and more publicity within the scientific community and many recent natural language processing tools try to utilize it for different tasks.   The goal of this project is to connect any type of a text provided by the end-user and automatically link it to Wikipedia articles strongly associated with the text.   Students will surely have to get to know and describe the main approaches for:   1.  automatic keyword and keyphrase extraction  (extraction of the small key segments from a document which are able to correctly describe its content and meaning).  2.  word sense disambiguation  (identifying which sense of a word (i.e. meaning) is used in a sentence, when the word has multiple meanings, for instance the word bank in both, English and Dutch)  3.  named entity recognition  (locating and classifying atomic elements in text into predefined categories such as the names of persons, organizations, locations etc.).   The final goal is to design a complete system which would do the extraction of the most important keywords and entities and connect them to corresponding Wikipedia pages.   The student is free to choose to work with English or with Dutch texts and Wikipedia articles.   The thesis consists of:  1. Studying the Wikipedia data and metadata structure  2. Studying state-of-the-art approaches for automatic keyphrase extraction, named entity recognition and word sense disambiguation. 2a. Developing student s own methods for natural language processing tasks listed above. 3. Designing and implementing the system that links texts to Wikipedia articles.     A good knowledge of any object-oriented programming language (Java/C++/C',no_work
'Ontwikkeling van een webplatform voor een oefeninggebaseerde leeromgeving Adhemar Bultheel igor.jacques+kuleuven-kortrijk.be stefan.dewannemacker+kuleuven-kortrijk.be  Patrick DeCausmaecker Adhemar Bultheel patrick.decausmaecker+kuleuven-kortrijk.be Adhemar Bultheel igor.jacques+kuleuven-kortrijk.be stefan.dewannemacker+kuleuven-kortrijk.be  De ontwikkeling van het voorgestelde leerplatform kadert in het onderzoek naar e-learning dat gebeurt binnen het computerwetenschappelijke luik van de onderzoeksploeg ITEC te Kortrijk. In deze ploeg werken educatief-technologen en computerwetenschappers samen aan de ontwikkeling van nieuwe educatieve technologieen. Het is in deze context dat de computerwetenschappers van ITEC een state-of-the-art software component ontwikkeld hebben die op autonome basis kan beslissen welke oefening op welk moment het meest geschikt is voor een gebruiker. Dit gebeurt op basis van de verzamelde leerresultaten uit het verleden, alsook op basis van een gedetailleerd gebruikersprofiel waarin onder andere bijgehouden wordt welke leeronderwerpen een gebruiker reeds beheerst. De onderzoeksgroep wil nu in samenwerking met een thesisstudent overgaan tot het effectief inzetten van de beslissingsomgeving met behulp van een online platform. Vooraleer tot de implementatie van dit platform kan worden overgegaan zijn nog een aantal onderzoeksstappen nodig die eveneens in de context van deze thesis zullen plaatsvinden (zie verder).Het te ontwikkelen platform is in elk geval een absolute must om de functionaliteit van onze beslissingscomponent beschikbaar te stellen over het web. Allereerst is het de bedoeling de verschillende oefeningen volledig te modeleren, alsook om te beschrijven welke interacties van de leerder met elke soort oefening mogelijk zijn en hoe deze met behulp van RDF kunnen worden opgeslagen. Vervolgens is het de bedoeling om te komen tot een solide softwareontwerp van een webplatform dat zal instaan voor het presenteren van oefeningen en het verwerken van leerresultaten. Daarna zal het ontwerp geimplementeerd worden om tot een werkend geheel te komen waarmee online geleerd kan worden.  Dankzij de interactie met de eerder vermelde beslissingscomponent, zal de thesis dus uitmonden in een compleet werkend online oefensysteem.  De student zal bij de aanvang van dit thesisproject zich inwerken in ons onderzoeksteam. Op die manier zal hij kennis maken met het opzet van het te ontwikkelen platform, alsook met de verschillende oefeningentypes. Vervolgens dienen de verschillende oefeningentypes te worden gemodelleerd, dat wil zeggen dat alle presentatie-elementen in kaart worden gebracht, alsook alle mogelijke interacties. (4 weken)Eveneens bij de aanvang zal de student zich inwerken in RDF, een Semantic Web taal voor kennisrepresentatie die als alternatief voor een relationele database gebruikt zal worden. Het webplatform dient immers alle interacties van de leerder met elke oefening, alsook de leerresultaten vast te leggen. Dit gebeurt in RDF volgens een bepaald opslagformaat dat reeds deels ontworpen werd, maar dat de student verder zal verfijnen voor elke oefening. Dit gedeelte kan als onderzoeksgedeelte worden beschouwd. Het werken met RDF als vorm van kennisrepresentatie vormt in elk geval een integraal onderdeel van deze thesis. (4 weken)Om tot het gewenste webplatform te komen zal een derde deel van dit eindwerk erin bestaan een grondig ontwerp te maken van de nodige software componenten. Dit ontwerp omvat ook de bepaling van welke programmeertalen voor welk gedeelte van de software gebruikt zullen worden. De interface van het platform met de beslissingscomponent zal in onderling overleg worden vastgelegd. (6 weken)In een derde deel zal het webplatform geimplementeerd worden. Dit zal, naast andere te kiezen webgebaseerde technologieen, de kennis vereisen van JavaScript. Kennis over deze talen kan in de loop van het thesisproject worden opgedaan. (12 weken) interesse in Semantic Web (RDF) en web programmeren',no_work
'Implementatie van een nieuw state-of-the art algoritme voor spectraal berekeningen  Raf Vandebril Raf Vandebril Raf Vandebril In dit onderwerp wordt een nieuw algoritme voor spectraalberekening voor matrices geimplementeerd in een hogere programmeertaal en wordt dit algoritme op een gedetailleerde wijze vergeleken met het bestaande LAPACK alternatief.CONTEXT (Info over het probleem, ev. info over het onderzoeksproject waarin deze masterproef kadert)Het berekenen van eigenwaarden en singuliere waarden van matrices is een frequent voorkomend probleem. Er bestaan zowel standaardtechnieken die toepasbaar zijn op alle type matrices of zeer specifieke, vaak snellere, technieken die enkel op bepaalde klassen van matrices werken.Er zijn twee mogelijkheden, waaruit de student kan kiezen. De opzetblijft hetzelfde: het implementeren van een nieuw algoritme en vergelijkenmet de state-of-the-art. Enkel het onderliggende probleem verschilt,voor onderwerp (1) focussen we op normale matrices, onderwerp (2)focust op algemene niet-symmetrische matrices.   Voor enkele deelklassen van de normale matrices zoals de (scheef) symmetrische en unitaire matrices bestaan er reeds snelle algoritmen. Voor de algemene klasse van normale matrices bestaat dit echter nog niet. Recent is er een nieuwe techniek voor normale matrices die gebruikt maakt van complex symmetrische matrices. In dit thesisonderwerp gaan we dienieuwe technieken implementeren en analyseren.   Recent is er een nieuw algoritme ontwikkeld dat het welbekendeQR-algoritme (top 20 algoritme van de 20ste eeuw) veralgemeend,gebruikmakend van factorizaties in rotaties.  Er bestaat enkel eenMatlab implementatie van dit algoritme en geenefficiente, snelle implementatie. In dit onderwerp gaan we ditnieuw algoritme implementeren en analyseren.   Het doel van de thesis is licht theoretisch, maar vooral meerpraktisch gericht op implementeeraspecten. De bestaande nieuwealgoritmen worden geimplementeerd en vergeleken met de software vanLAPACK. Er wordt dan een analyse gemaakt van deze nieuweimplementatie, m.b.t. geheugen, snelheid, .... De student bestudeert het state-of-the-art algoritme dat de basis vormt voor deeigenwaardeberekening in LAPACK. Hij implementeert de nieuwemethodes op even verfijnde wijze, en kan dan een duidelijkevergelijking maken van de verschillende implementaties. De student is vertrouwd met de basis van numeriek lineaire algebra. De student is geinteresseerd in implementeren en vergelijkingen van algoritmen.',no_work
'Event-B and de integratie van NuSMV en IDP Hanne Vlaeminck Marc Denecker Hanne Vlaeminck  Several languages and inference methods have been developed to specify dynamic systems and perform different kinds of verifications and simulations on these specifications. One of these systems is the Event-B language and the ProB system. The ProB system is an animator and model checker for specifications written in the B language and allows fully automatic animation of many event-B specifications, and can also be used for model finding, deadlock checking and test-case generation. The ProB system takes as an input a system specification in event-B that basically describes the preconditions and effects of actions on system variables. The system can perform  various forms of verification and inference on such specifications:  it can automatically simulate  the specification (for simulation, planning, etc),    it can be used to prove invariants of the specification,    it can be used to dynamically or statically create the state graph of the system, yielding a  finite state machine (FSM), which in turn can be used for various other tasks:     computing reachability or non-reachability of states,     computing deadlocks of the system or proving deadlock freeness,     computing CTL or LTL queries on the FSM.    The ProB system is implemented in Prolog. Nevertheless, the system achieves good performance and is currently used for industrial applications e.g., for verifying metro systems produced by Siemens.   There is a strong overlap between the above languages, systems and functionalities and languages such as FO(.) and the Linear Time Calculus, IDP, and the NuSMV system that you  studied in the course Modelling of Complex systems. In fact, the ProB system demonstrates that it is possible  to integrate the functionatities  and languages of IDP and NuSMV and build industrially useful systems.  The goal of this thesis is   to compare the Event-B language with Linear Time Calculus (LTC) in FO(.),    to extend IDP with verification tools of the kind provided in ProB, i.e. one that can construct the FSM of a dynamic system that is specified in a FO(.) theory (e.g., in the form of a Linear Time Calculus) and offer some of the most important functionality that the ProB system offers, such as simulation, invariant checking and deadlock checking.    The first part of this thesis will consists of a study of the Event-B language and its relation to LTC. Next, we expect the student to develop a suitable representation of Event-B specifications in FO(.), and finally to build tools. The goal is to use the IDP system for the inference tasks we identified above. Recently the IDP system has been integrated with the LUA scripting language, a language for fast prototyping. To evaluate the tool we can use e.g. the examples from the ProB-website. Interested in formal verification methods, logic, algorithms, implementation.   ProB webpage  Tutorial on ProB  IDP webpage',no_work
'Beheer lokaal je profiel met je persoonlijke data Kristof Verslype Bart DeDecker Kristof Verslype In toenemende mate houden allerlei bedrijven en instellingen in gegevensbanken uitgebreide profielen met onder meer je aankoopgedrag bij. Voorbeelden zijn online boek- en muziekhandels. Deze profielen zijn gekoppeld aan een identificeerbare persoon. Dit leidt enerzijds tot een bedreiging van de privacy van de gebruiker en anderzijds zal zo n gegevensbank met vaak tienduizenden of meer klantenprofielen een geliefd doelwit zijn voor aanvallers, zowel van binnenuit als buitenaf. Het kan dus  in het belang van zowel de gebruiker als het bedrijf zijn dat dit op een anoniemere, gedistribueerde manier gebeurt. et idee achter de thesis is dat de gebruiker anoniem of onder een pseudoniem de service provider  (de online winkel) contacteert. Hierbij houdt de gebruiker domeinspecifieke gegevens bij, die door service providers geconsulteerd kunnen worden. Deze profieldata kan door service providers bevraagd worden binnen de beperkingen opgelegd door de policy van de gebruiker. Een voorbeeldje zal dit verduidelijken. De gebruiker zou anoniem boeken kunnen kopen bij verschillende eCommerce sites. Lokaal houdt de gebruiker bij welke boeken hij reeds gekocht heeft in welke hij geinteresseerd is. Een set van eCommerce sites krijgt van de gebruiker het recht dit profiel te bevragen, mits beperkingen. Zo zou amazon.com het recht kunnen krijgen na de aankoop van een boek door de gebruiker om gegevens over dit boek aan het profiel toe te voegen. Ook krijgt amazon.com het recht de bij de gebruiker populairste auteurs van fictie boeken te zien die in het profiel staan. Op basis daarvan kan amazon.com dan suggesties doen naar de gebruiker toe. Anderzijds krijgt amazon.com niet te zien welke medische boeken de gebruiker gekocht heeft, aangezien dit te gevoelige informatie zou prijsgeven. Het spreekt voor zich dat zo n profiel niet enkel met een policy beschermd wordt, maar dat er ook gebruik gemaakt wordt van cryptografische bouwblokken zoals encryptie en authenticatie om een optimale bescherming te garanderen. Dit alles zal geentegreerd worden in een aan het departement ontwikkeld raamwerk. Concreet ontwikkel je zo n lokale profielbeheercomponent. Daarbij vertrek je van een aantal scenario s die je deels zelf zult uitwerken. In tweede instantie zal deze component geentegreerd worden in een reeds bestaand raamwerk dat intern werd ontwikkeld. Een policy zal ontwikkeld worden als onderzoeksdeel van de thesis. De student is gemotiveerd en in staat zelfstandig een aantal scenario s uit te werken en op basis daarvan een conceptueel model, alsook een policy uit te werken.    Deze thesis omvat niet zoveel literatuurstudie. De student zal zich vertrouwd moeten maken met anonieme credentials en met het raamwerk.',no_work
'Een flexibele policy component in een privacyondersteunend raamwerk Kristof Verslype Bart DeDecker Kristof Verslype Een credential is een set van attributen, meestal persoonlijke gegevens van de gebruiker, ondertekend door een vertrouwde derde partij. Er zijn flexibele, privacy-vriendelijke credentialsystemen ontwikkeld door IBM en Microsoft. Deze laten toe eigenschappen van de attributen te bewijzen aan een andere partij, terwijl de rest van de informatie in het credential verborgen blijft voor die partij. Zo is het mogelijk enkel te bewijzen dat je ouder bent dan 18 met behulp van zo n credential dat bijvoorbeeld je postcode, geboortedatum en naam bevat.Binnen het departement werd een raamwerk ontwikkeld dat mechanismen aanbiedt om de privacy van de gebruiker te verbeteren wanneer hij interageert met externe service providers en daarbij gebruik maakt van dergelijke credentials. In dit raamwerk zijn er verschillende componenten: een voor de opslag, een voor de communicatie, een voor het gebruik van de credentials, etc. In dit raamwerk is er nood aan een policy ondersteuning (d.i. PEP, PDP, PIP, ...) dat beslist aan de hand van. de beschikbare policies of een bepaalde actie die een van de componenten wil uitvoeren al dan niet toegelaten is.  Het doel van de thesis is het ontwikkelen van een policy decision point (PDP) component  in een bestaand privacy raamwerk. De verschillende componenten (opslagcomponent, privacycomponent, credentialcomponent, etc.) van het raamwerk hebben elk nood aan hun eigen policies. De policies op zich kunnen sterk verschillen, maar toch zou een policy component ontwikkeld moeten worden die een uniforme interface aanbiedt zodat het door de verschillende andere componenten makkelijk en op een gelijkaardige manier gebruikt kan worden. In die policy component moeten verschillende types policies ingeplugd kunnen worden. De policy component bekijkt bij een autorisatieaanvraag uiteraard enkel de relevante policies. Ook is het zo dat het mogelijk moet zijn ondersteuning voor verschillende policytalen in het raamwerk te voorzien.  De student zal eerst een op een hoog niveau inzicht moeten krijgen in de policies die in het raamwerk nodig zijn. Initieel zullen een aantal eenvoudige policies beschouwd worden en later wat complexere. Aan de hand daarvan wordt een policy component ontworpen en geimplementeerd. Deze policy component moet op een uniforme manier door de verschillende raamwerk componenten gebruikt kunnen worden om te weten te komen of een bepaalde actie al dan niet toegelaten is. Daarna, of deels in parallel met het voorgaande, wordt een policytaal uitgewerkt voor de credential component (de component die de functionaliteit voor het gebruik van credentials voorziet). Ondersteuning voor deze policytaal wordt geimplementeerd en in de policy component ingeplugd. Ten slotte worden de policies gevalideerd aan de hand van een reeds bestaande, uit te breiden applicatie.  De student is gemotiveerd en in staat zelfstandig te werken. Zo moet de student bijvoorbeeld in staat zijn een degelijk ontwerp te maken.  De student zal vertrouwd moeten worden met de mogelijkheden van anonieme credentials, met de design principes die gehanteerd worden wanneer van policies gebruik gemaakt wordt. Ten slotte zal de student zich vertrouwd moeten maken met het raamwerk.',no_work
'Hoe anoniem ben ik na het bewijzen van persoonlijke informatie? Kristof Verslype Bart DeDecker Kristof Verslype Een credential is een set van attributen, meestal persoonlijke gegegevens van de gebruiker, ondertekend door een vertrouwde derde partij. Zo zijn er bijvoorbeeld de klassieke X.509 certificaten, die, helaas, helemaal niet privacy vriendelijk zijn. Er zijn ook meer flexible, privacy-vriendelijke credentialsystemen ontwikkeld door IBM en Microsoft. Deze credentialsystemen laten toe eigenschappen van de attributen te bewijzen aan een andere partij, terwijl de rest van de attribuutinformatie verborgen blijft voor die partij. Zo is het mogelijk enkel te bewijzen dat je ouder bent dan 18 met behulp van zo n credential dat bijvoorbeeld je postcode, geboortedatum en naam bevat.. Hoewel dit duidelijk een verbetering is t.o.v. X.509 certificaten waarbij sowieso alle attributen prijsgegeven worden, blijft de gebruiker in het ongewisse wat betreft zijn graad van anonimiteit als hij bepaalde persoonlijke eigenschappen prijsgeeft. Een eerste theoretisch voorstel om de gebruiker te informeren over zijn anonimiteit t.o.v. service providers werd al uitgewerkt. Het doel van de thesis is om dit om te zetten in een concreet, werkend systeem en om dit te integreren in een raamwerk dat aan het departement werd ontwikkeld.  De student maakt een flexibel ontwerp en integreert dit in het raamwerk. Daarna wordt een implementatie gemaakt. Als uitbreiding zullen de metrieken die deze component genereert gebruikt worden in policies (vb. de anonimiteit t.o.v. een bepaalde service provider mag niet onder een bepaalde waarde zakken). Motivatie is zoals steeds een eerste vereiste. Deze thesis is eerder implementatiegericht. De student mag dus niet afgeschrikt worden door wat programmeerwerk. De student begint met het doornemen van relevante literatuur over anonieme credentialsystemen en over de voorgestelde oplossing om de anonimiteit van de gebruiker te meten. Eventueel zal er ook gekeken worden naar andere privacy metrieken.',no_work
'Learning the typical order of life events from Twitter streams Steven Bethard Sien Moens Steven Bethard Steven Bethard Humans have a lot of commonsense knowledge about life events: you typically have breakfast before you have lunch, you typically get married before you get divorced, etc. Yet this kind of real-world knowledge is not currently available in any machine-usable form. Twitter provides a unique opportunity to automatically acquire some of this real-world knowledge by applying text mining techniques to tweets: short timestamped texts describing life events that are available on a massive scale. The student will study existing techniques for acquiring event ordering knowledge, develop a new approach based on Twitter streams, and produce a new database of statistical event ordering information. The student will have to:1) familiarize themselves with current approaches for learning event ordering models2) learn the Twitter API and how to manage large volumes of tweet data3) design methods for filtering and parsing tweets to identify just those that describe routine events4) build a statistical model of event ordering based on the collected events5) evaluate the resulting event ordering database on a temporal order prediction task (e.g. TempEval 2010). The student should be familiar with the basics of interacting with web services and with collecting word statistics from text. Some experience with machine learning models is also recommended.  Nathanael Chambers and Dan Jurafsky,  Unsupervised learning of narrative schemas and their participants , Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP (Suntec, Singapore), Association for Computational Linguistics, August 2009, pp. 602?610. http://www.aclweb.org/anthology/P09-1068  Timothy Chklovski and Patrick Pantel,  Verbocean: Mining the web for ?ne-grained semantic verb relations , Proceedings of EMNLP 2004 (Barcelona, Spain) (Dekang Lin and Dekai Wu, eds.), Association for Computational Linguistics, July 2004, pp. 33?40.  Michaela Regneri, Alexander Koller, and Manfred Pinkal,  Learning script knowledge with web experiments , Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics (Uppsala, Sweden), Association for Computational Linguistics, July 2010, pp. 979?988.  Takeshi Sakaki, Makoto Okazaki, and Yutaka Matsuo,  Earthquake shakes Twitter users: real-time event detection by social sensors , Proceedings of the 19th international conference on World wide web (New York, NY, USA), WWW ?10, ACM, 2010, pp. 851?860.  Marc Verhagen, Roser Sauri, Tommaso Caselli, and James Pustejovsky,  Semeval-2010 task 13: Tempeval-2 , Proceedings of the 5th International Workshop on Semantic Evaluation (Uppsala, Sweden), Association for Computational Linguistics, July 2010, pp. 57?62.',no_work
'Een Eclipse plugin voor het sturen van adaptief gedrag in component-gebaseerde applicaties Davy Preuveneers Yolande Berbers Davy Preuveneers Dynamische component-gebaseerde applicaties kunnen zichzelf aanpassen wanneer de omstandigheden dit vereisen. Zo kan een intelligente multimedia speler op je smartphone beslissen om bepaalde streaming-componenten voor online music uit te schakelen wanneer de batterij bijna leeg is. Dergelijk adaptief gedrag wordt vaak gemodelleerd a.d.h.v. event-condition-action regels. Zo kan een applicatie via events op de hoogte gebracht worden van het batterijverbruik, en zal, als een kritische grenswaarde bereikt wordt, een actie ondernomen worden om bvb. een component van de applicatie stil te leggen of eventueel te verhuizen naar een ander toestel. We wensen in deze thesis applicatie-specifieke situaties en adaptatie-regels te modeleren (bvb. performantie problemen, batterij kritisch, voorkeuren gebruiker) die het adaptief gedrag en de herconfiguratie zullen sturen (component toevoegen, weglaten, verhuizen naar een ander toestel en/of parameters aanpassen). Tussen deze regels kunnen afhankelijkheden of zelfs inconsistenties optreden. Bijvoorbeeld, een eerste regel specifieert dat het volume automatisch moet verhoogd worden wanneer je smartphone een van je favoriete songs speelt; een tweede regel specifieert dat het geluid zachter moet op openbare plaatsen zoals de bibliotheek om geen mensen te storen. Deze regels zullen meestal wel werken, behalve wanneer ze samen optreden. Op dat ogenblik is het niet duidelijk welk volume vereist is. Dit maakt het moelijk om te bepalen welke herconfiguratie optimaal is.  Het doel van deze thesis is een Eclipse-plugin te ontwikkelen die een softwareontwikkelaar het mogelijk te maakt om mogelijke herconfiguraties van component-composities te beschrijven a.d.h.v. adaptatie-regels en om met Eclipse inconsistenties in deze adaptatieregels te analyzeren. Enkele uitdagingen omtrent het voorstellen van adaptief gedrag met regels zijn:  Conflicterende condities:  sommige regels treden samen op omwille van overlappende condities, maar kunnen conflicterend adaptatief gedrag initieren  Conflicterende acties:  regels met onafhankelijke condities kunnen leiden tot incompatiebele acties, of het initieren van andere regels met mogelijk ongewenste lussen als gevolg    De eerste fase van de thesis zal bestaan uit een literatuurstudie omtrent component-gebaseerde applicaties en regelgebaseerd adaptief gedrag. In een tweede fase zal men een Eclipse-plugin ontwerpen en implementeren dat ontwikkelaars toelaat het adaptief gedrag te modeleren en om inconsistenties in de regels te analyzeren. Het raamwerk moet toelaten om:  mogelijke inconsistenties in de condities en de acties van de regels te visualizeren  om conflicten op te lossen door bvb. het introduceren van prioriteiten of het aanpassen van de regels om zo het adaptief gedrag van de applicatie te corrigeren   Theorie in combinatie met een praktische implementatie.   Chisel: A Policy-Driven, Context-Aware, Dynamic Adaptation Framework  Een uitgebreidere literatuurlijst volgt bij de start van de thesis.',no_work
'Reliable concurrency using real time capacity planning. PedroJavier delCidGarcia Wouter Joosen PedroJavier delCidGarcia In order to achieve the visions of smart dust, sensor clouds and commercially viable WSN deployments:  we are currently investigating multi-purpose WSNs. In these deployments, the network is viewed as a light weight service infrastructure to be exploited by multiple concurrent applications. The main characteristics are: mobile and resource constraint devices, large scales, heterogeneity, high degrees of concurrency and no inter-application coordination.  We are currently working with industrial partners in Belgium and based on their functional and technological requirements we have designed a middleware architecture that provides enhanced support for uncoordinated, concurrent use of the limited sensor resources. The architecture defines a meta-level for resource usage configuration, real time capacity planning and localized autonomic adaptation.  Capacity planning is one of the most critical responsibilities in the management of an infrastructure to ensure that adequate resources are planned for and provided. However, in our context predicting future workloads is not feasible, making the case for a run-time approach. You will design and evaluate resource allocation strategies to be executed in the capacity planning module of our middleware.  You will focus on the allocation of three critical resources in Wireless Sensor Networks (WSNs) mainly; (i) memory usage both RAM and FLASH (ii) energy usage due to sensor invocation and (iii) energy usage in transmission. (specifically transmission related to application usage not network traffic).You will first perform an investigation into the current state of the art on allocation strategies to properly fundament the selection of various promising alternatives. An implementation of the aforementioned middleware is needed for the AVR Raven platform. The selected strategies must be implemented and executed on the capacity planning module of the middleware and a baseline performance evaluation of each one should be done. This evaluation should be done following an existing evaluation protocol to generate adequate performance benchmarks. After concluding the benchmarking and based on this data, you perform a trade-off analysis that should indicate when each of the strategies should be used, given that under different system conditions each strategy will likely perform differently.  You will have 4 goals: 1)	Analysis of the state of the art of resource allocation strategies. 2)	Implementation of the provided middleware architecture in the AVR Raven platform.3)	Design, implementation and benchmarking of various resource allocation strategies.4)	Trade-off analysis that should indicate when each of the strategies should be used. Given that under different system conditions each strategy will likely perform differently.  Theoretical:You will perform an analysis of the state of the art in resource allocation strategies. A comprehensive literature list will be provided. Based on this analysis you will select various promising resource allocation strategies to be evaluated.  After the implementation and benchmark you will perform an analysis of the trade-offs in the use of each strategy. Implementation: An existing middleware architecture must be implemented on the AVR Raven platform, you may use the LooCI component infrastructure. You will implement various resource allocation strategies. A performance benchmark for each strategy should be done that evaluates several criteria for each of the critical resources aforementioned.  You are interested in considering a research career either in industry or academia. This thesis is designed to provide critical insight into the essential skills needed to succeed as a scientific researcher; mainly research, analysis, prototype implementation and publication of results. You are a self-motivated student with a strong interest in large scale distributed systems. Much of this work consists of practical research and development with real sensor hardware, but the work will also require critical insight. A creative attitude is certainly an advantage because the domain of capacity planning in large-scale distributed systems like sensor networks is relatively new. You will work in a clearly defined research space which will be designed to optimize your research output and results. Experience with C is an advantage. Are you interested? Please be sure to contact the contacts for a brief interview. http://spots.dev.java.net/ http://www.sics.se/contiki/ http://www.atmel.com/dyn/products/tools_card.asp?tool_id=4395',no_work
'Design patterns voor coordinatie in multi-agent systemen Tom Holvoet Tony VanBeers Tom Holvoet Tom Holvoet Tony VanBeers Coordinatie vormt een cruciale uitdaging bij het bouwen van een multi-agent systeem. Agenten werken samen om de objectieven van een gedistribueerd systeem te bereiken. Individuele agenten hebben een lokale kijk op het systeem en dienen gelijktijdig samen te werken met potentieel een groot aantal andere agenten. In de literatuur wordt coordinatie uitvoerig beschreven. Ontwerppatronen worden erkend als vooraanstaande instrumenten voor hergebruik van generische oplossingen voor specifieke problemen binnen een bepaalde context [GHJ95]. Patronen beschrijven oplossingen, en ondersteunen bovendien het communiceren van complexe ontwerpen met verschillende belanghebbende partijen. In de onderzoeksgroep DistriNet wordt onderzoek gedaan naar coordinatie in grootschalige, gedistribueerde systemen, met specifieke aandacht voor applicatiedomeinen als logistiek, verkeer, en slimme elektriciteitsnetten. In het bijzonder worden omgevingsgebaseerde coordinatie-mechanismes bestudeerd, zoals het gebruik van gradient fields, virtuele feromoonsporen, en delegate MAS [WBH08,HV07,HWV09]. Recent werd een eerste poging ondernomen om het delegate MAS coordinatie mechanisme als een set van patronen te beschrijven. Het mag echter duidelijk zijn dat een meer rigoureuze beschrijving van deze patronen evenals een integratie van de patronen met andere gekende patronen voor multi-agent systemen noodzakelijk zijn om de herbruikbaarheid van de mechanismes ten volle te ondersteunen. De belangrijkste taken in deze masterproef zijn dan ook: 1/ het categoriseren van relevante patronen zoals beschreven in de literatuur (o.a. [KKP98,SD98,W03]), en het identificeren van relaties tussen patterns 2/ het nagaan op welke manier het hergebruik van deze patronen het best kan ondersteund worden (hetzij via typische OO-technieken zoals overerving, delegatie, of via components of specifieke taalconstructies. 3/ het evalueren van dit hergebruik door te experimenteren met (een aantal van) deze patronen binnen de  MAS-DisCoSim  simulatie-omgeving. Voor dit onderwerp zijn we op zoek naar gemotiveerde studenten met een creatieve maar kritische ingesteldheid. Het vak  multi-agent systems  gevolgd hebben is meegenomen maar geen strikte voorwaarde. Kom zeker langs indien je geinteresseerd bent.   [GHJ95] Erich Gamma, Richard Helm, Ralph Johnson and John Vlissides, Design Patterns: Elements of Reusable Object-Oriented Software (ISBN 0-201-63361-2), Addison-Wesley Professional, 1995 [HV07] Tom Holvoet, Paul Valckenaers, Exploiting the environment for coordinating agent intentions, Lecture Notes in Computer Science, volume 4389, pages 51-66, November 2007 [HWV09] Tom Holvoet, Danny Weyns, Paul Valckenaers, Patterns of Delegate MAS. Proceedings of 2009 Third IEEE International Conference on Self-Adaptive and Self-Organizing Systems, San Francisco, California, USA, September 2009 [KKP98] Elizabeth A. Kendall, P. V. Murali Krishna, Chirag V. Pathak, C. B. Suresh, Patterns of intelligent and mobile agents, In Proc. of the second international conference on Autonomous agents, 1998 [MASD] MAS-DisCoSim [SD98] Alberto Silva, Jos? Delgado, The Agent Pattern: A Design Pattern for Dynamic and Distributed Applications. In Proceedings of the EuroPLoP???98, Third European Conference on Pattern Languages of Programming and Computing, 1998 [WBH08] Danny Weyns, Nelis Bouck?, Tom Holvoet, A field-based versus a protocol-based approach for adaptive task assignment, Autonomous agents and multi-agent systems, volume 17, issue 2, pages 288-319, October 2008 [W03] Weiss, A Pattern Language for Motivating the Use of Agents, LNCS 3030, 2003',no_work
'Monitoring and resource usage enforcement in the sensor cloud  Jef Maerien Christophe Huygens Wouter Joosen Jef Maerien Draadloze sensornetwerken (DSNs) gaan een grote contributie te leveren aan the Internet of Things, waarbij de virtuele wereld met de reele wereld gekoppeld wordt. Dit biedt enorm veel potentieel voor allerhande applicaties gaande van eenvoudige toepassingen om milieufenomenen op te volgen, tot complexe cross-domain applicaties zoals het opvolgen van producten in de logistieke keten. Door de grootschaligheid van het netwerk, heterogeniteit van aanwezige hardware, en enorme dynamiek, is het beheer van dergelijke infrastructuur niet eenvoudig. Het is daarom belangrijk om ten allen tijde inzicht te krijgen in de goede werking van de knopen en het verbruik van de applicaties in het netwerk.In vele toepassingen zullen de sensornetwerken ook gedeeld worden door verschillende partijen die elk hun eigen ?applicatie? draaien op het sensor netwerk. Een applicatie bestaat uit verschillende componenten die op verschillende sensor knopen draaien. Deze applicaties verbruiken de resources van de sensor knopen, zoals energie maar ook file system, RAM, etc.. Omdat applicaties typisch gedistribueerd over meerdere knopen draaien, is het moeilijk om een accuraat zicht te krijgen op het werkelijke verbruik van een specifieke applicatie. Daarom zijn er ook verschillende strategieen voorhanden om te gaan monitoren: alles doorsturen op bepaald tijdstip, lokaal verwerking op de node of aggregatie van de data over verschillende knopen. Iedere strategie heeft meetbare karakteristieken m.b.t. resource en communicatie vereisten, maar ook indirecte karakteristieken die een grote invloed kunnen hebben op de gehele levensduur van het sensornetwerk (zoals ten allen tijde een consistente view op het netwerk hebben vs. een licht verouderde view,...).Naast het opvolgen, is het ook belangrijk om het verbruik van gedistribueerde applicaties te kunnen beperken. Bijvoorbeeld een gedistribueerde applicatie mag slechts 50 kB ram en 100 kB file storage gebruiken over het ganse sensor netwerk. Er zijn opnieuw enkele mogelijke strategieen om dit probleem op te lossen: Zet je een default policy over alle knopen waarbij de applicatie op elke knoop een evenredig deel mag verbruiken, wat zwaardere componenten te weinig resources geeft en de lichtere te veel, of kijk je eerst naar het verbruik en grijp je pas in wanneer je duidelijk ziet dat de policy wordt overtreden en enkel daar waar nodig.  In deze thesis zul je aan de hand van een use case de te monitoren resources (RAM, file system, sensor services,?) en non functional concerns (security, performantie, accuraatheid en freshness van data,...) defini?ren. Vervolgens zal je een aantal geschikte monitoring strategieen ontwerpen. Je kiest een of meerdere strategieen, implementeert deze op echte sensor hardware, en voert een evaluatie uit. Dit zal ongetwijfeld leiden tot interessante conclusies en nieuwe inzichten in het domein m.b.t. de kosten baten analyse van monitoring en enforcement binnen grootschalige gedistribueerde systemen zoals sensornetwerken.   Literatuurstudie van monitoring en enforcement in gedistribueerde (embedded) systemen  Analyse van vereisten in een typische realistische applicatie  Ontwerp van 1 of meerdere strategieen  Implementatie op echte sensor hardware zoals SunSPOT of AVR Raven motes.  Evaluatie van de geimplementeerde monitor strategieen: analyse, trade-offs, en besluitvorming    Je bent een zelfstandige en gemotiveerde student met een sterke interesse in grootschalige gedistribueerde systemen. Een groot deel van deze thesis bestaat uit praktisch onderzoeks- en ontwikkelingswerk met echte sensor hardware, maar de evaluatie zal ook een zeker kritisch inzicht vereisen. Een creative ingesteldheid is zeker ook een pluspunt aangezien het domein van monitoring in grootschalige gedistribueerde systemen zoals sensornetwerken vrij nieuw is. Je zal bijgevolg ontdekken dat er enorm veel mogelijkheden zijn, wat veelal een vrije invulling van bepaalde elementen in deze thesis toelaat. Ervaring met C is een voordeel maar niet noodzakelijk.   http://www.sunspotworld.com/  http://spots.dev.java.net/  http://www.sics.se/contiki/  http://people.cs.kuleuven.be/~klaas.thoelen/thesis11-12/index.html',no_work
'Hand gesture detection and recognition Laura Antanas Wannes Meert Luc DeRaedt Laura Antanas Wannes Meert In human-computer interaction (HCI), the use of hand gestures is an attractive alternative to the keyboard. Among others, one of its main advantages is that it is more natural and therefore requires no or little practical training.  Such a type of human-computer interaction  is perfectly suitable for applications targeted to young children that have no or limited reading experience. In the DTAI research group a rock-scissors-paper playing robot is being developed as an educational tool to introduce artificial intelligence to children. The main way of interfacing with the computer is by hand detection and correct gesture recognition. It is a challenging task to create a robust hand recognition system that is capable of recognizing a broad range of hands under changing lightning conditions. Of great importance in the last past years, a natural and larger scale extension of this application is the automatic language sign recognition. Except the hand detection part, the sign recognition and translation is augmented in complexity by many more finger configurations. These configurations are used for finger-spelling, that is spell words letter by letter. A first goal of this thesis is to improve the current (naive) hand recognition implementation used in the rock-scissors-paper playing robot. There are two phases that need to be improved, first the detection of a hand in the camera image. Second the recognition of the gesture of the hand. A secondary goal is to have a trained robot which can recognize not only rock, scissor and paper gestures, but also other shapes. This can be, for example, a (simplified) sign language.  We propose to approach this problem by learning from examples, such that the interface can be naturally used also for other games and applications.    Investigate current approaches, solutions, and implementations that can be useful for this problem.  Implement a prototype (or use an existing framework) to perform hand detection.  Extend the prototype such that it also classifies/recognizes hand gestures.  Experiment with the prototype to see how many gestures your implementation can handle and how accurate it is.  Interest in machine learning and image processing. Toolboxes are in C++, therefore knowledge of C++ is required (no expert knowledge required).    S. Mitra, T. Acharya, Gesture Recognition: A Survey, IEEE Transactions on Systems, Man, and Cybernetics?part C: Applications and Reviews, Vol. 37, No. 3, May 2007  Pragati Garg, Naveen Aggarwal and Sanjeev Sofat, Vision Based Hand Gesture Recognition, 2009 - Huaqiang Jiang, Huosheng Hu, Self-directed-Learning for Sign Language Recognition, 2009   Thang B. Dinh  Van B. Dang  Duc A. Duong  Tuan T. Nguyen  Duy-Dinh Le, Hand gesture classification using boosted cascade of classifiers, 2006.   TLD   (+ related explanatory papers)   HandVu  (+ related papers on the website)',no_work
'Investigating Prolog Based Unit Test Frameworks Theofrastos Mantadelis Gerda Janssens Theofrastos Mantadelis pmoura+di.ubi.pt A very well-known method for testing the correctness of programs is unit testing. While it is common practice for imperative and object-oriented programming languages, it is not so widely used for declarative programming languages. We want to establish a unit test framework for Prolog. he aim is to investigate which features are needed to support unit testing in Prolog and to check whether the existing Prolog unit test frameworks support the required features. Finally the thesis aims at defining a declarative logic modelling representation for unit tests of Prolog programs and the implementation of the chosen novel features.   Familiarize with some well known imperative unit test frameworks.  Familiarize with the existing Prolog unit test frameworks.  Define the required features for a Prolog unit test framework.  Define a declarative logic representation for unit tests.  Implement the chosen novel features.   Interested in Prolog, program analysis, programming principles, unit tests.   Francois Degrave, Tom Schrijvers, and Wim Vanhoof - Automatic Generation of Test Inputs for Mercury. LOPSTR 2008.  Peter Biener, Francois Degrave, Wim Vanhoof - A Test Automation Framework for Mercury. CoRR 2010.  Miguel Gomez-Zamalloa, Elvira Albert, and Germ?an Puebla - On the Generation of Test Data for Prolog by Partial Evaluation. CORR 2009.  SWI Prolog Unit test framework: http://www.swi-prolog.org/pldoc/package/plunit.html  ECLiPSe Prolog Unit test framework: http://eclipseclp.org/doc/bips/lib/test_util/index.html  Logtalk Unit test framework: http://trac.logtalk.org/browser/trunk/library/lgtunit.txt',no_work
'Most likely failure explanations in probabilistic Prolog Angelika Kimmig Luc DeRaedt Angelika Kimmig In artificial intelligence, there is a lot of interest in combining the expressive power of (subsets of) first order logic with the ability to reason about uncertainty. Within the K.U. Leuven DTAI group, we develop a simple probabilistic extension of the logic programming language Prolog, called ProbLog. In contrast to Prolog, ProbLog s database facts only succeed with a certain probability. As a consequence, whether additional information can be derived from given facts also depends on these probabilities. In ProbLog, the set of all explanations of a query -- a piece of information that might follow from the facts -- is important for most reasoning tasks. It can be used to calculate the probability that the query indeed follows from the given facts and thus succeeds, but also to find the most likely reason for a query to succeed. For the latter, one simply needs to compare the probabilities of the different explanations, which can easily be calculated if the explanations do not use negation. If explanations do use negation, ProbLog currently cannot find most likely explanations, as it cannot find the most likely reason why a query fails. The goal of this thesis is to extend ProbLog with a method for finding most likely explanations of failures, and to thereby extend the range of questions the system can answer. The first part of the thesis focusses on finding the most likely explanation why a single query that does not involve negation fails. The starting point will be the approach for finding all explanations for failures introduced in [Poole 2000]. In the second part, the resulting algorithm will be extended to queries that depend on negated subgoals, and will be integrated with ProbLog s current algorithm for explaining success. interest in logic programming and reasoning under uncertainty   http://dtai.cs.kuleuven.be/problog  A. Kimmig, B. Demoen, L. De Raedt, V. Santos Costa, and R. Rocha. On the implementation of the probabilistic logic programming language ProbLog. Theory and Practice of Logic Programming (TPLP) 11:235-262, 2011.   D. Poole. Abducing through Negation as Failure: Stable models within the independent choice logic. Journal of Logic Programming, 44(1-3):5-35, 2000.',no_work
'Visualizatie van robot-applicaties m.b.v. Eclipse Davy Preuveneers Yolande Berbers Herman.Bruyninckx+mech.kuleuven.be Davy Preuveneers  Het ontwerpen, deployen en testen van gedistribueerde geembedde applicaties voor robotsystemen is een complex gegeven. De reden hiervoor is dat - in vergelijking met een volledig gecentralizeerd systeem - het aantal mogelijke configuraties in een component-gebaseerde applicatie die draaien op verschillende systemen veel uitgebreider zijn, het testen van al die variaties tijdrovend is, en omdat fouten in een dergelijke gedistribueerde opstelling makkelijker kunnen optreden.  Enerzijds laat Eclipse als ontwikkelomgeving toe om het implementeren van robotica-applicaties te vereenvoudingen, anderzijds is de ondersteuning voor het deployen, testen en monitoren van gedistribueerde component- gebaseerde applicaties zeer beperkt omdat robots en mechatronicasystemen niet- alledaagse kwaliteitsvereisten (fault-tolerance, realtime, resource beperkingen) hebben in vergelijking met meer klassieke desktop en/of servertoepassingen.    Het doel van deze thesis is om een Eclipse plugin te ontwikkelen die toelaat om op een grafische manier het deployen en monitoren van robotica- applicaties mogelijk te maken. Hiervoor zal je eerst dergelijke applicaties modeleren m.b.v. het Eclipse Modeling Project, en ontwikkel je een Eclipse plugin waarmee het deploymentprocess van applicaties over verschillende apparaten grafisch kan uitgevoerd worden, en die de toestand en andere relevante parameters van de applicatie kan vizualizeren.  Tevens moet de tool ondersteuning bieden om boodschappen van en tussen de componenten op de verschillende (sub-)systemen te verzamelen en deze ter beschikking te stellen van de Eclipse gebruiker. Deze traces moeten de ontwikkelaar in staat stellen om verschillende configuraties van gedistribueerde toepassingen te testen en om kwaliteitsvereisten te valideren doorheen het ganse ontwikkelproces van de applicatie. Idealiter moet de plugin het ook toelaten om de feedback van een gemonitorde applicatie te "re-playen" om zo een in-depth post-mortem analyze uit voeren in het geval een aantal kwaliteitsvereisten niet gehaald worden.   De thesis start met een literatuurstudie van controle software (Orocos, ROS, OpenRTM, OPRo) en middleware (LooCI, Orca, RTMiddleware) voor mechatronicasystemen. Je werkt samen met experten van FMTC en de departementen Mechanica en Computerwetenschappen om de belangrijkste interactievereisten in kaart te brengen. Je werkt je in in Eclipse EMF, GEF en GMF. Op basis van de verzamelde vereisten en use-cases ontwerpen, ontwikkel je een Eclipse plugin met de eerder vermelde karakteristieken.  Kennis van gedistribueerde systemen en interesse in embedded systems is aangewezen.   Eclipse EMF/GEF/GMF:  http://www.eclipse.org/modeling/    Orocos:  http://www.orocos.org/  LooCI:  http://code.google.com/p/looci/   Een uitgebreide literatuurlijst zal ter beschikking komen bij het begin van de thesis.',no_work
'SensorLab Nelson Matthys Wouter Joosen Nelson Matthys Draadloze sensornetwerken zijn een veelbelovende technologie die het mogelijk maakt om de fysieke wereld te koppelen aan de virtuele wereld. Toepassingsdomeinen voor draadloze sensortechnologie zijn legio: gaande van het opvolgen van pakketten in de logistieke keten, het optekenen van allerhande milieufenomenen, het creeren van slimmere wagens en infrastructuur, aanbieden van allerhande domoticaoplossingen, tot het uitvoeren van procescontrole in industriele productieomgevingen. Gezien het enorme potentieel dat draadloze sensortechnologie biedt binnen deze toepassingsdomeinen, blijft de ontwikkeling en beheer van sensorapplicaties complex. Tijdens het op grote schaal uitrollen van de applicatie kunnen er allerhande problemen optreden. Meermaals is gebleken dat o.a. bugs, netwerkdynamisme, hardwarebeperkingen, performantie problematiek en schaalbaarheidsbeperkingen een impact uitoefenen op de werking van de applicatie. Ervaring leert eveneens dat dergelijke problemen meestal op voorhand opgespoord en vermeden konden worden d.m.v. een proefdraai van de applicatie in een gecontrolleerde labo-opstelling. Er is bijgevolg nood aan een realistische testinfrastructuur die het mogelijk moet maken om (i) het uitrollen van verschillende applicaties te ondersteunen, beheren, en testen, en (ii) het proefdraaien van de applicatie nauwgezet op te kunnen volgen.  Binnen deze thesis zal je een realistische testinfrastructuur bouwen met echte sensor hardware. Je ontwikkelt eveneens een applicatie die het mogelijk maakt om deze infrastructuur te configureren, beheren, en te monitoren. Ten slotte wordt de infrastructuur getest a.d.h.v. een typische sensorapplicatie.   Literatuurstudie rond middleware voor en karakteristieken van sensornetwerken  Architectuur en realizatie van de testinfrastructuur (SensorLab): analyse and evaluatie van benodigde tools.  Validatie en testen van SensorLab infrastructuur d.m.v. typische sensorapplicatie.    Je bent een zelfstandige en gemotiveerde student met interesse in embedded en grootschalige gedistribueerde systemen. Een groot deel van deze thesis bestaat uit praktisch onderzoeks- en ontwikkelingswerk met echte draadloze sensor hardware. Deze thesis richt zich bijgevolg eerder op industrieel georienteerd onderzoek waarbij een echte testinfrastructuur wordt gebouwd. Bijgevolg is een brede kennis van gedistribueerde systemen, netwerken en infrastructuur aangewezen. Interesse in systeemtools is een pluspunt.   http://www.sunspotworld.com/  http://www.sics.se/contiki/  http://www.cs.kuleuven.be/~klaas/thesis11-12/  http://code.google.com/p/looci/',no_work
'Vergelijkende studie van programmeermodellen voor sensornetwerken Nelson Matthys Christophe Huygens Wouter Joosen Nelson Matthys Draadloze sensornetwerken zijn een veelbelovende technologie die het mogelijk maakt om de fysieke wereld te koppelen aan de virtuele wereld. Toepassingsdomeinen voor draadloze sensortechnologie zijn legio: gaande van het opvolgen van pakketten in de logistieke keten, het optekenen van allerhande milieufenomenen, het creeren van slimmere wagens en infrastructuur, aanbieden van allerhande domoticaoplossingen, tot het uitvoeren van procescontrole in industriele productieomgevingen. De meeste toepassingsdomeinen hebben echter vereisten omtrent aanpasbaarheid van applicaties doorheen de tijd (functionele en niet-functionele updates, bugfixes, enz). Vandaag de dag gebeurt de ontwikkeling van dergelijke applicaties d.m.v. een geschikt programmeermodel of paradigma (bv: component-gebaseerde software ontwikkeling, tuple-spaces abstracties, agent-gebaseerde ontwikkeling, enz). Ieder paradigma heeft hierbij zijn eigen karakteristieken, voordelen en gebreken om de notie van aanpasbaarheid te ondersteunen. Vermits sensoren enerzijds batterijgevoed en anderzijds beperkt zijn qua hardwareresources moet de haalbaarheid en long-term impact van iedere aanpassing geevalueerd worden in termen van energieverbruik. Analyse van de impact op het energieverbruik gebeurt door evaluatie van zowel de kostprijs om de wijziging te uit te rollen (deployment kost) als de impact van de wijziging op langere termijn (operationele kost). In deze thesis wordt vertrokken van een aantal typische use cases en aanpassingsscenarios. Bij iedere aanpassing worden twee kostenfuncties (deployment en operationele kost) geassocieerd die vervolgens geevalueerd moeten worden in functie van verschillende metrieken zoals huidige netwerktopologie, energiekost applicatie (footprint, communicatie frequentie, i/o toegang, ...).   Literatuurstudie rond middleware voor sensornetwerken.  Definitie van deployment en operationele kostenfuncties.  Uitwerken typische use case in gekozen programmeermodel.  Evaluatie en analyse van kostenfuncties op basis van metrieken van de use case.    Je bent een zelfstandige en gemotiveerde student met interesse in embedded en gedistribueerde systemen. Een groot deel van deze thesis bestaat uit praktisch onderzoeks- en ontwikkelingswerk met echte draadloze sensor hardware, maar de evaluatie zal ook een zeker kritisch inzicht vereisen. Deze thesis richt zich bijgevolg eerder op academisch georienteerd onderzoek. Een creative ingesteldheid is zeker ook een pluspunt aangezien het het domein rond programmeermodellen voor sensornetwerken veel greenfield research omvat. Ervaring met C is niet vereist (er wordt eventueel een korte inwerkingsperiode voorzien). Ben je geinteresseerd? Neem dan zeker eens contact op met de contactpersonen voor een kort kennismakingsgesprek.      http://www.sunspotworld.com/      http://www.sics.se/contiki/      http://www.cs.kuleuven.be/~klaas/thesis11-12/       http://code.google.com/p/looci/',no_work
'Parallellisatie in Fortran: een case study Koen Poppe Ronald Cools Ronald Cools Koen Poppe Parallellisatie is een actief onderwerp, zeker in het kader van grid-computing. Daarnaast komen ook de shared-memory gebaseerde systemen weer naar de voorgrond door de opkomst van de multi-core processoren. Dit geeft aanleiding tot uiteenlopende mogelijkheden voor het parallelliseren. Het is dan ook nuttig om op zoek te gaan naar welke methode het meest geschikt is voor welk soort probleem. Aan de hand van een of meerdere specifiek gekozen voorbeelden van numerieke methodes, tracht deze thesis een beeld te vormen van de hedendaagse parallellisatiemogelijkheden voor Fortran. Hierbij kan bijvoorbeeld ingegaan worden op vectorisatie, het Message Passing Interface (MPI) paradigma, co-array Fortran (F--), Open High Performance Fortran (HPF) en Open Multi-Processing (OpenMP).  Na een korte literatuurstudie en een zoektocht naar interessante voorbeeldproblemen worden de verschillende parallellisatiemethodes bestudeerd. Daarna volgt de implementatie van een selectie van de voorbeeldproblemen, gebruik makende van twee of meer van deze methodes. Naast een kwalitatieve vergelijking van de programma s worden er concrete experimenten gedaan op zowel multi-core als grid-computing systemen. Dit alles kan leiden tot meer inzicht in paralellisatie in het kader van Fortran programma s.  Eerder implementatie gericht. 	 Vereiste voorkennis: Fortran 		 (vb: H0F03 - Technisch wetenschappelijke software) 	 Aan te raden kennis: Parallel programmeren 		 (vb: H03F9 - Algoritmes voor Parallelle computers)',no_work
'Delegate Multi-Agent Systems in Erlang Tom Holvoet Paul.Valckenaers+mech.kuleuven.be Tom Holvoet Tom Holvoet Paul.Valckenaers+mech.kuleuven.be In het kader van onderzoek aan de K.U.Leuven werd het concept van een D-MAS (delegate multi-agent system) ontwikkeld. Een D-MAS is een ontwerppatroon en -concept voor de coordinatie van activiteiten in belangrijke infrastructuren. Typische toepassingsdomeinen zijn:   intelligent verkeer en transport (ITTS) logistiek (LES - logistic execution systems)  productie (MES - manufacturing execution systems) slimme elektriciteitsnetwerken (smart grids) mobiele robots ...  Een D-MAS is een zwerm van lichtgewichtagenten die door een normale agent aangemaakt wordt om een bepaalde taak te vervullen. Bijvoorbeeld, een agent die een weggebruiker vertegenwoordigt zal een eerste D-MAS gebruiken om mogelijke routes te ontdekken en te evalueren. Die agent zal een tweede D-MAS gebruiken om de gekozen route te reserveren. Als die weggebruiker een elektrisch voertuig benut zal die agent met zijn D-MAS eveneens de reservatie van de nodige tijdslots bij laadstations verzekeren. Het D-MAS patroon resulteert in een systeem met veel parallelle softwareprocessen in een gedistribueerde omgeving. Bovendien vergen de typische toepassingen een hoge beschikbaarheid en betrouwbaarheid van de dienstverlening. In de telecom sector werd hiervoor een programmeertaal ontwikkeld: Erlang. Erlang ondersteunt applicaties met tienduizenden processen en is uniek in zijn ondersteuning voor complexe gedistribueerde applicaties. Ontwikkeling in Erlang was vier tot tien maal sneller dan in C++ in complex telecom toepassingen. Meer informatie:   Dit eindwerk ontwerpt en implementeert "Erlang Behaviours" voor D-MAS en demonstreert deze D-MAS implementatie op een toepassing in simulatie van intelligent verkeer of logistiek. Bedoeling is om de schaalbaarheid van een delegate MAS implementatie in Erlang te evalueren. De masterproef omvat de volgende activiteiten.  Erlang aanleren  D-MAS bestuderen  Een eenvoudige simulatie van een verkeers- of logistiek systeem ontwerpen en realiseren  D-MAS behaviours in Erlang ontwerpen en implementeren  D-MAS op de verkeerssimulatie toepassen  Demonstratie van de toepassing uitwerken (e.g. met web interface)  Test- en evaluatieomgeving uitwerken (e.g. met amnesia)  Evaluatiecampagne uitvoeren  Voor dit onderwerp zijn we op zoek naar gemotiveerde studenten met een creatieve maar kritische ingesteldheid. Het vak  multi-agent systems  gevolgd hebben is meegenomen maar geen strikte voorwaarde. Kom zeker langs indien je geinteresseerd bent.   Erlang,  Joe Armstrong (2010). Communications of the ACM, Vol. 53 No. 9, Pages 68-75  www.erlang.org, www.erlang.se  www.trapexit.org',no_work
'Kijken naar bordspellen: ontwikkeling van een kennisgebaseerd computervisie-systeem Joost Vennekens Marc Denecker Joost Vennekens Joost Vennekens  In computervisie tracht men systemen te ontwikkelen die in staat zijn om op basis van camerabeelden de werkelijkheid te begrijpen. Dit is een moeilijke opgave, aangezien er veel kennis over de wereld nodig is om een rooster van pixels om te zetten in een beschrijving van voorwerpen, personen, acties en gedragingen.De meeste computervisie-systemen die vandaag de dag bestaan, maken gebruik van hand-gecodeerde algoritmes. Dit betekent dat een dergelijk systeem bijvoorbeeld beschikt over een algoritme dat mensen kan herkennen, en over een algoritme dat auto s kan herkennen, en over een algoritme dat de actie wandelen kan herkennen, enzoverder. Deze aanpak is echter nogal arbeidsintensief, aangezien voor elke nieuwe soort van objecten en elke nieuwe actie die men wilt herkennen, een nieuw algoritme geschreven moet worden. Een alternatieve aanpak is om te gaan werken op een kennisgebaseerde manier, waarbij we een algemeen herkenningsalgoritme gebruiken, dat gevoed kan worden met beschrijvingen van objecten of acties. Zo zouden we bijvoorbeeld kunnen zeggen dat een auto een groot, langwerpig voorwerp is dat rust op vier wielen, en daarmee automatisch het herkenningsalgoritme aan de slag laten gaan.  Het doel van deze masterproef is om een kennisgebaseerd computervisie-systeem te ontwikkelen dat in staat is om het verloop eenvoudige bordspellen zoals bijvoorbeeld Monopoly te volgen, aan de hand van een beschrijving van hun spelregels. Een dergelijk systeem zal bestaan uit twee componenten:  een eenvoudige visiecomponent, die in staat is om de componenten van een typisch bordspel (dobbelstenen, kaarten, pionnetjes,...) te herkennen;  een kenniscomponent, die in staat is om een beschrijving van de spelregels van een spel te gebruiken en op basis hiervan de uitvoer van de visiecomponent te interpreteren. Voor de uitwerking van de visiecomponent zullen we gebruik maken bestaande bibliotheken in bijvoorbeeld C of C++. De implementatie van de kenniscomponent zal gebeuren door middel van bestaande systemen, zoals bijvoorbeeld ProbLog. Interesse voor  formeel modeleren, implementeren.',no_work
'Een adaptief algoritme voor het prijzen van financiele opties Dirk Nuyens Ronald Cools Dirk Nuyens Dirk Nuyens Nico Achtsis In  "financial engineering"  kan men de prijs van een financieel product schrijven als een hoog-dimensionale integraal (met honderden dimensies). Voor sommige van deze producten kan men echter een transformatie uitvoeren waarbij bijvoorbeeld enkel de eerste twee dimensies echt van belang zijn. Het evalueren van een hoog-dimensionale integraal is doorgaans een zeer rekenintensieve opdracht waarvoor men Monte Carlo methoden gebruikt, maar door gebruik te maken van deze intrinsieke lage dimensionaliteit kan dit veel efficienter gebeuren d.m.v. deterministische methoden (b.v. quasi-Monte Carlo methoden).                         Het ontwikkelen en implementeren van een adaptief algoritme voor het bereken van de prijs van een financieel product met een lage intrinsieke dimensionaliteit. De implementatie zal gebeuren in C++, eventueel met integratie vanuit Python (met numpy/scipy). Het algoritme zelf is reeds omschreven in de literatuur. Deze masterproef heeft een sterke implementatiekant, maar er is ook voldoende kennis van de numerieke wiskunde vereist voor het combineren van de verschillende technieken om de volledige toepassing samen te stellen.Vereiste voorkennis: "Technisch wetenschappelijke software".',no_work
'Darwin meets Robots - een evolutionaire benadering voor het ontwikkelen van MAS coordinatie strategieen Rinde VanLon Tom Holvoet Rinde VanLon In de onderzoeksgroep DistriNet wordt onderzoek gedaan naar het pick-up and delivery problem (PDP). PDP is een logistiek probleem van o.a. transport bedrijven. Pakketjes moeten van een oorsprong naar een bestemming worden getransporteerd door een vloot van vrachtwagens. Interessant is dat pakketjes op elk moment beschikbaar gemaakt kunnen worden en ook een bezorg deadline hebben. Dit maakt het tot een zeer dynamisch en lastig probleem. Binnen DistriNet is dit probleem tot nu toe vooral benaderd vanuit een Multi-Agent perspectief. Het doel in dit project is om vanuit een aanverwant onderzoeksgebied PDP te benaderen. Dit onderzoeksgebied is ?evolutionary robotics? (ER), in dit gebied wordt onderzoek gedaan naar het door gebruik van artificiele evolutie ontwerpen van robot controle programma s. De algoritmen die gebruikt worden heten evolutionaire algoritmen (EA), ook wel genetische algoritmen genoemd. Deze algoritmen zijn geinspireerd op natuurlijke evolutie zoals voor het eerst beschreven door Charles Darwin.  In ER is het vaak het doel om een (groot) aantal homogene robots als collectief effectief samen te laten werken. Het collectief heeft een gemeenschappelijk doel dat vaak uit subtaken bestaat. Een EA wordt gebruikt om de individuele robot besturing te ?ontwerpen?. Omdat ze samenwerken kan de kwaliteit (fitness) van een robot alleen worden beoordeeld op collectief niveau.  Het doel van dit project is om op basis van uitgebreid literatuur onderzoek in het evolutionaire robots domein een EA te ontwikkelen dat intelligente agents ontwerpt die in staat zijn om als collectief PDP op te lossen. Het hoofddoel is niet om PDP op te lossen, maar om onderzoek te doen naar een effectief algoritme dat intelligente agents kan ontwikkelen die in het PDP domein opereren. In dit project zal gewerkt worden met een bestaande multi-agent simulator en een Java library voor evolutionaire algoritmen. Dit stelt de student in staat om direct te focussen op het problem zelf. Er zal begonnen worden met een uitgebreide theorie studie van PDP en met name evolutionaire robots. Op basis van deze studie worden stapsgewijs een aantal belangrijke beslissingen genomen:   Het exacte (PDP) probleem wordt gedefinieerd.  De eigenschappen van de agents worden gedefinieerd (phenotype).  De encoding van een agent in het EA wordt gedefinieerd (genotype).  Een globaal ontwerp van de fitness functie. De fitness functie zal gebruik maken van de bestaande simulator waarin agents worden getest. Op basis van deze test zal een fitness waarde van een agent moeten worden vastgesteld.  Een globaal ontwerp van de variatie (mutaties, crossover) operatoren in het EA.     De verwachting is dat het maken van bovenstaande beslissingen afgewisseld wordt met de implementatie en het testen ervan. Deze aanpak is bedoeld om ervoor te zorgen dat al in een vroeg stadium feedback wordt verkregen over de conceptuele beslissingen. Het project zal worden afgerond met een aantal experimenten met het EA om de kwaliteit van de ge-evolueerde agents te onderzoeken.    Gemotiveerde student  Niet bang voor diepgaand literatuur onderzoek  Goede kennis van Java  Ervaring met EA / MAS / PDP is handig, niet vereist.   *Als je geinteresseerd bent verwachten we dat je contact met ons op neemt via bovenstaand e-mail adres nog voor de officiele meeting. Op deze manier kunnen we al snel  afspraken maken over het verloop van het project en ook rekening houden met eventuele persoonlijke wensen.    D. Floreano, L. Keller,  Evolution of adaptive behaviour in robots by means of darwinian selection. , PLoS biology, 2010.  M.W.P. Savelsbergh and M. Sol,  The general pickup and delivery problem , Transportation Science, 1995.  J-A Meyer, P. Husbands and I. Harvey,  Evolutionary Robotics: A Survey of Applications and Problems , Springer 1998.  D. Floreano, S. Mitri, A. Perez-Uribe, and L. Keller,  Evolution of Altruistic Robots . In Proceedings of the WCCI 2008 (2008), J. Zurada, Ed., Springer-Verlag Berlin Heidelberg, pp. 232? 248.  M.C. Schut,  Scientific Handbook for Simulation of Collective Intelligence , 2007.  K. Sims,  Evolving virtual creatures , Proceedings of the 21st annual conference on computer graphics and interactive techniques - SIGGRAPH ?94.   (zie ook:  YouTube  )  A.E. Eiben and J.E. Smith, ?Introduction to Evolutionary Computing?, Springer, Natural Computing Series, 2nd edition, 2007. ISBN: 978-3-540-40184-1.  Website van auteur.',no_work
'Shapeshifter: A model transformation application for parallelization of stream applications ZubairWadood Bhatti Davy Preuveneers Yolande Berbers ZubairWadood Bhatti Davy Preuveneers Stream programming is a technique that makes use of dataflow graphs to describe e.g. multimedia applications and the behaviour of the individual audio and video filters and codecs. Dataflow graphs are models of computation where concurrent actors communicate with each other via FIFO channels through blocking read and non-blocking write operations. These models are often complex to schedule at runtime because of performance variations of the actors, and the fact that the execution of every actor is subject to concurrency with and dependencies on other actors. These constraints need to be considered for scheduling. Therefore, it s sometimes beneficial to transform the application model into a model with limited but explicit concurrency.  The purpose of this thesis is to explore model transformations between auto-concurrent models (such as Dataflow Graph) and explicit concurrency models (such as Multi-threaded graphs). Both functional and data parallelism opportunities will exploited, and techniques such as  software pipelining  will be investigated for this transformation. The goal is to make this transformation fast, scalable and efficient. Efficiency of the transformation will be measured in terms of a potential gain or loss of the quality of the schedules derived from the transformed model versus those based on the original.  The thesis will start with a literature study on parallel processing, models of concurrency and model transformations for data flow graphs. The algorithms for the transformation will be designed and implemented as a plugin for Eclipse or Netbeans. The work will be evaluated on use cases and models of multimedia applications.  A strong interest in embedded systems. The daily supervision will be partially in English',no_work
'Genetic Algorithms Approach to Natural Language Processing Ivan Vulic Sien Moens Ivan Vulic  A genetic algorithm describes a heuristic search which tries to mimic the course of natural evolution, and is often used to solve various types of problems that include some kind of optimization or traversing through a huge search space. It is a technique that could be applied to many different tasks, from automotive design, protein design, computer gaming, robotics, even to joke and pun generation. They can be applied to numerous natural language processing problems as well. The focus of this project will be in construction of genetic algorithms as solutions for a selection of problems within Natural Language Processing (NLP), applied on Dutch or English, where the student might change what language she/he will prefer during her/his work on the thesis.   There is no fixed and resolute goal of the project, since it is very flexible in its extent and depth. The main goal is, as stated before, to prove that the framework of genetic algorithms is useful for natural language processing.  Genetic algorithms might be applied for many different problems. For instance, just to mention few:  1. obtaining  word alignments  combining various evidences from parallel texts written in different languages (the daily supervisor will provide corpora and ground truth for evaluations).  2.  part-of-speech tagging  (marking up the words in atext as corresponding to a particular linguistic category).  3.  grammatical induction  (learning a formal grammar from a set of observations)  4. finding optimal measures for  collocation extraction  (collocation is defined as a sequence of words or terms which co-occur more often than would be expected by chance).  5. joke and pun generation is also a possibility etc.  The student will have to construct and implement genetic algorithms for a subset of these tasks, evaluate the results and compare them with the results of other state-of-the-art systems.     The student will have to:  1. Study and implement genetic algorithms.  2. Learn about various problems in natural language processing.  3. Apply and evaluate her/his own algorithms for specific tasks as listed above.  The daily supervisor will provide all necessary datasets. The student might work with the parallel Europarl Corpus (EPC), which is well documented and available in many European languages, or the Dutch Parallel Corpus (DPC) Corpus, consisting of parallel documents in English, Dutch and French related to different domains (from newswire corpora to administrative or scientific texts).    A good knowledge of any programming language (Java/C++/C',no_work
'Appels met peren vergelijken Johan Wittocx Stef DePooter Marc Denecker Stef DePooter   De meeste programmeertalen maken standaard geen onderscheid tussen waardes met verschillende dimensies. Als een bepaalde afstand en een gewicht beiden worden voorgesteld door een floating point getal, dan zal het vergelijken of optellen van die twee waarden geen aanleiding geven tot een fout, terwijl vanuit fysisch standpunt de vergelijking nonsens is en de optelling onmogelijk. Ook mag men twee concrete waarden van eenzelfde dimensie niet zonder meer optellen wanneer de eenheden verschillend zijn. Om inches en meters op te tellen moet een van beiden eerst omgezet worden. Het niet ontdekken en opvangen van fouten tegen deze regels heeft in het verleden geleid tot desastreuze gevolgen. Een bekend voorbeeld is de crash van de Mars Climate Orbiter.    FO(.), de taal van het IDP systeem, is een uitbreiding van klassieke logica met onder andere een typesysteem. In dit typesysteem zijn integers reeds aanwezig, maar eenheden worden nog niet ondersteund.   Het doel van deze thesis is het toevoegen van natuurkundige eenheden aan FO(.) en het implementeren van die uitbreiding in IDP. De student maakt zich eerst vertrouwd met de integratie van natuurkundige eenheden in verschillende programmeertalen. Vervolgens wordt een voorstel uitgewerkt voor het integreren van eenheden in FO(.). Aspecten die hierbij aan bod komen zijn een goede syntax en definitie van type-correctheid. Daarna wordt de integratie geimplementeerd in IDP. De huidige type checker zal daarbij uitgebreid moeten worden om fouten tegen het gebruik van eenheden op te sporen. Interesse in logica Andrew John Kennedy, Programming Languages and Dimensions, PhD Thesis, Cambridge, 1995',no_work
'Detecteren van expressieve motieven in proteinen Celine Vens Hendrik Blockeel Celine Vens Het voorkomen van motieven in proteinen kan biologen belangrijke informatie verschaffen ivm welke rol de proteine speelt in het organisme. Bestaande tools voor motief detectie gebruiken hiervoor de zogenaamde primaire sequentie van de proteine, d.i. een aaneenschakeling van de 20 aminozuren. Een mogelijk motief is dan "LIIS", waarbij L, I en S specifieke aminozuren zijn.  Recent hebben we een nieuw algoritme voorgesteld, dat achtergrondinformatie over de aminozuren kan gebruiken in de motieven, dit geeft motieven als "small I hydrophobic S", waarbij bvb  hydrophobic  om het even welk hydrofoob aminozuur kan aanduiden. In dit eindwerk willen we nog een stapje verder gaan. Naast een primaire sequentie hebben proteinen ook een secundaire sequentie, die aangeeft hoe de aminozuurketen verbonden is. Er bestaan tools die een primaire proteine sequentie omzetten in een voorspelde secundaire sequentie. We willen deze secundaire structuur van de proteine in rekening brengen bij het zoeken naar motieven. Een mogelijk motief zou dan kunnen zijn: "(small in alpha-helix) I hydrophobic beta-sheet", waarbij alpha-helix en beta-sheet secundaire structuur elementen zijn. In dit eindwerk zal een bestaande tool die motieven detecteert (geimplementeerd in Perl), uitgebreid worden om secundaire informatie te gebruiken. Daarna wordt deze nieuwe techniek uitvoerig geevalueerd. De eerste fase van het eindwerk zal bestaan uit een literatuurstudie over primaire en secundaire proteine sequenties, en over motief detectie. Daarna wordt het motief detectie algoritme uitgebreid om secundaire sequenties te gebruiken. Belangrijk hierbij is het efficient doorlopen van de zoekruimte. Vervolgens gaan we op zoek naar publiek beschikbare datasets, en wordt geevalueerd of het gebruik van secundaire informatie nuttige motieven kan opleveren. Dit is een typisch "wetenschappelijke" thesis: literatuurstudie, implementatie, experimenteren, interpretatie van de resultaten. Hij is bijgevolg vooral geschikt voor studenten met een sterke wetenschappelijke interesse in machine learning en datamining. Biologische kennis is niet noodzakelijk, maar interesse in biologische toepassingen wel. C. Vens, M.N. Rosso, and E.G.J. Danchin, Identifying Discriminative Classification Based Motifs in Biological Sequences, Bioinformatics 27 (9), pp. 1231-1238, 2011.',no_work
'Beheer van netwerk beveiligingsinfrastructuur Bart Vanbrabant Wouter Joosen Bart Vanbrabant Computernetwerken worden steeds groter en beter beveiligd. Een centraal beveiligingsbeleid moet omgezet worden in regels die op routers en firewalls in het netwerk worden afgedwongen. Dit moet op een intelligente manier gebeuren, want niet alle regels zijn van toepassing op alle apparaten. Daarnaast zijn er ook apparaten waar alle netwerkverkeer passeert die niet genoeg capaciteit hebben om alle regels af te dwingen. Firewalls die beschikbaar zijn op de servers en computers in het netwerk worden meestal niet geentegreerd in het centrale beleid wegens een te grote overhead maar zouden ook ingezet kunnen worden. Het doel van deze thesis om een tool te ontwikkelen om een beveiliginsbeleid te modelleren en te vertalen naar de apparaten in het netwerk. Deze tool wordt ontwikkeld op een bestaand raamwerk om systeembeheer tools te ontwikkelen.   Studie van bestaande tools en onderzoek over het beheer van firewalls  Ontwikkeling van een tool op een bestaand framework  Evaluatie aan de hand van een case. Bijvoorbeeld de routers en firewalls van kulnet.   De student dient ervaring te hebben met netwerkbeheer of de motivatie om zich hierin te verdiepen. Het vak netwerken is vereist. Internetinfrastructuur en Security of Networks and Computer Systems ook, maar kunnen eventueel samen met de thesis gevolgd worden. Gedistribueerde systemen is ook ten zeerste aan te raden. Firmato: A novel firewall management toolkit  paper',no_work
'Coordinatiestrategieen voor een real-time prijsomgeving in Smart Grids Stijn Vandael Tom Holvoet Stijn Vandael wouter.labeeuw+esat.kuleuven.be  DSM (Demand Side Management) is het beinvloeden van de energievraag van lokale consumenten. In het toekomstig Smart Grid of slim elektriciteitsnet zal DSM mogelijk gemaakt worden door bidirectionele communicatie met consumenten. De doelstellingen van DSM kunnen veelvuldig zijn: piekbelastingen vermijden, overproductie uit hernieuwbare energie opvangen enz.  Aan de onderzoeksgroep DistriNet zijn we bezig met het ontwikkelen van coordinatiestrategieen voor DSM in een Smart Grid. Deze coordinatiestrategieen zijn gebaseerd op het mechanisme dat individuele toestellen hun energievraag bekend maken zodat de collectieve afname van een groep toestellen gecoordineerd en gecontroleerd kan worden.  Linear is een grootschalig project rond intelligente elektriciteitsnetwerken in Vlaanderen. In dit project wordt DSM verwezenlijk door middel van lokale prijzen. Op huishoudelijk niveau worden toestellen geoptimaliseerd naar deze real-time prijzen. De manier waarop deze prijzen bepaald worden is tot nu toe nog onduidelijk.  In deze thesis wordt onderzocht hoe real-time prijzen kunnen bepaald worden in een distributienet met een heterogene groep verbruikers. De kwaliteit van de oplossing zal o.a geevalueerd worden door het afvlakken van piekbelastingen.  In de eerste fase wordt op huishoudniveau onderzocht op welke manier individuele toestellen een planning kunnen opstellen, afhankelijk van real-time prijzen. Hierbij zal een optimalisatietechniek zoals LP (Lineair Programmeren) gebruikt worden.  In de tweede fase wordt een globale strategie ontwikkeld die real-time prijzen bepaalt voor het coordineren van een hele groep huishoudens. Belangrijk hierbij is dat ``load syncing??, het veroorzaken van piekbelastingen door gelijktijdige consumptie, vermeden wordt.     Gemotiveerde student  Goede kennis van Java     S. Vandael, N. Bouck?, T. Holvoet, G. Deconinck, ?Decentralized demand side management of plug-in hybrid vehicles in a Smart Grid?, ATES-2010, 2010, pp. 67-74  A. Molderink, V. Bakker, M. G. C. Bosman, J. L. Hurink, and G. J. M. Smit. Management and control of domestic smart grid technology. IEEE transaction on Smart Grid, 1(2):109?119, September 2010.  J. K. Kok, C. J. Warmer, and I. G. Kamphuis. Powermatcher: multiagent control in the electricity infrastructure. In AAMAS ?05: Proceedings of the fourth international joint conference on Autonomous agents and multiagent systems, pages 75?82, New York, NY, USA, 2005. ACM.  Linear Intelligent Networks, http://www.linear-smartgrid.be/',no_work
'Automatische migratie van IPv4 netwerken naar IPv6 Bart Vanbrabant Wouter Joosen Bart Vanbrabant In februari heeft het IANA de laatste beschikbare IPv4 blokken uitgedeeld aan de lokale registers. In April heeft APNIC, het register voor Azie, zijn laatste IPv4 addressen uitgedeeld. IPv6 is de opvolger voor IPv4 en is al geruime tijd klaar om gebruikt te worden. Tot voor kort bestond er geen economische druk om IPv6 te gaan toepassen. Dit is nu niet langer het geval nu in Azie geen IPv4 adressen meer beschikbaar zijn. In Azie gaan er nu nieuwe internet gebruikers opduiken die enkel nog via IPv6 op het internet kunnen. Voor bedrijven wordt het dus noodzakelijk om hun infrastructuur te migreren naar IPv6. Het doel van deze thesis is een netwerkbeheer tool te ontwikkelen dieIPv4 netwerken kan migreren naar IPv6. Deze tool moet op basis van een IPv4 configuratie de IPv6 configuratie van het netwerk genereren en uitrollen. Deze tool wordt ontwikkeld op een raamwerk om configuratie beheer gereedschappen te bouwen.   Ervaring op doen met het opzetten van IPv6 netwerken  Studie van migratie van IPv4 naar IPv6  Studie van raamwerk om netwerk beheer te automatiseren  Implementatie van een gereedschap om automatisch naar IPv6 te migreren  Evaluatie aan de hand van case gebaseerd een reele migratie   De student dient ervaring te hebben met netwerkbeheer of de motivatie om zich hierin te verdiepen. Het vak netwerken is vereist. Internetinfrastructuur en Security of Networks and Computer Systems ook, maar kunnen eventueel samen met de thesis gevolgd worden. Gedistribueerde systemen is ook ten zeerste aan te raden. Automated and Secure IPv6 Configuration in Enterprise Networks  paper',no_work
'Building a Style Checker for Dutch Ivan Vulic Sien Moens Ivan Vulic  Style and grammar checkers are useful for the same reason a spell checker is useful - it serves as a low-cost help to authors for writing texts with significantly fewer errors, typos and bad linguistic constructions which finally leads to documents ofa better quality and intelligibility. A good style checker needs to combine several desirable properties: it should be fast, interactive, intelligent (e.g., it should not suggest corrections for the already correct sentences), adaptive to needs of the end-user, and, of course, efficient.  Many style checkers for English already exist, so the focus of the project will be on developing a usable, full-fledged style checker for the Dutch language, which will be able to detect and propose corrections for the most common types of errors:  1.  spelling errors , where the system detects that a word is spelled incorrectly and proposes a solution based on the context and the error itself.  2.  grammar errors , all errors which do not comply to the grammar of the language  3.  style errors , which include usage of uncommon words or phrasal structures, or too complicatedsentences  4.  semantic errors , which include phrases or sentences which obey all grammatical rules, but are semantically incorrect (in other words, do not make much sense).  Two different approaches are possible -  the rule-based approach  (in short, writing an amount of error rules and checking if the user s text matches against such predefined rules) and  the statistical approach  (using n-grams of words or linguis-tic categories such as part-of-speech tags to detect the probability of a phrase or a sentence; sentences and phrases that score below a defined threshold are considered incorrect). It is also possible to combine the two approaches.  The goal is to build a style checker for Dutch, as a stand-alone application or as an integrated part of a word processor.  The student should:  1. study, implement and use different natural language processing techniques and tools such as  part-of-speech (POS) tagging  (marking up the words in a text as corresponding to a particular linguistic category),  parsing  (determining the grammatical structure of the text),  phrase chunking  (separating and segmenting sentences into its sub-constituents, such as noun phrases, verb phrases),  sentence boundary detection , learning semantic associations etc.  2. provide an extensive comparison of the two approaches (rule-based and statistical) accompanied by illustrative examples and an evaluation using a manually designed ?erroneous? test corpus.  3. fully design a stand-alone style checker for Dutch, with the option of integrating it within an already existing word processor.    No prior knowledge of natural language processing is necessary  A working knowledge of any object-oriented programming language is needed  Daily supervision is in English    [1] P. S. Kernick and D. M. W. Powers. 1996. A Statistical Grammar Checker.  [2] D. Naber. 2003. A Rule-Based Style and Grammar Checker. Diploma Thesis',no_work
'Bio-geinspireerde optimalisatie voor het opladen van PHEVs (plug-in elektrische hybride voertuigen) in een Smart Grid Stijn Vandael Rinde VanLon Tom Holvoet geert.deconinck+esat.kuleuven.be Stijn Vandael Rinde VanLon Volgens recente studies zullen tegen 2030 zowat 30% van alle voertuigen in Belgie PHEV s zullen zijn. In korte tijd zullen er daardoor een groot aantal gebruikers van het elektriciteitsnet bijkomen. Doordat de meeste PHEV s  s avonds opgeladen worden, zal de  bestaande avondpiek door huishoudelijk gebruik vergroot worden. In een slim elektriciteitsnet of Smart Grid, wordt het mogelijk het opladen van PHEV s te coordineren (DSM; demand side management). In de onderzoeksgroep DistriNet zijn we verschillende coordinatiestrategieen aan het ontwikkelen voor DSM van PHEV s. Hierbij maken we een vergelijking tussen decentrale (agent-gebaseerde) coordinatie en centrale (scheduler) oplossingen. De centrale oplossing is gebaseerd op LP (Linear programmeren), een deterministische optimalisatiemethode. Het probleem echter met LP is dat deze oplossingsmethode enkel geschikt is tot ~10.000 PHEV?s omdat de oplossingsruimte te groot wordt.  Stochastische optimalisatie technieken (zoals bio-geenspireerde technieken) zijn bekende approximatie methoden, die typisch ingezet kunnen worden voor grotere oplossing ruimtes. Deze approximatie methoden werken efficienter (in computationele zin) maar geven geen garantie van optimaliteit.  Het doel van deze thesis is de ontwikkeling van een oplossing gebaseerd op bio-geinspireerde technieken voor het opladen van een groot aantal PHEV?s. De kwaliteit van deze oplossing zal o.a geevalueerd worden op (sub-)optimaliteit en convergentiesnelheid. In de eerste fase zal een theoriestudie van optimalisatietechnieken en Smart Grids uitgevoerd worden. Inzake optimalisatie zullen de verschillende stochastische optimalisatietechnieken en bio-geenspireerde technieken bestudeerd worden. Inzake Smart Grids zal het probleedomein van DSM van PHEV s kort bestudeerd worden. In de tweede fase zal het DSM probleem van het opladen van PHEV?s vertaald worden naar een geschikt model voor stochastische optimalisatie. Een mogelijke aanpak is het vertalen van het probleem naar een kortste-pad probleem.  In de derde fase zullen verschillende bio-geenspireerde oplossingen grondig geevalueerd en vergeleken worden met elkaar. Enkele voorbeelden van bio-geenspireerde technieken zijn: Evolutionary Algorithms, Simulated Annealing, Particle Swarm Optimization, Ant Colony Optimization, etc.  In de vierde fase wordt, gebaseerd op de ervaring in de vorige fases, een specifiek aspect verder uitgewerkt in overleg met de begeleiders. Enkele mogelijkheden:  Adaptieve optimalisatie waarbij een dynamische omgeving wordt beschouwd.  Optimalisatie voor verschillende fitness functions door studie van business cases in Smart Grids.  Simulatie van de elektriciteitsinfrastructuur voor een technische analyse van de verliezen en piekbelastingen op de verschillende componenten.    Gemotiveerde student  Goede kennis van Matlab en Java   *Als je geinteresseerd bent verwachten we dat je contact met ons op neemt via bovenstaand e-mail adres nog voor de officiele meeting. Op deze manier kunnen we al snel  afspraken maken over het verloop van het project en ook rekening houden met eventuele persoonlijke wensen.    S. Vandael, N. Bouck?, T. Holvoet, G. Deconinck,  Decentralized demand side management of plug-in hybrid vehicles in a Smart Grid , ATES-2010, 2010, pp. 67-74  K. Clement , E. Haesen, J. Driesen,  Coordinated Charging of Multiple Plug-In Hybrid Electric Vehicles in Residential Distribution Grids , PSCE 09 , Seatle, Washington, USA, March 15-18, 2009; 7 pages.  Jason Brownlee, Clever Algorithms,  Nature-Inspired Programming Recipes , 2011.   E. Bonabeau, M. Dorigo, G. Theraulaz, ?Swarm Intelligence, From Natural to Artificial Systems?, 1999, Oxford University Press.  A.E. Eiben and J.E. Smith, ?Introduction to Evolutionary Computing?, Springer, Natural Computing Series, 2nd edition, 2007. ISBN: 978-3-540-40184-1.  Website van auteur.  J. Kennedy and R. Eberhart,  Particle Swarm Optimization , IEEE, 1995.',no_work
'RMOX: a parallel operating system on the Intel 48-core Single-chip Cloud Computer Davy Preuveneers patrick.pelgrims+mechelen.lessius.eu Yolande Berbers ZubairWadood Bhatti Davy Preuveneers patrick.pelgrims+mechelen.lessius.eu  Multi-core chips become more popular than ever before. Vendors like Tilera are building nowadays multi-core processors with more than 64 processor cores. But current operating systems like Linux, Unix or Windows where not designed for this parallel multi-core technology. Functionality like OpenMP is applied to build large communicating multi processor/processing systems. Since these operating systems are pretty large, they can?t fit in the on chip caches of the cores, and swapping occurs frequently, which induces a loss of performance.   With RMoX, an experimental process oriented operating system, written in the occam-pi, a process-oriented programming language that abstracts processes and message-massing communication, an optimal chip resource allocation could be achieved.  A reasonably sized application (including the RMoX operating system) may consist of several thousand parallel and concurrently running communicating processes or processors. RMox and the occam-pi programming approach guarantees freedom from aliasing and race-hazard errors, deadlock and livelock and differs substantially from the more widely accepted threads-and-locks techniques.    Putting an OS like RMoX on a chip like the the Intel 48-core Single-chip Cloud Computer (SCC) can make current and experimental systems much more performant than systems that run current operating systems.   The objective of this research proposal is to port RMoX on the Intel  i48 Single-chip Cloud Computer and study the ability to distribute processes and inter process communication in a dynamic way to achieve the best overall performance.  RMoX is currently available for PC/104+ range embedded PC devices. A first task will be to port RMoX to the Intel SCC, and investigateruntime scheduling techniques to distribute processing workloads and communication, and compare the performance results of RMoX with those of general purpose operating environments. A strong interest in parallel computing is recommendedThis thesis proposal is in collaboration with Patrick Pelgrims from the Co.EmSys Research Group, Lessius Mechelen, Campus de Nayer,patrick.pelgrims@mechelen.lessius.eu   RMoX: http://rmox.net/  PC/104+: http://www.pc104.org/  Occam-pi: http://pop-users.org/wiki/occam-pi  Intel SCC: http://software.intel.com/en-us/videos/48-core-single-chip-cloud-computer/ Een uitgebreidere literatuurlijst volgt bij de start van de thesis',no_work
'Simulatie van een slim elektriciteitsnet in Vlaanderen Stijn Vandael Tom Holvoet geert.deconinck+esat.kuleuven.be Stijn Vandael Aan de onderzoeksgroep DistriNet zijn we bezig met het ontwerpen van coordinatiestrategieen voor elektrische voertuigen. Deze coordinatiestrategieen worden uitvoerig geevalueerd in een simulator voor slimme elektriciteitsnetten. Deze simulator is momenteel enkel geschikt voor simulaties op kleine schaal (distributienet). Het doel van deze thesis om de huidige simulator te herzien om grootschalige simulaties (ter grootte van Vlaanderen) toe te laten. De kwaliteit van de oplossing wordt bepaald door 1) een grondige evaluatie naar performantie en schaalbaarheid en 2) een validatie naar het simuleren van een realistische scenario in Vlaanderen.  In eerste fase wordt de simulator (geprogrammeerd in Java) bestudeerd en wordt een grondige analyse van de performantie gemaakt. Hierbij zal er gebruik gemaakt worden van een state-of-the-art profiler.  In de tweede fase wordt het design van de simulator herbekeken om simulaties op transmissienet niveau toe te laten. Belangrijke aspecten hierbij zijn het simuleren van een vermaasd net (in plaats van een radiaal net) en de integratie van powerflow berekeningen. Hierbij wordt de performantie geevalueerd en geoptimaliseerd.  In de derde fase wordt de simulator gevalideerd in enkele realistische scenario s van het transmissienet in Vlaanderen en vergeleken met bestaande simulaties van het transmissienet.   Gemotiveerde student Goede kennis van Java    Douglas C. Schmidt, Michael Stal, Hans Rohnert, Frank Buschmann "Pattern-Oriented Software Architecture, Volume 2, Patterns for Concurrent and Networked Objects", Wiley, 2000  S. Vandael, N. Bouck?, T. Holvoet, and G. Deconinck,Decentralized demand side management of plug-in hybrid vehicles in a Smart Grid, ATES-2010, 2010, pp. 67-74',no_work
'Robot Manipulation: Using relational representations for manipulation tasks in a robot simulator Bogdan Moldovan Davide Nitti Luc DeRaedt herman.bruyninckx+mech.kuleuven.be Bogdan Moldovan Davide Nitti Robotics is a vast area of research employing many techniques in artificial intelligence to obtain smart physical agents that can perform all kinds of useful tasks. Much work on robotics focuses on machine learning techniques to obtain adaptive methods for e.g. navigation, manipulation, planning, etc. The use of relational knowledge representation formalisms is very useful to describe the robots environment, plans, goals and so on, but so far the application of these representations was limited. Recently, statistical relational learning techniques have become mature enough, and it is in this context that we would like to apply them in robotics context. We could call this new area "relational robotics". The Robotic Operating System (ROS) is a recent initiative to supply robotic researchers throughout the world with the same, general operating system for research on robotics. It is based on principles of distributed systems, and ROS features many components that can handle various perception and motor skills. To visualise the robot, a robotic simulator will be used. The two options available for this are the MORSE OpenRobot Simulator and theORCA robot simulation and navigation software. One of the most important tasks of a robot is to manipulate objects in an environment. For example, a robot can be sent to collect a book from a specific office, but in order to do that, it has to physically move itself to the book, adjust its gripper position and take actions to grab the book. Other possible applications are sorting a collection of objects on a table, or just playing with blocks. In all these applications, it would be useful to learn and plan using (probabilistic) relational knowledge representation schemes that generalize over specific objects, over numbers of objects and over complex relational configurations of objects. The thesis will build on work already done by students on a similar topic this year, the goal being to extend this setting further using the building blocks already provided. This thesis is also part of a collaboration with Prof. Herman Bruyninckx robotics group, and during the project work can also be done on a real robot. The goal of the project is to use relational representations and learning for robot manipulation tasks in a realistic simulator. The perception of the robot should be based on object models and simulated visual input. The student is expected to go through the following steps: 1) Perform a literature study on the use of relational knowledge representation and learning for robots manipulating objects in a (toy) environment, as well as basic vision-based perception. Furthermore, the student must get acquainted with ROS and the simulator. 2) Choose a robotic arm, task and domain in which the robot must use object models or simulated vision-based input, and where the goal is manipulate a number of objects in the environment. 3) Develop knowledge representation and algorithms for solving the task in (2). 4) Implement the algorithms in (3) in ProbLog and connect it to ROS, and extensively evaluate the approach and its performance on the task. 5) Explore various extensions when time permits. The student is interested in machine learning, artificial intelligence and robotics. Preferably the student is knowledgeable in C++/Python, and preferably also in Matlab and/or Prolog. http://www.ros.org (main website of ROS; also contains tutorials) http://www.openrobots.org/wiki/morse (MORSE OpenRobot simulator) http://www.ics.forth.gr/~xmpalt/research/orca/ (ORCA robot simulation and navigation software) (a robot playing with blocks)M. Toussaint, N. Plath, T. Lang and Nikolay Jetchev (2010) Integrated motor control, planning, grasping and high-level reasoning in a blocks world using probabilistic inference. IEEE International Conference on Robotics and Automation (ICRA) (learning probabilistic relational rules for planning in a simulated domain)Hanna M. Pasula, Luke S. Zettlemoyer, Leslie Pack Kaelbling: Learning Symbolic Models of Stochastic Domains. J. Artif. Intell. Res. (JAIR) 29: 309-352 (2007) (a real robot learning concepts for manipulation of objects)Affordance-Based Imitation Learning in Robots,  Manuel Lopes, Francisco S. Melo, Luis Montesano  VisLab-TR 09/2007, 2007 IEEE/RSJ International Conference on Intelligent Robots and Systems, San Diego, USA, October 2007. (Mobile) manipulationhttp://mobilemanipulation.org (recent workshop on (mobile) manipulation, and pointers)http://first-mm.eu/ (European project on (relational) manipulation with K.U. Leuven presence)',no_work
'Automatisch abstractie maken van heterogeniteit in besturingssystemen Bart Vanbrabant Wouter Joosen Bart Vanbrabant Omgaan met de heterogeniteit van ICT infrastructuren een grote uitdaging bij het automatiseren van het beheer van ervan. De naam van een dienst of de locatie configuratiebestand verschilt vaak tussen besturingssystemen en moet daarom geparametriseerd worden in beheertools. Daarnaast moeten deze tools om systeembeheer te automatiseren ook handmatig op de hoogte gesteld worden van afhankelijkheden tussen een configuratiebestand en een dienst, of tussen diensten onderling. Toch is deze informatie is impliciet beschikbaar in veel besturingssystemen onder de vorm van metadata voor hun software distributie kanalen zoals bijvoorbeeld apt of yum repositories. Bestaande beheertools zijn niet in staat om deze aanwezige metadata te gebruiken. Het doel van deze thesis om de aanwezig metadata in besturingssystemen automatisch te verwerken en beschikbaar te stellen aan systeembeheer tools. Daarnaast moet dit in een gedistribueerde context gebeuren, zodat elke fabrikant van een besturingssysteem of software pakket deze data zelf beschikbaar kan stellen. Hiervoor baseren we ons op de technologie die gebruikt wordt in het semantisch web maar ook moet de nodige aandacht besteed worden aan beveiliging van de herkomst van de metadata.   Studie hoe metadata aanwezig is in besturingssystemen  Studie van semantisch web technologie  Extraheren van de metadata en bruikbaar maken voor systeembeheer tools  Integratie van metadata in een bestaand raamwerk om systeembeheer tools te ontwikkelen  Evaluatie door een case uit te werken op een heterogene ICT infrastructuur   De student dient ervaring te hebben met systeembeheer en semantisch web, of de motivatie om zich hierin te verdiepen.',no_work
'Going Somewhere?: Using relational representations for navigation tasks in a robot simulator Bogdan Moldovan Davide Nitti Luc DeRaedt herman.bruyninckx+mech.kuleuven.be Bogdan Moldovan Davide Nitti Robotics is a vast area of research employing many techniques in artificial intelligence to obtain smart physical agents that can perform all kinds of useful tasks. Much work on robotics focuses on machine learning techniques to obtain adaptive methods for e.g. navigation, manipulation, planning, etc. The use of relational knowledge representation formalisms is very useful to describe the robots environment, plans, goals and so on, but so far the application of these representations was limited. Recently, statistical relational learning techniques have become mature enough, and it is in this context that we would like to apply them in robotics context. We could call this new area "relational robotics". The Robotic Operating System (ROS) is a recent initiative to supply robotic researchers throughout the world with the same, general operating system for research on robotics. It is based on principles of distributed systems, and ROS features many components that can handle various perception and motor skills. To visualise the robot, a robotic simulator will be used. The two options available for this are the MORSE OpenRobot Simulator and theORCA robot simulation and navigation software. One of the main tasks in robotics research has always been the navigation problem. Current problems in this area are about how to visit several places in an environment (e.g. to pick up selected objects) or to find out it has already been at a certain place (e.g. by recognizing certain visual clues), and how to nagivate in the environment given certain constraints (e.g. doors between rooms might be closed). In this thesis we want to explore such tasks using relational representations and learning algorithms. The thesis will build on work already done by students on a similar topic this year, the goal being to extend this setting further using the building blocks already provided. This thesis is also part of a collaboration with Prof. Herman Bruyninckx robotics group, and during the project work can also be done on a real robot. The goal of the project is to use relational representations and learning for robot navigation tasks in a realistic simulator. The perception of the robot should be based on simulated vision and object models. The student is expected to go through the following steps: 1) Perform a literature study on the use of relational knowledge representation and learning for robots navigating in a (toy) environment, as well as basic vision-based perception. Furthermore, the student must get acquainted with ROS and the simulator. 2) Choose a robot, task and domain in which the robot must use object models or simulated vision-based input, and where the goal is to visit certain places in the environment. 3) Develop knowledge representation and algorithms for solving the task in (2). 4) Implement the algorithms in (3) in Prolog and connect it to ROS, and extensively evaluate the approach and its performance on the task. 5) Explore various extensions when time permits. The student is interested in machine learning, artificial intelligence and robotics. Preferably the student is knowledgeable in C++/Python, and preferably also in Matlab and/or Prolog. http://www.ros.org (main website of ROS; also contains tutorials) http://www.openrobots.org/wiki/morse (MORSE OpenRobot simulator) http://www.ics.forth.gr/~xmpalt/research/orca/ (ORCA robot simulation and navigation software) (relational object maps for robots)B. Limketkai, L. Liao and D. Fox (2005) Relational object maps for mobile robots, Proceedings of the 19th international joint conference on Artificial intelligence table of contents, Pp1471-1476 Using inductive logic programming for navigation policiesCocora, A., Kersting, K., Plagemann, C., Burgard, W. and De Raedt, L. (2006), Learning Relational Navigation Policies, in: Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS). An early example using inductive logic programmingInuzuka, N., Onda, T. and Itoh, H. (1999), Learning Robot Control by Relational Concept Induction with Iteratively Collected Examples, in: In Proceedings of the 8th European Workshop on Learning Robots, pp. 71-83.',no_work
'Combining visual and language features for image retrieval Mathias Verbeke Laura Antanas Luc DeRaedt Mathias Verbeke Laura Antanas Due to the overwhelming amount of multimedia data we are facing today, image retrieval has gained a major importance. Although significant progress has been made in the computer vision community, one bottleneck in this process remains the semantic gap between the raw visual data extracted from images using current state-of-the-art descriptors and the actual semantic interpretation that users give to these images [5]. This bottleneck may be reduced by employing multimodal approaches, which take advantage of the fact that in many applications image data typically coexists with other modalities of information such as text. Several existing works combine these 2 sources of information. However, only recently, larger Wikipedia text descriptions or hierarchical structure defined on semantic attributes (WordNet [2]) have been employed for image retrieval or classification. The goal of this thesis is to investigate the importance of both rich text descriptions and hierarchical semantic structure on image retrieval in cases when high amounts of training data are not feasible. Separately, they have shown their benefits on image retrieval tasks on large datasets. More specifically, we propose to start from the ImageCLEF Wikipedia Retrieval task dataset [1], global visual feature descriptors and WordNet (a lexical database of English containing hierarchical conceptual-semantic and lexical relations between the words). The goal is to develop an image retrieval system or classifier that combines these features and techniques to show their benefits on a reduced problem.   Literature study on feature representations and machine learning techniques in computer vision and computational linguistics.  Get familiar with the available proposed tools  Combine them to come up with a representation suitable to build a multimodalretrieval system or classifier  Evaluation on the ImageCLEF 2011 dataset     Interested in machine learning, computer vision and computational linguistics.  Strong programming skills are an advantage.     http://www.imageclef.org/2011/Wikipedia  http://wordnet.princeton.edu/  D. Myoupo et al., Multimodal image retrieval over a large database, CLEF 09 Proceedings of the 10th International Conference on Cross-Language evaluation forum: multimedia experiments, 2009  J. Deng, A. Berg, and L. Fei-Fei. Hierarchical Semantic Indexing for Large Scale Image Retrieval. IEEE Computer Vision and Pattern Recognition (CVPR). 2011.  L.J. Li, H. Su, Y. Lim and L. Fei-Fei, Objects as Attributes for Scene Classification. Proceedings of the 12th European Conference of Computer Vision (ECCV), 1st International Workshop on Parts and Attributes. 2010.',no_work
'Agents are delivering Ready-Mix Concrete. Shaza Hanif Tom Holvoet Tom Holvoet MAS provides efficient solutions for solving real life problems. Ready-mix concrete delivery problem can be defined as: concrete produced at production sites is to be delivered at customer s construction sites using a set of vehicles. Some additional constraints make this problem distinct from ordinary Pickup and delivery problems.  To mention a  few of constraints; First, concrete may only reside in the vehicle for limited amount of time, before it looses quality for the customer. Second, after a servicing a customer, the vehicle has to return to the production site and then filled again for second customer. i.e. two customers can not be serviced by filling the vehicle once. Third, if more then one delivery of concrete is necessary to satisfy the demand of the a customer, the spacings between the consecutive deliveries may not exceed certain time limits, as the concrete could partially harden at the construction site before the subsequent supplies arrive.  Delegate MAS is a coordination mechanism between agents that help agents coordinate utilizing only locally available knowledge.  The goal of project is to develop a Multiagent system for solving Concrete Delivery Problem of a company with real life data. Since the problem is dynamic, delegate MAS -- that focuses on dynamism -- will be used as collaboration mechanism between agents. The static problem has been effectively solved using discrete optimization techniques. The current proposal is to solve the dynamic problem (in which customer orders will arrive dynamically) using a multiagent system, particularly by using delegate MAS. The thesis may involve collaboration with external, which will be done mostly by the coordinators.  Work Constitution:     Literature Study: 20%    Programming/Implementation: 70%    Expermentation: 10%   Note: the reference [3] given for concrete delivery problem uses discrete optimization techniques. The reference should be used to understand the problem only, not the solution. Interests in Multiagent Systems/optimization problems/real life problems   T. Holvoet and P. Valckenaers:  Exploiting the Environment for Coordinating Agent Intentions , in Environments for Multiagent Systems III, ser. LNCS, 4389. Springer, 2006.      Jelle Van Gompel, Bart Tuts, Rutger Claes, Mario Henrique Cruz Torres, Tom Holvoet:   MAS-DisCoSim 4 PDP: A testbed for multi-agent solutions to PDPs  , Proceedings of the 9th International Conference on Autonomous Agents and Multiagent Systems, pages 1-2,  2010    L. Asbach, U. Dorndorf, and E. Pesch:  Analysis, modeling and solution of the concrete delivery problem.   European Journal of Operational Research, 193 (3): 820-835, 2009.    M. Wooldridge (Eds.), An Introduction to MultiAgent Systems, ISBN:0470519460 9780470519462, Wiley, 2009.',no_work
'Ontwerp en ontwikkel een patient monitoring system "as a service" Stefan Walraven Wouter Joosen Stefan Walraven  De huidige computerinfrastructuur in ziekenhuizen is zeer uitgebreid en complex. Met de invoering van het elektronische patientendossier (EPD), elektronische voorschriften en andere digitale projecten voor de gezondheidszorg (bv. een patient monitoring system) zal die complexiteit alleen maar stijgen. De ziekenhuizen willen echter meer focussen op hun kerntaak, nl. het leveren van medische hulp, in plaats van het onderhouden van hun infrastructuur en software applicaties. Een mogelijke optie is het uitbesteden van deze infrastructuur en applicaties aan een externe cloud provider. De ziekenhuizen kunnen dan deze software applicaties gebruiken als een service, en hoeven enkel te betalen voor wat ze echt gebruiken.  Cloud computing is een recente trend die verwijst naar het aanbieden van applicaties, systeemsoftware en hardware infrastructuur als online services op een elastische manier. Voorbeelden van eenvoudige cloud applicaties uit je dagdagelijkse leven zijn de services die Google en Microsoft aanbieden: Google Docs, Office Web Apps etc. We onderscheiden 3 varianten van cloud computing: 1) Infrastructure as a Service (IaaS) is het aanbieden van computer infrastructuur als een service, 2) Platform as a Service (PaaS) levert een platform waarop applicaties en services ontwikkeld en uitgevoerd kunnen worden, en 3) Software as a Service (SaaS) is een model voor het inzetten van software waarbij applicaties worden aangeboden als online services op aanvraag.  De overgang naar een cloud omgeving brengt heel wat architecturale gevolgen met zich mee. Zo zullen nu verschillende ziekenhuizen tegelijkertijd dezelfde service gebruiken die wordt aangeboden door de externe cloud provider. Welke software componenten mogen hierbij gedeeld worden tussen de verschillende ziekenhuizen en welke moeten strikt gescheiden worden? Hoe en waar wordt de data opgeslagen? Bovendien moet het mogelijk om gemakkelijk een nieuw ziekenhuis toe te voegen dat gebruik wil maken van de service.   Het doel van deze thesis is het ontwerpen en implementeren van een patient monitoring system (PMS) als SaaS applicatie bovenop een PaaS platform. We zullen hierbij vertrekken van de PMS architectuur die tijdens het vak Software Architectuur is ontworpen.  De eerste stap bestaat uit de studie van het concept cloud computing en de typische eigenschappen. Op basis van deze nieuwe requirements kunnen de use cases en het domein model van de PMS applicatie uitgebreid en aangepast worden. Vervolgens wordt de architectuur aangepast zodat deze geschikt is voor een cloud omgeving. Uiteindelijk is het de bedoeling dat een prototype van de PMS applicatie geimplementeerd wordt bovenop een PaaS platform. De keuze van dit PaaS platform zal afhangen van de specifieke vereisten en zal in samenspraak met de begeleider gekozen worden. In volgende iteraties kunnen bepaalde extra niet-functionele vereisten aan de architectuur en implementatie toegevoegd worden.    Literatuurstudie: studie van het concept Cloud Computing en de typische eigenschappen van cloud applicaties.  Uitbreiden en aanpassen van de use cases en domein model op basis van de nieuwe requirements voor het PMS, specifiek voor een cloud computing omgeving.  Aanpassen van de PMS architectuur.  Implementatie van een prototype bovenop een PaaS platform (bepaald op basis van vereisten en in samenspraak met begeleider).  Stappen 2 - 4 worden uitgevoerd in meerdere iteraties naargelang extra (niet-)functionele vereisten worden toegevoegd.    De thesis vereist goed inzicht en kennis van gedistribueerde systemen (cf. het vak Gedistribueerde Systemen) en software architectuur. Bovendien gaat deze thesis verder op de architectuur van het patient monitoring system (PMS) dat tijdens het vak Software Architectuur is ontworpen. Het is dan ook een vereiste dat je het vak Software Architectuur hebt gevolgd. Een groot deel van deze thesis bestaat ook uit praktisch implementatie-gericht werk.  Ben je een zelfstandige student en geinteresseerd in dit thesisonderwerp, neem dan zeker contact op met de contactpersoon voor een kort kennismakingsgesprek.    Cloud computing en SaaS:   The NIST Definition of Cloud Computing  Above the Clouds: A Berkeley View of Cloud Computing  Architecture Strategies for Catching the Long Tail  Enabling Multi-Tenancy: An Industrial Experience Report  A Framework for Native Multi-Tenancy Application Development and Management   Documentatie van enkele PaaS platformen:   Windows Azure  JBoss SteamCannon',no_work
'Middleware ondersteuning voor het bouwen van SaaS applicaties Stefan Walraven Wouter Joosen Stefan Walraven  Software as a Service (SaaS) is een variant van cloud computing waarbij software applicaties worden aangeboden als online services en de gebruikers (dit zijn organisaties en bedrijven)  enkel betalen voor wat ze effectief gebruiken (pay per use). Softwarebedrijven die voor het SaaS model kiezen, bouwen de SaaS applicatie vaak bovenop een Platform as a Service (PaaS). Een PaaS levert een online platform voor het ontwikkelen en uitvoeren van cloud applicaties (bv. Google App Engine en Windows Azure). Het platform zal hierbij de nodige infrastructuur-gerelateerde vereisten aanpakken, zoals beschikbaarheid en schaalbaarheid.  Het gebruik van een PaaS platform vereenvoudigt de implementatie van een SaaS applicatie, vooral op het gebied van infrastructuur en basisondersteuning. Er bestaan echter verschillende strategieen om een SaaS applicatie te bouwen. De keuze voor een specifieke architectuur hangt af van de applicatie zelf, de data in de applicatie, of de klant. Zo kan er bijvoorbeeld gebruik gemaakt worden van een schaalbare, gedistribueerde database die door alle klanten gedeeld wordt (het ?multi-tenancy? principe), of er kan per klant een nieuwe instantie van de applicatie gecreeerd worden (het traditionele ?single-tenancy?). Deze keuze heeft dus grote gevolgen voor de implementatie van de applicatie en brengt enorme complexiteit met zich mee. Zeker in het geval wanneer verschillende klanten een verschillende aanpak vereisen. De huidige PaaS platformen bieden hier echter geen ondersteuning voor: de softwarebedrijven moeten voor elke applicatie bepalen welke strategie of strategieen geschikt zijn en dan de nodige ondersteuning implementeren.   In deze thesis ontwikkelen we een middleware ter ondersteuning van het bouwen van SaaS applicaties. Deze middleware zal de verschillende implementatiestrategieen voor SaaS ondersteunen en de onderliggende complexiteit verbergen voor de software ontwikkelaars. Ze hoeven enkel voor elke applicatie aan te geven welke implementatie(s) ze vereisen. We bouwen deze middleware bovenop een bestaand PaaS platform.  De eerste stap in deze thesis bestaat uit de studie van het Saas model, de typische eigenschappen en de verschillende implementatiestrategieen (bv. multi-tenancy). Bijkomend zal er een specifiek PaaS platform gekozen worden waarop de middleware zal ontwikkeld worden. Deze keuze zal gemaakt worden in samenspraak met de begeleider. Vervolgens wordt een architectuur en implementatie uitgewerkt voor de middleware. Hierbij zal een iteratief proces worden toegepast waarbij telkens een nieuwe implementatiestrategie wordt toegevoegd. Modularisatie van de verschillende componenten en de middleware zelf zal een belangrijke rol spelen. De evaluatie van de thesis bestaat uit het ontwikkelen van een SaaS applicatie boven op de middleware en het uittesten van de verschillende implementatiestrategieen.    Literatuurstudie:   Studie van het concept SaaS, de typische eigenschappen en implementatiestrategieen.  Studie van een specifiek PaaS platform (bepaald in samenspraak met begeleider).   Ontwerpen en implementeren van de middleware op het geselecteerde PaaS platform. Dit is een iteratief proces waarbij in elke iteratie een extra implementatiestrategie voor SaaS wordt ondersteund.  Evaluatie: implementatie van een SaaS applicatie bovenop de middleware.    Je bent een zelfstandige en gemotiveerde student met een goede kennis van gedistribueerde systemen en component- & service-gebaseerde softwareontwikkeling (cf. het vak Gedistribueerde Systemen). Een groot deel van de thesis bestaat uit praktisch ontwikkelingswerk, maar je moet ook theoretisch kunnen werken om 1) inzicht te krijgen in de bestaande oplossingen en technieken, en 2) zelf een geschikte aanpak van het probleem voor te stellen.  Ben je geinteresseerd in dit thesisonderwerp, aarzel dan niet om contact op te nemen met de contactpersoon voor een kort kennismakingsgesprek.    SaaS en multi-tenancy:   The NIST Definition of Cloud Computing  Architecture Strategies for Catching the Long Tail  A Framework for Native Multi-Tenancy Application Development and Management  Enabling Multi-Tenancy: An Industrial Experience Report   Modularisatie technieken:   Aspect-Oriented Programming : bv.  AspectJ  en  Spring AOP  Dependency Injection (DI) : bv.  Spring IoC ,  CDI ,  Guice , en  Ninject   State of the practice (industrie):   Google:  Megastore ,  Namespaces API  Apprenda SaaSGrid  GigaSpaces   Documentatie van enkele PaaS platformen:   Windows Azure  JBoss SteamCannon',no_work
'Samen verkeer voorspellen Rutger Claes Tom Holvoet Rutger Claes  De huidige generatie route begeleiding gaat uit van een statische beschrijving van het wegennet, soms reeds aangevuld met real-time observaties, om reistijden van routes te berekenen.  Die berekende reistijden zullen onnauwkeurig zijn aangezien de verkeerssituatie kan wijzigen tussen het moment van de berekening en het moment dat de bestuurder effectief over de weg rijdt.  Omwille van deze dynamiek zullen reistijden gebaseerd op statische of real-time informatie leiden tot sub-optimale routes.  Beter zou zijn wanneer de route berekening vertrekt van de reistijden die de bestuurders effectief zullen ervaren.  Dit soort effectieve reistijden kunnen voorspeld worden met behulp van  een multi-agent systeem  waarin autonome software agenten van een type de wegen in het wegennet voorstellen en agenten van een tweede type de wagens in dat wegennet voorstellen.  De agenten die instaan voor de wegen gebruiken  machine learning  technieken om een model op te bouwen dat hen toelaat reistijden te voorspellen.  Deze modellen werken op basis van invoer die wordt aangeleverd door de agenten in de voertuigen.  Deze agenten samen zijn dan in staat om voertuigen te begeleiden gebruik makende van voorspelde reistijden.   In ons huidige onderzoek werken de agenten die instaan voor het aanleren van de modellen en leveren van de reistijden geisoleerd.  Ze krijgen informatie van de agenten die instaan voor de voertuigen, ze kunnen observaties maken in het wegen netwerk, maar ze wisselen onderling geen informatie uit.  Dit soort informatie uitwisseling zou hen in staat stellen hun modellen uit te breiden en ook informatie over naburige wegen op te nemen.  Deze uitbreiding bestaat uit twee aspecten: de modellen die de weg-agenten gebruiken moeten worden uitgebreid zodat ze de extra informatie aan kunnen en er moeten een uitwisseling van relevante informatie komen tussen de verschillende weg-agenten.  De samenwerking tussen de weg-agenten enerzijds en de voertuig-agenten anderzijds is gebaseerd op een biologisch geenspireerde coordinatie patroon genaamd delegate multi-agent systems, voor de samenwerking tussen de weg-agenten onderzoek je in deze thesis geschikte coordinatie patronen.  Een mogelijke  machine learning  techniek is het gebruik van artificiele neurale netwerken.   Concreet zal je vertrekken van een microscopisch verkeerssimulatie platform dat in staat is realistische verkeerssimulatie uit te voeren.  Bovenop dit platform zal je een multi-agent systeem ontwikkelen dat in staat is om wagens te begeleiden gebruik makend van voorspelde reistijden.  Dit simulatie platform zal je toelaten om verschillende aspecten van je oplossing te analyseren en te evalueren.  Voor dit thesis onderwerp zijn we op zoek naar gemotiveerde studenten.  Kennis van machine learning en multi-agent systemen is een voordeel maar is geen vereiste.  Studenten die geinteresseerd zijn in dit onderwerp nemen best eerst contact op met de begeleiders voor een kennismakingsgesprek.  	 		 			A Decentralized Approach for Anticipatory Vehicle Routing using Delegate Multi-Agent Systems, Rutger Claes, Tom Holvoet and Danny Weyns, Transactions on ITS		 	 	 		 			 http://people.cs.kuleuven.be/~rutger.claes/papers/rutger-claes-2009-tits.pdf 		 	 	 		 			GridLock: A Microscopic Traffic Simulation Platform, Rutger Claes and Tom Holvoet, 2011 MT-ITS		 	 	 		 			 http://people.cs.kuleuven.be/~rutger.claes/papers/rutger-claes-2011-mt-its.pdf 		 	 	 		 			An object-oriented neural network approach to short-term traffic forecasting, Hussein Dia, European Journal of Operational Research 131 - 2001, p. 253-261		 	 	 		 			 http://people.cs.kuleuven.be/~rutger.claes/papers/dia-ann.pdf',no_work
'TrafficDesk: Verkeer op je desktop Rutger Claes Tom Holvoet Rutger Claes  Er gebeurdt veel onderzoek naar coordinatie van verkeer.  Omdat dit soort coordinatie mechanismen moeilijk te implementeren zijn in de werkelijkheid gebeurdt de evaluatie en validatie vaak aan de hand van verkeerssimulaties.  Er bestaan dan ook een groot aantal verkeerssimulatie platformen.  Binnen onze onderzoeksgroep hebben we eigen microscopisch simulatie platform genaamd GridLock.  De evaluatie en validatie van coordinatie mechanismen kan gebeuren op verschillende platformen, hierdoor zullen de resultaten simulatie-platform-onafhankelijk en dus betrouwbaarder zijn.  Het toepassen van een coordinatie mechanisme bovenop verschillende platformen vereist een gemeenschappelijke interface voor al deze platformen.   Binnen deze thesis zal je een desktop applicatie ontwikkelen die gebruikers toelaat grootschalige verkeerssimulatie op te configureren.  Op basis van deze simulaties zal de applicatie toelaten coordinatie mechanismen en verkeersmaatregelen te evalueren.  Een mogelijke uitbreiding van deze thesis bestaat erin om de interactie tussen coordinatie mechanisme, desktop applicatie en verkeerssimulator te analyseren.  Op basis daarvan kan dan een generieke interface voor verkeerssimulaties worden uitgewerkt.  De interface moet de interactie tussen een coordinatie mechanisme en de simulatie toelaten.  De interface moet enerzijds voldoende generisch zijn om verschillende verkeerssimulatoren aan te sturen en moet anderzijds expressief genoeg zijn om een zo breed mogelijk gamma coordinatie mechanismen en verkeersmaatregelen te implementeren.  De interface moet ook toelaten relevante informatie uit de simulatie te extraheren om zo het verkeer te analyseren.   Het uitwerken van de interface kan gebeuren op basis van het GridLock simulatie platform.  Als voorbeeld van een coordinatie mechanisme kan gebruik gemaakt worden van  Anticipatory Vehicle Routing using Delegate Multi Agent Systems .  Voor de simulatie environment zal gebruik gemaakt worden van of het Netbeans platform of het Eclipse Rich Client Platform.  Op basis van een van deze frameworks zal een applicatie ontwikkeld worden die toelaat GridLock simulaties te configureren.  Indien de thesis door meerdere studenten wordt gekozen zullen de studenten de applicatie uitbreiden om ook een tweede simulatie platform aan te sturen.  Voor dit thesis onderwerp zijn we op zoek naar gemotiveerde studenten.  Studenten die geinteresseerd zijn in dit onderwerp nemen best eerst contact op met de begeleiders voor een kennismakingsgesprek.  	 		 			NetBeans IDE - NetBeans Rich-Client Platform Development		 	 	 		 			 http://platform.netbeans.org 		 	 	 		 			Eclipse Rich Client Platform		 	 	 		 			 http://wiki.eclipse.org/index.php/Rich_Client_Platform 		 	 	 		 			A Decentralized Approach for Anticipatory Vehicle Routing using Delegate Multi-Agent Systems, Rutger Claes, Tom Holvoet and Danny Weyns, Transactions on ITS		 	 	 		 			 http://people.cs.kuleuven.be/~rutger.claes/papers/rutger-claes-2009-tits.pdf 		 	 	 		 			GridLock: A Microscopic Traffic Simulation Platform, Rutger Claes and Tom Holvoet, 2011 MT-ITS		 	 	 		 			 http://people.cs.kuleuven.be/~rutger.claes/papers/rutger-claes-2011-mt-its.pdf',no_work
'Markov Random Field Structure Learning Jesse Davis Jesse Davis Parisa Kordjamshidi Markov networks are a formalism for compactly representing the joint probability distribution over a set of variables. Its power lies in the ability to exploit (conditional) independences among sets of variables in the data. Markov networks are often written as a weighted sum of features, where the features are conjunctions over the variables in the domain. Thus, the problem of learning the structure of a Markov network boils down to constructing the set of features. Most current approaches perform complex search procedures to construct the features. However, recent experiences for similar problems have shown that simple techniques, such as randomly generating features, often work well in practice. This thesis will explore the connection between various existing algorithms and see how they can be applied in the context of learning the structure of a Markov network. This thesis will explore the connection between various existing algorithms and see how they can be applied in the context of learning the structure of a Markov network. The tasks involved with this thesis are the following:      Explore random feature generation techniques for feature construction (e.g., like those employed in Schietgat et al., 2011).     Explore feature generation techniques based on association rule mining.     Select a relevant subset of datasets from an existing repository and run the experiments.  Interest in machine learning.  Comfortable with C++ or java.         Daniel Lowd and Jesse Davis. Learning Markov Network Structure with Decision Trees. Proceedings of the 10th IEEE International Conference on Data Mining (ICDM), 2010. Sydney, Australia.  Schietgat, L., Costa, F., Ramon, J., De Raedt, L. (2011). Effective feature construction by maximum common subgraph sampling. Machine Learning, 83 (2), 137-161.',no_work
'Monitoring van cloud-gebaseerde applicaties door middel van gedistribueerde event-aggregatie.  Wouter DeBorger Wouter Joosen Wouter DeBorger  Cloud computing ondersteunt de ontwikkeling van software op een ongekende schaal. Elastische schaalbaarheid, standaard API s en automatische implementatie laten toe om meer complexe software te bouwen. Maar cloud computing maakt het ook moeilijk om de uitvoering van dergelijke automatische implementaties te inspecteren en te controleren. Om te weten wat een cloud computing systeem daadwerkelijk aan het doen is, moet informatie worden verzameld uit verschillende bronnen en samengevoegd tot een begrijpelijk overzicht. In de huidige stand van de techniek zijn cloud inspectiesystemen niet in staat om dit te doen. Een eenvoudig voorbeeld is gedistribueerde verwerking van medische beeldmateriaal. Het beeldmateriaal, verkregen uit scans en microscopie, wordt geanalyseerd door een netwerk (cloud, grid of cluster) van rekenservers. Elke afbeelding volgt een specifieke workflow met verschillende stappen. De machines verdelen het werk autonoom onder elkaar. Het is echter belangrijk dat de operatoren en onderzoekers op elk moment weten waar elke afbeelding zich bevindt, in welke toestand en of de verwerking tijdig klaar zal zijn, of er geen afbeelding verloren gaat en zo verder. Deze informatie kan afgeleid worden uit de aankomst- en vertrektijden van afbeeldingen op verschillende machines voor verschillende verwerkingsstappen. Het doel van deze thesis is het omzetten van laag niveau gebeurtenissen zoals  Prent 7650 is aangekomen bij Server 75 voor actie 5  in zinvolle boodschappen zoals:  De scan van meneer Peeters zal niet op tijd klaar zijn .   Concreet ga je in deze thesis een bestaand inspectiesysteem combineren met een bestaand gedistribueerd informatie aggregatie systeem. Je zal gebruik maken van systemtap, een inspectiesysteem met support voor oa java, python en postgresql. Voor informatie aggregatie ga je gebruik gemaken van SpoVNet, een P2P, scalable, distributed event aggregation system. Deze combinatie zou moeten toelaten om events in een heterogene omgeving en op op een dynamische manier te verzamelen en te aggregeren op een schaalbare manier. Het ultieme doel is om op een cloud meerdere applicaties on-the-fly te kunnen inspecteren, in een per application, unified view.  Mogelijke use cases:     events detecteren die niet in de normale workflow zitten (find the hacker)   statistieken verzamelen per gebruiker     omniscience (verzamel voldoende informatie om de uitvoering achterwaarts af te spelen, zodat je fouten heel snel kan vinden)  visualiseer de huidige toestand van de applicatie      voorbereiding    korte studie van het related work    eerste testen met systemtap    eerste testen met spovnet      Milestone I    kleine test applicatie bouwen    system tap linken met spovnet    test       Milestone II    in overleg een doel kiezen, bijvoorbeeld een van de use cases.     Je bent een technisch vaardige en gemotiveerde student met een goed inzicht in gedistribueerde systemen. Bij deze thesis komt een stevige dosis implementatiewerk kijken. In deze thesis krijg je de kans om kennis te maken met een aantal krachtige tools in de Linux omgeving. Als je vlot nieuwe technieken aanleert zal het dus zeker een verrijkende ervaring zijn. Als je geinteresseerd bent in deze thesis aarzel dan niet om contact op te nemen met Wouter De Borger (w.deborger@gmail.com, lokaal 02.33)      http://sourceware.org/systemtap/    Cordies: Expressive event correlation in distributed systems    The Power of Events, Luckham (boek)    Dapper, a Large-Scale Distributed Systems Tracing Infrastructure, Sigelman, google',no_work
'Configuratie van SaaS via feature modellen Stefan Walraven Wouter Joosen Stefan Walraven  Software as a Service (SaaS) is een variant van cloud computing waarbij software applicaties worden aangeboden als online services en de gebruikers (dit zijn organisaties en bedrijven) enkel betalen voor wat ze effectief gebruiken (pay per use). Om te profiteren van de schaalvoordelen wordt dezelfde applicatie-instantie gedeeld tussen meerdere organisaties en bedrijven, tenants, genoemd, elk met hun eigen eindgebruikers (zoals klanten, werknemers...). Deze tenants hebben echter verschillende vereisten met betrekking tot de gedeelde applicatie. Daarom is het noodzakelijk dat een SaaS applicatie tenant-specifieke configuratie & customisatie ondersteunt: een tenant kan de applicatie aanpassen aan zijn specifieke noden zonder de andere tenants te beinvloeden.  Een vaak toegepaste manier om een softwareproduct met al zijn variaties (customisaties) voor te stellen is een feature model. Dit is een compacte representatie van een softwareproduct in termen van features en hun afhankelijkheden. Een feature is een specifieke karakteristiek of kwaliteit van een software systeem. Deze feature modellen worden vaak voorgesteld in de vorm van een feature diagram. De features van een webshop zijn bijvoorbeeld de catalogus, een betaalmodule met meerdere opties (kredietkaart of overschrijving), security, en een zoekfunctie. Bepaalde features kunnen verplicht zijn, andere optioneel; features kunnen ook van elkaar afhankelijk zijn of juist met elkaar conflicteren. Aan de hand van een feature model kan een klant de gewenste set van features selecteren (? configuratie van de applicatie) en wordt een geschikte variant van het softwareproduct samengesteld.   In deze thesis willen we nagaan of feature modellen geschikt zijn om tenant-specifieke configuratie van SaaS applicaties mogelijk te maken. Feature modellen zijn namelijk vrij statisch, terwijl een SaaS applicatie zeer dynamisch kan zijn (denk maar aan web service composities). Bovendien zijn er mogelijk customisaties vereist die niet voorgesteld kunnen worden in een feature model.  De eerste stap in deze thesis bestaat uit de studie van het SaaS model en de typische eigenschappen. Bijkomend wordt er gekeken naar relevante literatuur met betrekking tot feature modellen in een service-geori?nteerde context. In een tweede stap worden de relevante tenant-specifieke customisaties (van een SaaS applicatie) geidentificeerd op basis van een case study. Op basis van het voorgaande werk kan dan onderzocht worden of feature modellen geschikt zijn om tenant-specifieke configuratie mogelijk te maken. Uiteindelijk is het de bedoeling om verbeteringen voor te stellen en te implementeren voor de huidige aanpak zodat feature modellen geschikter worden voor het SaaS model.    Literatuurstudie:   Studie van het concept SaaS en zijn typische eigenschappen  Studie van feature modellen in een service-georienteerde context   Identificeren van de relevante tenant-specifieke customisaties van een SaaS applicatie op basis van een case study.  Evaluatie van de geschiktheid van feature modellen voor tenant-specifieke configuratie.  Uitbreiding van feature modellen, aangepast aan het SaaS model:   Voorstellen van verbeteringen voor de huidige aanpak;  Implementatie.     Een belangrijk deel van deze thesis bestaat uit de studie en evaluatie van feature modellen in een Software-as-a-Service (SaaS) context. Dit vereist o.a. goed inzicht en kennis van gedistribueerde systemen en service-gebaseerde softwareontwikkeling (cf. het vak Gedistribueerde Systemen). Bij het tweede deel komt er echter ook voldoende ontwikkelingswerk aan bod.  Ben je een zelfstandige student en geinteresseerd in dit thesisonderwerp, aarzel dan niet om contact op te nemen met de contactpersoon voor een kort kennismakingsgesprek.    SaaS:   Architecture Strategies for Catching the Long Tail  A Framework for Native Multi-Tenancy Application Development and Management  Customizing Enterprise Software as a Service Applications: Back-End Extension in a Multi-tenancy Environment  Customization Realization in Multi-tenant Web Applications: Case Studies from the Library Sector   Feature modellen:   Feature Oriented Domain Analysis (FODA)  Tools , bv. Pure::Variants  Service-Oriented Architectures and Software Product Lines  Service-Oriented Product Lines [ 1 ,  2 ]',no_work
'Inspectie van samengestelde bedrijfsapplicaties.  Wouter DeBorger Wouter Joosen Wouter DeBorger  Zoals je bij de practica van het vak Gedistribueerde Systemen al gemerkt zal hebben bied middelware (zoals JEE) heel wat nuttige ondersteuning aan, maar maakt het debuggen erg moeilijk. Tijdens het programmeren zie je niet veel van de middleware buiten de API en wat annotaties. In de debugger zie plots heel veel synthetische code opduiken, die erg moeilijk te begrijpen is.  Sommige bugs zijn daardoor erg moeilijk te vinden. Een veel gemaakte fout is bij voorbeeld het bijhouden van referenties naar entities nadat de transactie afgelopen is. Deze fout is erg moeilijk te detecteren omdat de debugger niet kan zeggen bij welke transactie de entity hoort. Ook problemen met RMI zijn moeilijk op lossen. Als men, met de huidige technologie, een RMI-applicatie debugt, kan men niet zien wat de stack-trace van een remote invocation is, omdat de twee helften van de stack op een andere machine te vinden zijn. Ook de waarde van velden van remote-object zijn moeilijk terug te vinden, omdat ze zich op een andere machine bevinden. De middleware die nuttige abstracties aanbiedt bij het ontwikkelen bemoeilijkt dus het debuggen, doordat de debugger de abstracties niet meer ondersteunt.  Het doel van deze thesis is een debugger te bouwen die JEE begrijpt en alle nuttige abstracties aan de gebruiker kan laten zien. Met een bestaande tool ga je de abstracties die je in een JEE omgeving terugvindt modelleren. Op basis van dit model kan dan automatisch een inspectie tool gegenereerd worden, die wel alle JEE abstracties, zoals entities, EJB s, containers en transacties kan laten zien.    Inwerkfase    leer de tools kennen    leer de interne werking van JEE kennen      Transactie support    breid een RMI debugger uit met support voor expliciete transactie demarcatie.      Verder doelen worden in overleg vastgelegd  Je bent gemotiveerd en technisch vaardig.  Bij deze thesis komt veel implementatiewerk kijken en je zal jezelf vertrouwd moeten maken met de interne werking van het JEE Glassfish platform.     Mirrors: Design Principles for Meta-level Facilities of Object-Oriented Programming Languages (Bracha)    A Generic and Reflective Debugging Architecture to Support Runtime Visibility and Traceability of Aspects (De Borger)',no_work
'Smart Twitter for Mobile Ad hoc Networks  Koosha Paridel Yolande Berbers Koosha Paridel Microblogging and social networks like Twitter are hot these days, but the concepts on which they are based, i.e. publish/subscribe systems, have been around for decades. You simply decide which tweets of people you follow by subscribing to certain people. The subscription model is fairly simple and the communication infrastructure is centralized. In this thesis, you will investigate how Twitter can be made smarter by enhancing the subscription model beyond matching tweets from certain people, and by developing communication/routing protocols for efficient distribution of the tweets in mobile ad hoc networks.  In this thesis, you will design an advanced subscription model for tweets that not only allows following tweets from certain people, but that also enables subscribing to tweets of anyone at a particular location (e.g. on the train to work), with a similar profile (e.g. friends or relatives) or interests (e.g. sharing a taxi at the airport), or tweeting about a particular topic (e.g. sports), etc. As such, the smart Twitter should be able to match tweets from people in a particular context.The second goal of this thesis is to design a routing scheme for a decentralised Twitter operating in a mobile ad hoc network on e.g. smartphones. The advantage of such an approach is that your followers will most likely be close-by, smoothening the path to face-to-face interactions. The disadvantage of ad hoc routing compared to a centralized infrastructure is that some interested followers mightnot receive your tweet, or that some people are flooded with routingrequests to forward the tweets. You will investigate ways for routing tweets efficiently, with efficiency e.g. measured in terms of network traffic and processing overhead, number of missed tweets, distance travelled by a tweet, effect of caching tweets, etc.  You will first study the basics of publish/subscribe systems and routing schemes for mobile ad hoc networks. You will thenimplement a basic microblogging service on top of an existing publish/subscribe middleware. Then you will propose a more versatile subscription model and implement a prototype with the necessary runtime support to handle the more complex tweet subscription matching process.As a last step, you will investigate communication strategies for routing tweets in a mobile ad hoc network, and test your solution on a real mobile phone or a network simulator to test with larger mobile ad hoc networks.  The student should be familiar with distributed computing and routing protocols.The daily supervision of this thesis will be in English    Survey of Publish Subscribe Event Systems   Distributed Event Routing in Publish/SubscribeCommunication Systems: a Survey',no_work
'Applicatie-niveau beveiliging voor Software-as-a-Service in de Cloud Bert Lagaisse Maarten Decat Wouter Joosen Bert Lagaisse Maarten Decat  Software wordt meer en meer aangeboden als een online, webgebaseerde service, daarbij vaak gebruikmakende van de cloud met als doel om de applicatie schaalbaar te maken. Security is essentieel voor de doorbraak van aanbieders van Software-as-a-Service, maar de nieuwe omgeving stelt ook nieuwe uitdagingen, vooral op het vlak van schaalbaarheid van de beveiligingsoplossing.    Deze thesis richt zich op gebruikersbeheer en access control. De  uitdagingen hierbij zijn tweevoudig: enerzijds is nood aan schaalbaar gebruikersbeheer voor de aanbieder van de service, de verschillende afnemers (zogenaamde tenants) en de grote hoeveelheid eindgebruikers. Het delegeren van gebruikersmanagement naar de tenant is daardoor cruciaal. Anderzijds is er ook nood aan een schaalbare security architectuur voor het evalueren van complexe en expressieve access control policies, die ook steeds vaker gebruik willen maken van application state.   In deze thesis onderzoek je, evalueer je en implementeer je enkele schaalbaarheidstechnieken voor deze problemen. Concreet onderzoek je de toepasbaarheid van enkele concepten uit bestaande beveilingsraamwerken zoals XACML 3.0 en ontwikkel je een beveilingsarchitectuur en prototype om aan de uitdagingen het hoofd te bieden.    Het doel van deze thesis is het onderzoeken van de vereisten van huidige SaaS applicaties, de architectuur van een passend access control mechanisme uit te werken en te verifieren aan de hand van een eigen implementatie. XACML 3.0 wordt gebruikt als basis.   Het onderzoek binnen deze thesis wordt toegepast op een reele case study, bijvoorbeeld omtrent e-document processing. Deze case study is een online software service, tegen betaling aangeboden door een SaaS provider, die door grote bedrijven wordt gebruikt om grote hoeveelheden gepersonaliseerde documenten te genereren en te distribueren. Typische voorbeelden zijn de maandelijkse fakturen van GSM-operatoren.    	Studie van SaaS requirements adhv literatuur en een case study.  	Evaluatie van state-of-the-art taak allocatie technieken (e.g. XACML 3.0) voor deze requirements.  	Opstellen van een eigen access control architectuur.  	Implementeren van proof-of-concept.  	Evaluatie van implementatie.   Deze thesis bestaat uit het uitwerken en implementeren van een access control architectuur voor SaaS applicaties in de cloud. Een stevige interesse en kennis van gedistribueerde systemen en software architectuur zijn vereist, alsook een sterke interesse in beveiliging. Zelfstandig kunnen werken aan de implementatie van een softwaresysteem is ook belangrijk.   Cloud computing:   Capturing the value of Cloud Computing, Boston Consultancy Group  Architecture Strategies for Catching the Long Tail  The NIST Definition of Cloud Computing   SaaS applicaties   Architecture strategies for catching the long tail   Access control   XACML 3.0  Distributed Authorization Middleware for Service-Oriented Architectures',no_work
'Agent code migration: a case study for PDP problems Ning Gui Tom Holvoet Ning Gui Multi-agent techniques are used to provide decentralized solutions for controlling large-scale, dynamic systems - e.g. for controlling a large number of vehicles that need to accomplish transport tasks for clients (package delivery service). Achieving efficient and effective collective behavior is difficult especially when systems exhibit temporal or regional heterogeneity. Thus, in order to deal with such problems, agents are required to fast evolve their behaviors for new environments. However, traditional AI based agent s learning process cannot effectively deal with such highly dynamic environments.  The goal of this thesis is to study the feasibility of agent behavior evolution by using so called code migration mechanism. An agent uses this mechanism to transfer part of its logics (in form of components), knowledge of local information collected from history, to other agents directly or through environments. In this way, other agents can query, select and integrate certain role components during run-time to achieve fast behavior evolution rather than learn everything from scratch. The PDP problem is used to evaluate the agent performance equipped with/without this mechanism.    Multi-agent techniques are used to provide decentralized solutions for controlling large-scale, dynamic systems - e.g. for controlling a large number of vehicles that need to accomplish transport tasks for clients (package delivery service). Achieving efficient and effective collective behavior is difficult for such systems as they normally exhibit temporal or regional heterogeneity. Agents with fixed adaptation features cannot effectively deal with such diversity. Large scale and high dynamicity demands agents to have the best matching (different) behaviors according to their working environments.  The term ?role? is proposed as an important abstraction for agent behavior. At different context, an agent performs different roles thus its behavior can be contextually changed [1]. The purpose of this thesis to apply the role-based agent techniques in the large-scale systems, more specifically, pick and delivery problem (PDP)[2]. Rather than using predefined agent behavior, this project is to investigate the feasibility in constructing an agent s behavior dynamically by integrating best matching roles (at the form of components) according to current context. Agents can also drop its roles (possibly optimized for certain sub-domain as forms of components to the environments. Other agents can pickup those roles when entering this region, thus fast behavior evolution can be achieved.   In this thesis, the PDP problem is suggested as the targeted problem and the MAS DiscoSim [3] developed in the previous project is suggested as the basic simulation platform to show the effect of dynamic role integration.   Tasks to do:   Analyze the heterogeneous effects of PDP problems;  Design software solution to support run-time role integration [4];   Design proper scenarios to best demonstrate the effect of run-time role integration  Implement the scenarios by MAS-DiscoSim.    Several scenarios should be considered:   Run-time role integration;   Agents drop and pickup role components to/from the enviroment ;   Agents collaborate with each other by playing different types of roles in DiscomSim     The tentative expectation of this thesis is to prove the feasibility to use agent behavior evolution to deal with dynamic and large-scale problems. A set of simulations will be designed and developed in this project. A set of comparison between with/without role migrations should be provided.   The student(s) is expected to have good understanding of Java. He/She should have good understanding on meta-programming (XML based). Previous programming experience with MAS-DiscoSim is preferred.   [1] L. Y. Liu and H. B. Zhu, "Implementing agent evolution with roles in collaborative systems, " Proceedings of the 2006 Ieee International Conference on Networking, Sensing and Control, pp. 819-824, 2006.    [2] S. Parragh, K. Doerner, and R. Hartl,  "A survey on pickup and delivery problems, " Journal of Betriebswirtschaft, vol. 58, pp. 81-117-117, 2008.    [3] J. V. Gompel, B. Tuts, R. Claes, M. C. Torres, and T. Holvoet. MAS-DiscoSim for PDP:a Testbed for Multi-Agent Solutions to PDPs. Available: http://distrinet.cs.kuleuven.be/software/agentwise/mas-discosim/    [4] A. Fuggetta, G. P. Picco, and G. Vigna,  "Understanding code mobility, " Ieee Transactions on Software Engineering, vol. 24, pp. 342-361, May 1998.',no_work
'Diagnosegeneratie op intensieve zorgen Jan Ramon Maurice Bruynooghe Jan Ramon Jelle VanEyck In een intensieve zorgen afdeling verblijven kritiek zieke patienten die ondersteuning van essentiele functies nodig hebben.  De intensieve verzorging en monitoring zorgt voor een grote hoeveelheid gegevens, zowel observaties (temperatuur, bloeddruk, ...) als rapporten van verpleegsters en artsen in tekstvorm.  Op het einde van het verblijf dient een rapport opgemaakt te worden dat alle diagnoses en behandelingen vermeldt. Het doel van deze thesis is het leren van een predictief model dat diagnoses afleidt uit de in de databank aanwezige gegevens. Deze thesis omvat volgende stappen:  Beknopte literatuurstudie en inwerking in het intensieve zorgen domein  Het modelleren van verbanden tussen tekstuele gegevens en monitoring data  Het ontwerpen van een ontologie voor de classificatie van diagnoses  Het leren van een predictief model dat diagnoses afleidt/voorspelt uit de tekst en monitoring data  Het ontwerpen van een algoritme dat kan aangeven over welke diagnoses meest onzekerheid bestaat, om zo efficient vragen te kunnen stellen en het model met domeinkennis van artsen te vervolledigen  Evaluatie   Interesse in data mining en logica.   Data mining in intensive care',no_work
'Taak- en component-allocatie op basis van domeinkennis voor SaaS applicaties in de cloud. Bert Lagaisse Wouter Joosen Bert Lagaisse Software wordt meer en meer aangeboden als een online web-gebaseerde service (Software as a service, SaaS). Om te kunnen scaleren naar een groot aantal gebruikers wordt daarom meer en meer gebruik gemaakt van cloud-technologie door de aanbieder: zowel in eigen datacenters (private clouds), alsook dmv publieke cloud platformen zoals Amazon EC2, Google App Engine of Microsoft Azure. Omwille van verschillende redenen zoals privacy of lokale wetgeving, moeten sommige taken en componenten in de software verplicht gebruik maken van het private data center voor hun uitvoering alsook voor hun data, terwijl andere taken en componenten kunnen gebruik maken van publieke cloud technologie. In dat geval spreken we van een hybrid cloud.  In deze thesis onderzoeken en ontwikkelen  we de nodige ondersteuning voor aanbieders van Software-as-a-Service  diensten, om gebruik te maken van meerdere cloud omgevingen (publiek en private) die zo naadloos op elkaar aansluiten tot een hybrid cloud. Meer specifiek zullen we in dit project een architectuur creeren , ontwikkelen, en bestuderen die statische en dynamische taak allocatie van software componenten (verspreid over meerdere cloud computing omgevingen) ondersteunt, en die hierbij domein-specifieke kennis in acht neemt.   Het onderzoek binnen deze thesis wordt toegepast op een reele case study omtrent e-document processing. Deze case study is een online software service, tegen betaling aangeboden door een SaaS provider, die door grote bedrijven wordt gebruikt om grote hoeveelheden gepersonaliseerde documenten te genereren en te distribueren via verschillende kanalen. Typische voorbeelden zijn de maandelijkse fakturen van GSM operatoren.De enorme piek aan uit te voeren taken, typisch op het einde van de maand vraagt om een hybrid cloud architectuur die naadloos de publieke cloud kan gebruiken, maar ook rekening houdt met privacy en lokale wetgeving omtrent financiele documenten.    	Studie van SaaS requirements adhv literatuur en de e-document processing case study.  	Evaluatie van state-of-the-art taak allocatie technieken voor deze requirements .  	Opstellen van een eigen taak allocatie architectuur.  	Implementeren van proof-of-concept.  	Evaluatie van implementatie.    Je bent een zelfstandige en gemotiveerde student met een goede kennis van gedistribueerde systemen en component- & service-gebaseerde softwareontwikkeling (cf. het vak Gedistribueerde Systemen). Een groot deel van de thesis bestaat uit praktisch ontwikkelingswerk, maar je moet ook theoretisch kunnen werken om 1) inzicht te krijgen in de bestaande oplossingen en technieken, en 2) zelf een geschikte aanpak van het probleem voor te stellen.  Ben je geinteresseerd in dit thesisonderwerp, aarzel dan niet om contact op te nemen met de contactpersoon voor een kort kennismakingsgesprek.    Cloud computing:    Capturing the value of Cloud Computing, Boston Consultancy Group   The NIST Definition of Cloud Computing  Architecture Strategies for Catching the Long Tail   Specifieke cloud platformen   Windows Azure  JBoss SteamCannon  Amazon Web Services LLC. Amazon Elastic Compute Cloud (Amazon EC2).  http://aws.amazon.com/ec2/  Google, Inc. Google App Engine.  http://code.google.com/appengine/     Onderzoeksliteratuur omtrent task allocation and scheduling:   Marek Wieczorek, Andreas Hoheisel, and Radu Prodan. Towards a general model of the multi-criteria workflow scheduling on the grid. Future Gener..Comput. Syst., 25(3):237-256, 2009.  Jia Yu, Rajkumar Buyya, and Kotagiri Ramamohanarao. Workflow scheduling algorithms for grid computing. In Metaheuristics for Scheduling in Distributed Computing Environments. Springer, 2008.  Tevfik Kosar and Mehmet Balman. A new paradigm: Data-aware scheduling in grid computing. Future Generation Computer Systems, 25(4):406-413, 2009.',no_work
'Verificatie van SPM s Raoul Strackx Jan Smans Bart Jacobs Raoul Strackx Jan Smans Persoonlijke gegevens, paswoorden, kredietkaartgegevens, ... allen worden ze dagelijks ingevuld in browsers of andere programma s uitvoerend op bestaande besturingssystemen. Hoewel we er allemaal vanuit gaan dat deze gegevens niet zomaar te grabbel gegooid worden, worden er dagelijks kwetsbaarheden ontdekt die dit mogelijk maken. Onderzoek aan de KULeuven probeert dit op twee wijzen tegelijk te verhinderen.Ten eerste wordt er onderzoek gedaan naar hoe programma s geverifieerd kunnen worden. Verificiatie laat toe om met mathematische zekerheid te garanderen dat het programma de gevoelige gegevens niet zal lekken. Hiervoor werd er een tool, VeriFast, geschreven dat zowel op het niveau van Java- of C-programma s werkt. De programmeur annoteert zijn code met extra informatie, en Verifast zal hem op mogelijke kwetsbaarheden wijzen.Hoewel deze aanpak zeer goed blijkt te werken, is het praktisch onbegonnen werk om bijvoorbeeld een volledig besturingssysteem te verifieren. Een tweede onderzoeksgebied aan de KULeuven focust hoe de trusted computing base (TCB), de code die minimaal vertrouwd moet worden, kan worden verkleind. Ook dit onderzoek blijkt veel belovend. Er werd reeds een maatregel ontwikkeld om de TCB (die bijvoorbeeld de kernel en de gebruikte applicatie bevat) terug te dringen van ettelijke miljoenen regels code naar een paar duizend. Hiervoor werd het concept van self-protecting modules ontwikkeld. Dit zijn kleine stukken code die de benodigde functionaliteit bevatten. Ze bieden bijvoorbeeld de mogelijkheid om een cryptografische handtekening te controleren waarbij zowel het cryptografische algoritme als de gebruikte sleutel in volledige isolatie met de rest van het systeem wordt uitgevoerd. Ook is het voor spm s mogelijk om met elkaar op een veilige manier te communiceren. Dit vereist echter een correcte werking van die spm s. Het doel van de thesis is om na te gaan hoe de correcte werking van spm s precies kunnen worden geverifieerd.  Studenten zullen binnen de thesis vooral gebruik maken van de C-programmeertaal om modules te bouwen en de VeriFast verifier om de correctheid van hun implementatie te verifieren. Studenten moeten zeker interesse hebben in de verificatie van C-programma s.   Verifast  Self-protecting modules',no_work
'Creatie van Self-Protecting Modules Raoul Strackx Frank Piessens Raoul Strackx Naarmate onze economie meer steunt op informaticasystemen, hoe belangrijker hun correcte werking worden. Het uitvoeren van onvertrouwde programma s in userspace is lang niet meer voldoende. Bestaande besturingssystemen voeren immers ettelijke miljoenen regels code uit met de hoogste privileges. De correctheid van deze code kan echter niet gegarandeerd worden. Bovendien wordt deze code voortdurend uitgebreid, bijvoorbeeld met device drivers voor het aansturen van nieuwe hardware.Aan de KULeuven wordt onderzoek gedaan hoe deze problemen vermeden kunnen worden. De trusted computing base (TCB), de software die vertrouwd moet worden zoals in veel gevallen het besturingssysteem, werd reeds gereduceerd van ettelijke miljoenen regels code naar ettelijke duizenden. Bovendien is het mogelijk om bepaalde stukken software slechts gedeeltelijk te vertrouwen. Hiervoor werd het concept van self-protecting modules (SPM s) geintroduceerd. Dit zijn kleine stukken code die de benodigde functionaliteit bevatten. Ze bieden bijvoorbeeld de mogelijkheid om een cryptografische handtekening te controleren waarbij zowel het cryptografische algoritme als de gebruikte sleutel in volledige isolatie met de rest van het systeem wordt uitgevoerd. De creatie van deze SPM s vormt echter nog een probleem. Vooraleer deze naadloos in bestaande systemen kunnen worden gebruikt, wordt van de programmeur enkele aanpassingen op assembly niveau verwacht.  Het doel van deze thesis is deze creatie te automatiseren en/of enkele SPM s te implementeren.  De student zal tijdens zijn thesis in contact komen met zowel de implementatie van modules in assembly en de C-programmeertaal als de automatische creatie van dergelijke modules vanuit dynamische bibliotheken. Studenten moeten enige kennis hebben van low-level implementatiedetails en/of de C-programmeertaal, en/of moeten bereid zijn zich verder in dergelijke low-level details te verdiepen.   Self-protecting modules',no_work
'Ontwerp een grafische tool voor subobject-oriented programming.  Marko vanDooren Dave Clarke Marko vanDooren  Klassen zijn fundamentele elementen in objectgerichte programmeertalen, maar ze kunnen niet gebouwd worden door andere klassen samen te stellen. Daardoor wordt veel boilerplate code voor bijvoorbeeld associaties en grafen steeds opnieuw geschreven. Het onderstaande Java fragment van een routeringsapplicatie illustreert dit.    class  City {  City(String name) { this .name = name;}  String name;  String getName() { return  name;}  Set<Road> roads =  new  HashSet<Road>();  Set<Road> roads() { return   new  HashSet<Road>( this .roads);}   void  registerRoad(Road road) { this .roads.add(road);}   void  unregisterRoad(Road road) { this .roads.remove(road);}   double  distanceTo(City destination) {    Set<City> done =  new  HashSet<City>();     // assume that the order of Pair is defined by the second element     PriorityQueue<Pair<City,Double>> distances =        new  PriorityQueue<Pair<City,Double>>();    Pair<City,Double> uPair =  new  Pair<City,Double>( this ,0d);     while (uPair !=  null ) {      City u = uPair.left();       if (u.equals(destination)) {         return  uPair.right();      }       if (! done.contains(u)) {        done.add(u);         double  distance = uPair.right();         for (Road road: roads()) {          City target = road.otherEnd(u);            if (! done.contains(target)) {             double  newDistance = distance + road.length();            Pair<City,Double> newPair =                 new  Pair<City,Double>(target,newDistance);            distances.add(newPair);          }        }      }      uPair = distances.poll();    }     return  -1d;  }}    <span style="color:',no_work
'Ontwerp een raamwerk for refactoring  Marko vanDooren Eric Steegmans Marko vanDooren  Een probleem met bestaande refactoring tools is dat ze ofwel voor 1 enkele programmeertaal werken, ofwel voor een zeer beperkte verzameling van programmeertalen. Voor elke nieuwe programmeertaal moet daarom steeds een nieuwe refactoring tool ontwikkeld worden,  en als een taal aangepast wordt, dan moeten de bestaande refactoring tools ook aangepast worden. De oorzaak van dit probleem ligt in een te sterke koppeling tussen de programmeertaal en de refactoring tool. Daardoor werkt de refactoring tool niet meer voor andere talen, hoewel veel refactorings onafhankelijk zijn van de specifieke eigenschappen van een programmeertaal.  Een gevolg hiervan is dat bestaande refactoring tools vaak niet correct werken. Netbeans en IntelliJ controleren bijvoorbeeld niet correct op naam conflicten bij het hernoemen van variabelen, en Eclipse wil bij het hernoemen van methode wel eens een conflict geven in ongerelateerde code. De oorzaak van dit probleem ligt in het dupliceren van de regels van een taal in iedere refactoring tool. De complexiteit van deze regels zorgt voor een heel aantal bugs terwijl een refactoring tool eigenlijk zou moeten focussen op de refactorings en niet op het implementeren van de regels van een programmeertaal.  Chameleon is een raamwerk voor metamodellen. Dit raamwerk biedt klassen aan om taalconstructies te modelleren zoals methodes, variabelen, klassen, ... . Een concrete implementatie voor een taal kan deze klassen rechtstreeks gebruiken, of subklassen maken indien nodig. Door in een tool enkel gebruik te maken van de klassen uit het raamwerk, kan deze tool zonder aanpassingen gebruikt worden met verschillende taalmodules.   In deze thesis zul je een aantal refactorings onderzoeken en nagaan welke abstracties nodig zijn in het Chameleon raamwerk om deze te ondersteunen.  Je zal een ontwerp en implementatie maken voor de ontbrekende functionaliteit. Hierbij zul je per refactoring onderzoeken of de  functionaliteit afhankelijk is van enkel de taal, enkel de refactoring, beiden, of geen van beiden. Deze classificatie zal je toelaten om de functionaliteit in de correcte component te implementeren zodat het geheel schaalbaar blijft.   Je hebt een sterke interesse voor programmeertalen, en het ontwerpen van uitbreidbare software.       Refactoring : Improving the Design of Existing Code by Martin Fowler     Workshop on Refactoring Tools at OOPSLA 2008     Chameleon : hoofdstuk 4 van het  doctoraat  van Marko van Dooren',no_work
'Leerbaarheid van geometrische vormen Jan Ramon Maurice Bruynooghe Jan Ramon Thomas Fannes Recent is er in toenemende mate aandacht voor het herkennen van afbeeldingen.  Vaak wordt gezocht naar specifieke eigenschappen die men kan gebruiken om in bepaalde herkenningstaken te slagen.  Bv. vaak zoekt men naar characteristieke pixelpatronen of specifieke kleuren.  In deze thesis willen we een nieuwe weg inslaan en computationele geometrie combineren met leertheorie.  Meer bepaald willen we voor een aantal predictiesettings nagaan of ze vanuit theoretisch oogpunt efficient te leren zijn. De leerbaarheid van een aantal klassen geometrische objecten en ruimtelijke relaties bepalen Deze thesis is eerder theoretisch georienteerd.  De bedoeling is om volgende stappen te volgen:  Literatuurstudie machine learning theorie  Studie van de leerbaarheid (complexiteit, garanties op nauwkeurigheid, ...) voor een aantal predictiesettings met toenemende complexiteit, o.a.:  Het leren van ruimtelijke relaties (afstanden, hoeken) tussen een vast aantal punten  Het leren van ruimtelijke relaties tussen een vast aantal punten uit 2D projecties  Het leren van ruimtelijke relaties van een object t.o.v. een variabel aantal andere objecten.  Het leren van ruimtelijke relaties van een object t.o.v. een variabel aantal andere objecten die op hun beurt weer aan onderlinge relaties voldoen.  ...   Optioneel, vooral indien in voorgaande stap onoverkomelijke theoretische moeilijkheden zouden opduiken, implementatie en experimentele evaluatie van een aantal basis-leeralgoritmen voor het leren van ruimtelijke relaties.   Interesse in wiskunde, o.a. lineaire algebra en kansrekenen. Vooral literatuur uit de volgende domeinen is relevant:   Computational geometry  Learning theory, PAC learning',no_work
'Sensoren in Mobile Devices voor Computer Graphics Ares Lagae Philip Dutre Ares Lagae Mobile devices zoals de iPhone, de iPad en de Android Phone hebben naast een (of soms zelfs twee) camera s een aantal andere sensoren aan boord, zoals een accelerometer, een proximity sensor en een ambient light sensor, die nuttige informatie kunnen opleveren voor tal van toepassingen in Computer Graphics. Met de informatie van deze sensoren kan bijvoorbeeld een 3D controller gebouwd worden, die vervolgens kan gebruikt worden om te navigeren in een virtuele omgeving (bv. een first person shooter game), of om individuele beelden samen te assembleren tot een panorama of een environment map. In deze thesis zullen de mogelijkheden van dergelijke sensoren in mobiele devices voor toepassingen in Computer Graphics onderzocht worden.  Het doel van deze thesis is het ontwerp, de implementatie, en de evaluatie van een Computer Graphics toepassing die de mogelijkheden van de sensoren in een mobile device benut. Het werk van deze thesis bestaat uit een studie van de programmatie van het mobile device; een literatuurstudie van de Computer Graphics toepassing; het ontwerp, de implementatie, en de evaluatie van de toepassing.  De cursus Computer Graphics is vereist. Ervaring met C en/of C++ (en eventueel Objective C) is een pluspunt. Ervaring met een mobile device is een pluspunt. De relevante literatuur is afhankelijk van de keuze van de gebruikte technieken in Natural Language Processing en Computer Graphics. Neem contact op voor meer informatie.',no_work
'Text naar 3D Ares Lagae Philip Dutre Ares Lagae Er zijn verschillende manieren om 3D content te creeren in Computer Graphics: handmatig met een editor, uitgande van een voorbeeld, ... Er is echter nagenoeg geen werk dat 3D content creeert uitgaande van tekst. In deze thesis zal een proof-of-concept systeem ontworpen en geimplementeerd worden dat text als invoer gebruikt om 3D content te creeren. Hiervoor zijn verschillende mogelijkheden: het creeren van een virtuele 3D omgeving aan de hand van tekst-invoer (bv. second-life), Het genereren van een foto-montage van text (bv. voor de automatische illustratie van verhaaltjes), het genereren van een strip van text, of zelfs het genereren van een eigen episode van je favoriete serie (bv. uitgaande van reeds bestaande episodes met ondertiteling). Een belangrijk deel van deze thesis is de keuze van de toepassing, die uitdagend maar toch haalbaar moet zijn. Hiervoor zal een degelijke literatuurstudie (zowel in Natural Language Processing als in Computer Graphics) nodig zijn.  Het doel van deze thesis is het ontwerp en de de implementatie van een proof-of-concept systeem dat text als invoer gebruikt om 3D content te creeren.  Een belangrijk deel van de uitwerking van deze thesis is de keuze van de toepassing, die uitdagend maar toch haalbaar moet zijn. Hiervoor zal een degelijke literatuurstudie (zowel in Natural Language Processing als in Computer Graphics) nodig zijn.  De cursus Computer Graphics is vereist. De cursus Natural Language Processing is vereist. Ervaring met C en/of C++ is een pluspunt.  De relevante literatuur is afhankelijk van de keuze van de gebruikte technieken in Natural Language Processing en Computer Graphics. Neem contact op voor meer informatie.',no_work
'Improving security of Web Browsers Francesco Gadaleta Wouter Joosen Francesco Gadaleta The exponential growth of web services made web browsers the most used application today. Web browsers are more and more complex pieces of software which not only support the traditional features to surf regular web pages, but also include 3D engines, virtual machines for interpreted languages (eg. C',no_work
'Solving different variants of PDP by Delegate MAS Shaza Hanif Tom Holvoet Shaza Hanif Multiagent systems are distributed systems that are composed of mul- tiple interacting autonomous elements called agents. Delegate MAS is a coordina- tion mechanism between agents that help agents coordinate utilizing only locally available knowledge. Pick up and Delivery problem (PDP) is an optimization problem faced by transportation companies in which loads have to be transported from origins to destinations by a set of vehicles.  PDP is a very diverse problem and a variety of solutions are proposed in past to solve it. The static solutions (discrete optimization solutions) consider that all the transportation requests are known and an optimal schedule is obtained after applying the solution. Dynamic PDP offers additional challenges, since transportation requests are continually arriving and vehicles have to dynamically schedule them. Each request is defined by a pickup and delivery location as well as a time window in which a package has to be delivered.    The dynamic PDP can be solved by considering various problem setting.  For instance by varying (1) the locations of package origin and destinations,  (2) the capacities of vehicles, (3) time windows of packages. All the mentioned aspects can have huge impact on performance of a solution. e.g. it is possible that a solution is suitable for diverse kinds of package distributions but it is very sensitive to time windows.    We consider that it is possible that if problem setting is varied, a delegate MAS design would give different results. We want to investigate a delegate MAS design by varying different aspects of the problem e.g. distribution of transportation requests in the environment or varying vehicle capacity.  Currently, we are working on a basic implementation of the solution for PDP that uses delegate MAS as a coordination mechanism. We want the student(s) to investigate (and then improve) this particular design of Delegate MAS by varying different aspects of the problem. For instance, distribution of transportation requests (i.e request clusters, or uniformly distributed) in the environments can have impact on behavior of agents which in turn effects the performance of solution. Similarly, if capacity of vehicles is increased (from 1 load), the agents will interact differently because they can schedule to pick up two requests and then deliver them.  Work Constitution     Literature Study: 30%   Programming/Implementation: 40%    Expermentation: 30%    Good motivation for work, Interest in Multiagent Systems is a plus but not mandatory The students are requested to contact and communicate with the supervisor before selecting the topic.      M. Wooldridge (Eds.), An Introduction to MultiAgent Systems, ISBN:0470519460 9780470519462, Wiley, 2009.    T. Holvoet and P. Valckenaers:  Exploiting the Environment for Coordinating Agent Intentions , in Environments for Multiagent Systems III, ser. LNCS, 4389. Springer, 2006.     Jelle Van Gompel, Bart Tuts, Rutger Claes, Mario Henrique Cruz Torres, Tom Holvoet,  MAS-DisCoSim 4 PDP: A testbed for multi-agent solutions to PDPs  , Proceedings of the 9th International Conference on Autonomous Agents and Multiagent Systems, pages 1-2,  2010   M. W. P. Savelsbergh and M. Sol.  The general pickup and delivery problem.  Transportation Science, 29(1):17?29, 1995.',no_work
'Does it matter how agents coordinate? Shaza Hanif Tom Holvoet Shaza Hanif Multiagent systems are distributed systems that are composed of multiple interacting autonomous elements called agents. Coordination between agents helps them to manage inter-dependencies between their activities.  To evaluate different coordination mechanisms we will apply them in  problem, Pick up and Delivery problem. Pick up and Delivery problem (PDP) is an optimization problem faced by transportation companies in which loads have to be transported from origins to destinations by a set of vehicles.   We want to investigate what could be the effect of using different coordination mechanisms, when all the rest of features of solution are similar. Our particular focus is on comparing Delegate MAS with auction protocols.  The proposal is to investigate what is the role of different kinds of coordination mechanisms between agents. We want to evaluate that is delegate MAS really better then others? Can we provide any scientific evidence for it. We want to compare delegate MAS with best available auction protocol in the similar problem setting. The problem domain is Pickup and delivery problem.  Work Constitution     Literature Study: 20%   Programming/Implementation: 60%    Expermentation: 20%    Good motivation for work, Interest in Multiagent Systems is a plus but not mandatory The students are requested to contact and communicate with the supervisor before selecting the topic.      M. Wooldridge (Eds.), An Introduction to MultiAgent Systems, ISBN:0470519460 9780470519462, Wiley, 2009.    T. Holvoet and P. Valckenaers:  Exploiting the Environment for Coordinating Agent Intentions , in Environments for Multiagent Systems III, ser. LNCS, 4389. Springer, 2006.     M. W. P. Savelsbergh and M. Sol.  The general pickup and delivery problem.  Transportation Science, 29(1):17?29, 1995.',no_work
'Een IDE voor kennisgebaseerde software engineering Broes DeCat Marc Denecker Broes DeCat In de onderzoeksgroep KRR wordt een kennisbanksysteem ontwikkeld: een systeem dat toelaat kennis te formuleren op een declaratieve manier en die kennis te gebruiken voor allerlei problem solving taken, zoals oplossen van schedulingsproblemen, ontwerpen van configuratiesoftware, ... De kennisrepresentatietaal die we gebruiken is FO(.) en het kennisbanksysteem is IDP. Tot op heden maakt de software enkel gebruik van tekstfiles waarin de kennis wordt geformuleerd. Dit is ongeschikt voor grotere projecten, die vaak bestaan uit een aantal modulaire componenten. Onder andere syntactische fouten, inconsistenties tussen verschillende componenten en verlies van een globaal overzicht zijn vaak voorkomende problemen. Deze klachten zijn welbekend en kunnen opgelost worden door gebruik te maken van een ontwikkelingsomgeving. Zo n ontwikkelingsomgeving biedt de mogelijkheid om de kennisbank op een overzichtelijke en modulaire wijze op te bouwen. De kennisbank bestaat uit 5 belangrijke componenten: vocabularia (declaraties van de kennis), logische theori?en (axioma s), data (de concrete gegevens), inferentietechnieken (aangeboden problem-solving operaties) en een integrerende procedurele laag (in de programmeertaal Lua). Al deze componenten moeten op een begrijpbare manier worden voorgesteld (volgens hun respectievelijke formaat en inhoud) en moeten met elkaar kunnen worden verbonden om informatie uit te wisselen (relaties in een vocabularium kunnen bijvoorbeeld worden gebruikt in een logische theorie).  Daarbovenop maakt het kennisbanksysteem geavanceerde ideeen mogelijk zoals:  - Auto-completion  - Syntax Highlighting  - Detecteren van syntactische en semantische fouten  - Het integreren met de kennisgebaseerde visualisatietool IDPDraw, waarmee logische structuren heel overzichtelijk kunnen worden weergegeven. Dit zou dan neerkomen op een soort gui-editor (programma om gui s in te schrijven).  - We gebruiken momenteel een ASCII voorstelling van de taal FO(.), een beperking opgelegd door het gebruik van tekstfiles. De universele quantor wordt bijvoorbeeld geschreven als "!". Een ontwikkelomgeving maakt het mogelijk om dit alles weer te geven op de natuurlijke, symbolische manier, wat de leesbaarheid erg ten goede zou komen.  - Vertaling van logica naar natuurlijke taal, commentaar weergeven bij hover over de juiste subformule, ... hoort allemaal bij de mogelijkheden. Het ontwerpen en implementeren van een Eclipse-plugin voor het kennisbanksysteem gebaseerd op FO(.). De IDE zal de gebruikers ondersteunen in het gebruik van software om kennis voor te stellen, te gebruiken, te debuggen en te visualiseren om het software-engineering proces zoveel mogelijk te verbeteren. Na een introductie tot de taal FO(.) en de reeds beschikbare software, met name IDP (modelgeneratie-systeem) en IDPDraw (visualisatie-tool), wordt een ontwerp van een ontwikkelomgeving uitgewerkt. De nadruk zal liggen op gebruiksgemak en uitbreidbaarheid. Naderhand wordt de omgeving ook effectief ontwikkeld als een plugin in de Eclipse IDE, geschreven in Java. De student zal zich toeleggen op het ontwerp van een IDE voor een nieuw programmeerparadigma (kennisgebaseerde software). Ervaring met zowel software design, ontwerp van GUI s als ervaring met Eclipse - het Eclipse plugin systeem zijn belangrijke pluspunten.  Interesse in onderzoek naar de gebruikersnoden in een kennisgebaseerde programmeeromgeving. Goede kennis van Java is een vereiste. De belangrijkste systemen met verwante functionaliteit zijn  - het ProB systeem (http://www.stups.uni-duesseldorf.de/ProB)  - LogicPalet(http://www.logicpalet.com)  - iGROM (http://marketplace.eclipse.org/content/igrom)   - ASPIDE (https://www.mat.unical.it/ricca/aspide).',no_work
'General game playing met relational reinforcement learning Guy VandenBroeck Luc DeRaedt Kurt Driessens Guy VandenBroeck Kurt Driessens Hoewel de computerspeler Deep Blue van de wereldkampioen schaak kon winnen, heeft hij geen idee hoe hij dammen of poker moet spelen. Deep Blue vertoont dus een zeer beperkte vorm van intelligent gedrag. In general game playing probeert men af te stappen van gespecialiseerde algoritmes en een speler te creeren die goed is in elk spel. Om daarin the slagen moeten general game players verschillende domeinen van de artificiele intelligentie, zoals machine learning, kennisrepresentatie en beslissingstheorie, combineren tot een sterk geheel. Sinds 2005 organiseert AAAI een general game playing competitie. De deelnemende computerspelers krijgen daar een reeks ongeziene spellen gepresenteerd, beschreven in de Game Description Language. De spellen kunnen single- of multi-player zijn, in een 2- of 3-dimensionale wereld, enz. De deelnemer die over alle spellen heen de meeste punten haalt wint de competitie. Het doel van deze thesis is om een general game player te ontwikkelen die kan deelnemen aan de AAAI general game playing competitie. In een vorige thesis is een eerste general game player ontwikkeld die gebruik maakt van een algoritme dat op efficiente wijze een spelboom doorzoekt naar goede acties (Monte-Carlo Tree Search) en rond een relationeel leersysteem dat in staat is om spelsituaties te evalueren, gebruik makend van Relational Reinforcement Learning. De student die deze thesis toegewezen krijgt zal zich eerst vertrouwd moeten maken met dit werk. Vervolgens wordt gekeken naar nuttige uitbreidingen, zoals online leren van het relationeel model of alternatieve zoekstrategieen, om tenslotte deel te nemen aan de competitie Interesse in machine learning en AI is belangrijk. Dit eindwerk vereist een mix van theoretische uitwerking van de algoritmes, implementatie en experimentele evaluatie.  Overzicht van de AAAI Competitie      Game Description Language     http://en.wikipedia.org/wiki/General_Game_Playing     http://www.general-game-playing.de/',no_work
'Probabilistic predicate invention Angelika Kimmig Luc DeRaedt Angelika Kimmig Many artificial intelligence systems rely on knowledge about the domain of interest, often in the form of rules. For instance, rules of the form "eagle if two-legged and wings and beak and tail and golden-colored" or "blackbird if wings and tail and black-colored and beak and two-legged" could be used to classify animals based on some of their properties. Such detailed rules can be easily extracted from examples of animals for which basic properties as well as the type are known. However, it would be both more natural and more compact to use rules "eagle if bird and golden-colored" and "blackbird if bird and black-colored", and a general rule "bird if two-legged and wings and beak and tail" that could then also be used to define additional types of birds without repeating the full definition each time. Inventing additional predicates such as "bird" is a challenging task, as the number of possibilities is enormous and not all of them are meaningful or useful -- think for instance of "golden-colored and tail" as a definition of a new predicate in the example. One way of choosing between potential new predicates is based on the minimum description length principle: a predicate is more useful if it makes the overall encoding of all rules shorter. While this approach has been successfully used to create compact rule sets, it has an important shortcoming: it results in crisp, logical rules and cannot easily deal with probabilistic or uncertain information. Similar ideas have also been used to compress networks of relationships between entities, where rule bodies correspond to subgraph patterns, and predicates correspond to new nodes representing a collapsed instance of such a pattern. Again, taking probabilistic information into account would be very useful, as it would for instance provide a way to score approximate matches. The goal of this thesis is to develop a system that performs predicate invention to learn propositional rules in a probabilistic setting.  The work will be based on approaches from both rule learning and network compression. Starting from a literature study, suitable methods for taking into account probabilistic information will be developed, implemented, and experimentally evaluated. interest in machine learning, logic, and reasoning under uncertainty   S. Muggleton. Duce, an Oracle-Based Approach to Constructive Induction. In Proc. Tenth International Joint Conference on Artificial Intelligence, pages 287-292, 1987.  D. J. Cook and L. B. Holder (1994). Substructure Discovery Using Minimum Description Length and Background Knowledge. JAIR, Volume 1, pages 231-255.',no_work
'Relationeel leren voor voetbalgerelateerde voorspellingen Guy VandenBroeck Hendrik Blockeel Guy VandenBroeck  De voetbalwereld heeft de afgelopen twee decennia een ware revolutie ondergaan onder impuls van een forse financiele injectie door lucratieve overeenkomsten met commerciele partners en tv-zenders af te sluiten. Deze financiele injectie heeft voor een sterk toegenomen interesse in een meer wetenschappelijke benadering van het voetbal gezorgd. Bestuurders van voetbalclubs trachten weloverwogen financiele beslissingen te nemen en voetbaltrainers trachten de prestaties van hun team te verbeteren met behulp van uitvoerige analyses. Gokkantoren slagen er dankzij voorspellingsmodellen in om grof geld te verdienen aan sportweddenschappen.  Een aantal bedrijven hebben daarom technieken ontwikkeld om op efficiente wijze statistieken van voetbalwedstrijden te verzamelen. Deze statistieken kunnen nadien gebruikt worden om de prestatie van een speler of team te analyseren. Bestuurders kunnen deze informatie bijvoorbeeld gebruiken om te beslissen of de speler die ze op het oog hebben wel in hun team past. Voetbaltrainers kunnen er een beroep op doen om de beste opstelling voor de volgende wedstrijd te bepalen of om na te gaan welke spelers rust kunnen gebruiken. Ook voor gokkantoren kunnen dergelijke statistieken interessant zijn. Zij zijn er immers op uit om hun  betting odds  zo accuraat mogelijk te bepalen en bijgevolg ook hun winsten te optimaliseren.   Tijdens het academiejaar 2010-2011 werd in het kader van een masterproef een relationeel voorspellingsmodel uitgewerkt waarmee karakteristieken van voetbalwedstrijden (bijvoorbeeld de einduitslag) voorspeld kunnen worden. Het doel in deze masterproef is om dit voorspellingsmodel verder uit te werken om accuratere en geavanceerdere voorspellingen mogelijk te maken. In het voetbal zijn immers vele onderlinge relaties aanwezig. Sommige spelers staan er bijvoorbeeld voor bekend om erg complementair te zijn terwijl anderen dan weer moeilijk samen in dezelfde ploeg passen. Voetbalclubs zouden gericht op zoek kunnen gaan naar nieuwe spelers als ze dergelijke relaties reeds op voorhand kunnen voorspellen.   De student zal zich in eerste instantie moeten verdiepen in het reeds bestaande voorspellingsmodel. Dit omvat een studie van het eigenlijke voorspellingsmodel en kLog, de logische relationele taal waarin het voorspellingsmodel ontwikkeld werd. Daarnaast kan het interessant zijn om in de literatuur op zoek te gaan naar gerelateerd onderzoek.  Verbeteren van het voorspellingsmodel  Het voorspellingsmodel maakt geen gebruik van ruwe statistieken, maar steunt op een aantal prestatie-indicatoren. Deze indicatoren worden afgeleid uit de beschikbare statistieken en zouden een goed beeld moeten vormen van de prestaties van een speler of team. Het is aan de student om de bestaande indicatoren te bestuderen en nieuwe indicatoren (eventueel verbeteringen van bestaande indicatoren) te bedenken en uit te proberen.  Uitbreiden van het voorspellingsmodel  Het bestaande voorspellingsmodel is in staat om karakteristieken van voetbalwedstrijden te voorspellen, maar kan geen relaties tussen spelers en/of teams voorspellen. Het is aan de student om het voorspellingsmodel uit te breiden zodat ook (complexe) relaties voorspeld kunnen worden.  Interesse in en kennis van machine learning, meer specifiek in relationeel leren.',no_work
'Zoeken naar Cliques in Netwerken Siegfried Nijssen Luc DeRaedt Siegfried Nijssen Siegfried Nijssen Tias Guns Wanneer een groep knopen in een netwerk veel onderlinge verbindingen heeft, is dit vaak een aanwijzing dat deze knopen een belangrijke functie vervullen in het netwerk: in sociale netwerken zijn dit communities van gebruikers; in netwerken van eiwitten zijn dit complexen die in samenhang een biologische functie vervullen. Gezien het belang in verschillende toepassingen, is er recentelijk onderzoek gedaan naar het zoeken van dit soort groepen van knopen, die ook wel (quasi)-cliques genoemd worden. Deze eerdere methoden zijn echter vaak toegespitst op een specifieke formalisering van het probleem. Als gevolg hiervan is het vaak niet triviaal om ze aan te passen als er aanvullende informatie beschikbaar is of er aanvullenden wensen zijn: in sociale netwerken kan men bijvoorbeeld geinteresseerd zijn in groepen van knopen die niet alleen veel onderlinge verbindingen hebben, maar ook eenzelfde opleiding gevolgd hebben. In dit project willen we onderzoeken of eerdere methoden gegeneraliseerd kunnen worden in een algemeen raamwerk. Hierdoor zou de analyse van dit soort netwerken eenvoudiger moeten worden. Het uitgangspunt hierbij zijn algemene constraint programming methoden die we in eerder data mining onderzoek gebruikt hebben. Het ontwikkelen van (quasi-)clique mining methoden binnen een constraint programming raamwerk.  Het onderzoek zal beginnen met een studie van enkele eerdere algoritmen voor het vinden quasi-cliques en ons eerder onderzoek naar het gebruik van constraint programming in data mining. Vervolgens zal bestudeerd worden hoe deze methoden binnen een constraint programming raamwerk gebracht kunnen worden. Met de resulterende aanpak zullen experimenten uitgevoerd worden op netwerk data; in overleg met de student kan dit sociale netwerk data of biologische data zijn. Een belangrijke uitdaging is de aanpak voldoende efficient te maken om met grotere netwerken om te springen. In de latere fase van het project kan gekeken worden naar verfijningen die de oplossingssnelheid verhogen en naar uitbreidingen om met complexere constraints om te springen. De implementatie zal in C++ plaats vinden. Je moet dus bereid zijn in deze taal te implementeren.Het project heeft formele en algoritmische aspecten. Je moet dus geinteresseerd zijn in algoritmiek en niet terugschrikken voor wiskundige bewijzen. Luc De Raedt, Tias Guns, Siegfried Nijssen: Constraint programming for itemset mining. KDD 2008: 204-212.Guimei Liu, Limsoon Wong: Effective Pruning Techniques for Mining Quasi-Cliques. ECML/PKDD (2) 2008: 33-49.',no_work
'Interactief Voorspellers Leren: Zijn Mensen en Computers Samen Slimmer? Siegfried Nijssen Luc DeRaedt Siegfried Nijssen Siegfried Nijssen Tias Guns Het vinden van voorspellingsmodellen is een belangrijk probleem in machine learning. Regelsystemen zijn hier in het bijzonder interessant: ze geven niet alleen voorspellingen, maar ook  interpreteerbare verklaringen voor deze voorspellingen. Een creditcardmaatschappij zou zo n model bijvoorbeeld kunnen gebruiken om niet alleen te voorspellen of een klant geaccepteerd moetworden, maar ook een duidelijke verklaring krijgen waarom sommige klanten afgewezen of toegelaten worden - iets dat in dit soort toepassingen tegenwoordig van groot belang is.Het doel van regel leren (rule-learning) is dan ook meestal een voorspellingsmodel te bouwen dat niet alleen accuraat, maar ook inzichtvol en interpreteerbaar is. Traditioneel worden regelmodellen echter door machine learning algoritmen geleerd zonder interactie met de gebruiker; het algoritme gebruikt een ingebouwde heuristiek om een goede regel te vinden, en een andere heuristiek om deze regel met eerder gevonden regels te combineren. Je kunt dan ook argumenteren dat de interpreteerbaarheid van dit soort modellen tekort schiet.Recentelijk hebben wij efficiente technieken ontwikkeld die toelaten om op een exhaustive manier te zoeken naar goede regels die aan bepaalde randvoorwaarden (constraints) voldoen. Deze techniek zou het mogelijk kunnen maken dat een gebruiker, gegeven zijn domein kennis, zelf de beste regel selecteert, randvoorwaarden aan dit soort regels opgeeft, alsook de manier aangeeft waarop deze gecombineerd moet worden met de anderen. In dit project willen we een alternatieve, interactieve aanpak onderzoeken voor het bouwen van een regelgebaseerd voorspellingsmodel. Hierbij zou de computer interessante regels filteren uit een grote hoeveelheid kandidaten, waarna de mens de meest toepasselijke selecteert. We willen nagaan in hoeverre mate deze combinatie leid tot betekenisvollere en accuratere voorspellingsmodellen. Er zal een interactief programma ontwikkeld worden waarin verschillende randvoorwaarden voor regels kunnen opgegeven worden. Het zoeken naar regels zal gebeuren op basis van een bestaand constraint programming framework[1]. De gevonden regels kunnen op verschillende manieren gepresenteerd worden, waarbij de randvoorwaarden verder aangepast kunnen worden. Met behulp van zulke regels zal de gebruiker een voorspellingsmodel bouwen. Hierbij kan onderzocht worden hoe de gebruiker kan geholpen worden in het selecteren van een goede regel. Het uiteindelijke voorspellingsmodel zal vergeleken met de modellen die klassieke algoritmen leren. De hypothese die onderzocht zal worden is of interactief regel leren tot betere, mogelijk zelfs kleinere en accuratere modellen leidt, ook in toepassingen waar de data analyst niet vertrouwd mee is.  Je hebt een grote interesse in Artifici?le Intelligentie, meer ?bepaald in het voorspellen met behulp van regels. De thesis bevat een grote implementatie en integratie-component, waarbij de student niet terugschikt van meerdere programmeer- en scripttalen. Er zal bijgelezen moeten worden over constraint programming en machine learning technieken, en er zal experimenteel vergeleken worden met bestaande systemen zoals Weka.  1. Siegfried Nijssen, Tias Guns, Luc De Raedt. Correlated Pattern Mining in ROC Space: A Constraint Programming Approach. KDD, 2009.2. Johannes F?rnkranz, Peter A. Flach. ROC n rule learning: towards a better understanding of covering algorithms. ML Journal, 2005.3. Malcolm Ware, Eibe Frank, Geoffrey Holmes, Mark Hall, Ian H. Witten: Interactive machine learning: letting users build classifiers. Int. J. Hum.-Comput. Stud, 2001.4. Julien Blanchard, Fabrice Guillet, Henri Briand. Interactive visual exploration of association rules with rule-focusing methodology. KAIS Journal, 2007.',no_work
'Zoeken naar verzamelingen transcriptiefactoren in DNA Siegfried Nijssen Luc DeRaedt Siegfried Nijssen Siegfried Nijssen Tias Guns De expressie van genen kan door een complexe interactie van transcriptiefactoren beinvloed worden. Deze transcriptiefactoren - eiwitten - hechten zich "upstream" van een gen en brengen hiermee gezamenlijk de expressie van het gen op gang. Een belangrijke vraag in de bioinformatica is het op basis van data achterhalen van zowel de transcriptiefactoren als hun aanhechtingsplaatsen. Een mogelijke aanpak bestaat uit de volgende twee stappen. 1. Voor een gegeven aantal kandidaat-transcriptiefactoren wordt per sequentie de aanhechtingsplaats in de sequentie bepaald. Het resultaat is per sequentie een verzameling aanhechtende transcriptiefactoren.  2. Er wordt gezocht naar combinaties van transcriptiefactoren die in meerdere sequentiesvan interesse samen voorkomen; dit zijn mogelijk de transcriptiefactorendie samen voor het waargenomen effect zorgen.  In deze aanpak is het zeer belangrijk dat stap 1 voldoendeaanhechtingsplaatsen vindt; stap 2 kan ze tenslotte niet alsnog detecteren. Aan de andere kant mogen dit er ook niet te veel zijn; dit kan het zoekproces voor stap 2 bemoeilijken. De afstelling van deze twee fasen is dus van groot practisch belang en is de context waarin dit eindwerk plaats vindt. Het uitgangspunt is dat voor de berekening in fase 1 al programma s beschikbaar zijn die een onzekerheid toekennen aan voorspelde aanhechtingsplaatsen. In een eerdere aanpak werd er een grenswaarde op deze onzekerheid gezet, maar het blijkt in de praktijk lastig om een goede grenswaarde te bepalen.  Dit eindwerk vindt plaats in samenwerking met het Centre of Microbial and Plant Genetics van de KU Leuven (prof. Kathleen Marchal). In dit project wordt een nieuwe aanpak voor de identificatie van verzamelingen transcriptiefactoren ontwikkeld, wat tot een beter inzicht zal leiden in de regulatie van genen.In meer detail zal fase 2 in het hierboven beschreven proces verbeterd worden. In tegenstelling tot de eerdere methode zal de nieuwe methode om kunnen springen met de onzekerheden in fase 1 bepaald. Hierdoor zal het niet langer nodig zijn om een grenswaarde te bepalen en worden de resultaten betrouwbaarder.In deze aanpak zal gebruik gemaakt worden van Constraint Programming, een techniek voor het oplossen van zoek problemen ontwikkeld in de kunstmatige intelligentie.  Het project zal beginnen met het bestuderen van gerelateerd werk en het doen van enkele experimenten met bestaande programma s. Het doel hiervan is dat je vertrouwd raakt met het probleemgebied. Vervolgens wordt op basis van deze programma s een nieuw programma ontwikkeld.  Je hebt een interesse in bioinformatica en artificiele intelligentie.De implementatie zal in een combinatie van meerdere programmeertalen plaatsvinden; enige flexibiliteit hierin is dus gewenst.  1. L. De Raedt, T. Guns, and S. Nijssen (2008) Constraint programming for itemset mining. Proceedings of the 14th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining.2. T. Guns, H. Sun, S. Nijssen, K. Marchal, L. De Raedt (2010)  Cis-regulatory module detection using constraint programming. Proceedings of IEEE International Conference on Bioinformatics and Biomedicine.3. H. Sun, T. De Bie, V. Storms, Q. Fu, T. Dhollander, K. Lemmens, A. Verstuyf, B. De Moor, K. Marchal, K. (2009) ModuleDigger: an itemset mining framework for the detection of cis-regulatory modules. BMC Bioinformatics, 10 Suppl 1, S30.4. R. Sharan, T. Ovcharenko, A. Ben-Hur, and R.M. Karp, (2003) CREME: a framework for identifying cis-regulatory modules in human-mouse conserved segments. Bioinformatics, 19 Suppl 1, i283-291.',no_work
'Vergelijking modeleringskracht en performantie: NoSQL vs relationele gegevensbanken, een case study Frans VanAssche Nik Corthaut Erik Duval Frans VanAssche Nik Corthaut Toekomstige leeromgevingen zullen meer en meer gebruik maken van Web 2.0 en Web 3.0 applicaties, welke op hun beurt gebruik maken van leerobjecten, personen, gebeurtenissen, etc die beschikbaar zijn via het internet. Een belangrijke uitdaging is het modelleren en representeren van de gegevens. Recente ontwikkelingen  in dit gebied zijn bijvoorbeeld  linked data , semantic web,... De vraag is echter wat de beste  back-end  technologie is om die representaties in leeromgevingen te ondersteunen in  real-life  situaties. Dit is een van de technische uitdagingen in het internationale iTEC project. Het doel van deze thesis is om inzicht te verwerven in de modelleringskracht en performantie van NoSQL en RDB beheersystemen. In deze thesis werk zet je verschillende gegevensbeheersystemen op (zoals bijv. Postgres, BerkelyDB, Jena/Sesame RDF stores, ?) gegeven het iTEC datamodel. Daarbij heb je aandacht voor de verschilpunten in het vertalen van het datamodel naar de concrete implementaties. In de volgende stap ga je een performantie-analyse uitvoeren waarbij je nagaat welke systemen goed presteren, onder welke omstandigheden en wat mogelijke optimisaties zijn. Gegevensbanken 2 wordt aanbevolen   http://itec.eun.org/  Het Europese project waarin dit onderwerp kadert  http://en.wikipedia.org/wiki/NoSQL_(concept)  http://en.wikipedia.org/wiki/Relational_database_management_system',no_work
'Actief leren in een machine learning experiment database Sicco Verwer Gitte Vanwinckelen Hendrik Blockeel Sicco Verwer Sicco Verwer Gitte Vanwinckelen Declaratieve experimentatie is een onderzoeksgebied dat zich bezig houdt met de vraag of computers gebruikt kunnen worden om automatisch experimenten op te zetten. Een computerprogramma kiest zelf de juiste experimenten op basis van een gegeven vraag (gedeclareerd door de gebruiker). Elk experiment kan gezien worden als een toets van een bepaalde hypothese, voor elke hypothese dient een geschikt experiment geselecteerd te worden. De techniek van active learning kan gebruikt worden om deze selectie uit te voeren. Active learning is een onderdeel van machine learning waar het leeralgoritme vragen kan stellen aan een orakel (de uitvoerende van het experiment). Door vragen te stellen die zo informatief mogelijk zijn wordt het aantal benodigde vragen geminimaliseerd. Bij experimentatie is het echter vaak van belang dat de resultaten gelden met een van te voren vastgestelde statistische zekerheid. De vraag is of actief leren gebruikt kan worden om ook deze statistische zekerheid te garanderen. Een probleem wat hierbij een rol gaat spelen is dat het stellen van meer vragen (het testen van meerdere hypothesen) de statistische zekerheid van het uiteindelijke antwoord negatief beinvloed. Een methode ontwikkelen voor actief leren met statistische zekerheid. Na een literatuurstudie rond active learning en multiple hypothesis testing, dient de student een voorstel te doen over hoe deze twee gecombineerd kunnen worden. De student implementeert vervolgens een actief leeralgoritme met begrende statistische zekerheid voor de vraag welk algoritme het beste presteert op een gegeven dataset. Dit algoritme zal worden getoetst met behulp van de experiment database, een uitgebreide verzameling van machine learning experimenten. Kennis van, of sterke interesse in, machine learning en statistiek. Goed kunnen omgaan met algoritmen is belangrijk. Literatuur rond active learning, multiple hypothesis testing, en experiment databases.',no_work
'Het construeren van een leeralgortime voor een generatief taalmodel van netwerken. Sicco Verwer Hendrik Blockeel Sicco Verwer Sicco Verwer Grafen vormen een uiterst expressief en precies formalisme om objecten en hun relaties te omschrijven. In veel toepassingen zoals bio-informatica en webtechnologie worden grafen gebruikt om inzicht te verschaffen in de relaties tussen proteinen of personen. Machine learning methoden zoals graph mining kunnen gebruikt worden om interessante patronen in dit soort netwerken te vinden. De vraag is of we deze patronen ook kunnen gebruiken om een generatief model voor netwerken te maken. Zo n model vormt een kansverdeling over netwerken wat erg nuttig is om classifiers te maken, statistische toetsen uit te voeren, mogelijke netwerken te genereren, en inzicht te verschaffen in verschillende typen netwerk structuren. Een bekend type generatief model voor grafen is de zogeheten graaf grammatica. Deze ziet een graaf als een zin uit een taal en door het toepassen van kleine locale aanpassingen van patronen kan zo n zin herschreven worden naar een andere zin of graaf. Op deze manier kunnen erg complexe netwerkstructuren ontstaan. Het construeren van een leeralgoritme voor een generatief taalmodel van netwerken. Dit onderzoek is praktisch van aard. Na een literatuurstudie rond graph grammars, graph mining en grammatical inference (het leren van talen), zal de student proberen om een grammatica voor een gegeven verzameling netwerken te maken. De student dient hiervoor graph mining te gebruiken om een geschikte verzameling patronen te vinden en vervolgens een graph grammar te construeren die deze patronen herschrijft. Deze grammatica wordt geleerd door gebruik te maken van bekende taal leer methoden. Het uiteindelijke leeralgoritme zal worden getoetst op netwerk data.  Kennis van, of sterke interesse in, machine learning, formele talen, en graaf theorie. Goed kunnen omgaan met algoritmen is belangrijk. Literatuur rond graph mining, graph grammars, en grammatical inference.',no_work
'A study of lightweight software verification methods Dave Clarke Marc Denecker Dave Clarke Marc Denecker Dave Clarke Marc Denecker Context:Formal verification methods are of importance for building mission critical software and hardware. While proving correctness is a problem that cannot be fully automated (some subproblems such as proving termination are undecidable), there is now a thriving research area in which "lightweight verification methods" are being developed. Such methods were studied in the course Modelling of Complex Systems. Well-known examples of lightweight methods are systems such as Alloy and Maude. These systems are fully automatic but incomplete: they might be able to prove incorrectness of a system, but they cannot guarantee correctness to an absolute degree, they can only give a degree of confidence. Lightweight methods (and verification methods in general) differ on many different levels: they use different languages and methodologies for specifying dynamic systems and propositions to be verified. They implement different forms of inference. E.g., Alloy uses an object-oriented dialect of classical logic and finite model generation for guided simulation and bounded verification of propositions. The Action language as seen in the course MCS is an integration of the best of several worlds: techniques from the AI field of Knowledge Representation, and techniques from formal methods such as Alloy and NuSMV. The thesis aims at gaining a better understanding of the different methods in this field. The goal of the thesis is to make a comparative study of several lightweight software verification systems and methodologies. The comparison is with respect to aspects such as the quality of the language and the methodology, available verification or inference methods, efficiency and user-friendliness of the tools, etc. These aspects are evaluated in the context of sizable case study. A selection is made of lightweight verification methods and tools. The student familiarises with these methods and compares them in the context of a case study. Research-oriented, interest in formal languages and methods, and in verification.    Alloy   Maude   NuSMV   Logic in Computer Science by Michael Huth and Mark Ryan   Knowledge, Representation and Reasoning by R. Brachman en H. Levesque',no_work
'Service selection on the Clouds: a coordination based approach MarioHenrique CruzTorres Tom Holvoet MarioHenrique CruzTorres Cloud computing has taken the IT world. Researchers are studying how tocreate software systems that can benefit from the available resourcesoffered by cloud providers. Services are a natural way to design systemsthat will be deployed on cloud environments. However there are stillmany questions to solve, before business can really benefit from cloudcomputing. In this thesis you will study how selecting different services which aredeployed on different cloud providers influence the quality of service(QoS) of a system, regarding its availability, costs, etc.You will investigate the benefits and shortcomings of replicatingservices in different cloud providers. First you will get acquainted with at least two cloud providers, such as Google Apps and Amazon EC2. Then you will design and deploy simpleservices on the selected cloud providers. You will design a system that uses a number of these services.Your system will use different selection mechanisms to select whichservice should be used every time a new request arrives at your system. You can imagine that this system can be a video transformation tool that maintains different algorithms on different services deployed on the cloud.Then you will perform a number of experiments to see how reliable,efficient, costly, etc. it is to use services on cloud providers.After defining, implementing, and deploying the scenarios, you willreport which coordination strategy works better in the setting that you defined, giving detailed explanations for each case. The student should be proficient in JAVA and Object Oriented Programming. The student should also be willing to learn about how to program on cloud environments and about decentralized coordination mechanisms. Service oriented architectures: approaches, technologies and researchissues (article)Author Mike P. Papazoglou and Willem-Jan van den Heuvelarmbrust2009acbAbove the Clouds: A Berkeley View of Cloud Computing (techreport)AuthorMichael Armbrust and Armando Fox and Rean Griffith and Anthony D. Josephand Randy Katz and Andy Konwinski and Gunho Lee and David Patterson andAriel Rabkin and Ion Stoica and Matei ZahariaPatterns of Delegate MASAuthorTom Holvoet and Danny Weyns and Paul Valckenaers',no_work
'?What did I do wrong??: Interactive learning of regions of interest in medical images Laura Antanas Fabian.Guiza+med.kuleuven.be Martijn VanOtterlo Luc DeRaedt Fabian.Guiza+med.kuleuven.be Laura Antanas Martijn VanOtterlo Fabian.Guiza+med.kuleuven.be Intensive care medicine allows patients to survive lethal situations, through the use of monitoring systems, medications and mechanical devices. In the university hospital of K.U. Leuven , tissue samples from patients are routinely collected to perform laboratory analysis. Changes in tissue at the cellular level are indicative of intensive care related illnesses. First, currently the analysis of images from biopsies is performed manually by domain experts. This work is labor intensive and prone to subjective interpretation. It would therefore benefit from automatic image analysis techniques which would reduce workload, but also provide an objective and standardized way to extract information of interest from images. In this thesis we aim at automatically identifying zones of interest in microscopical images. Specifically we want to develop a system which, given an image, can highlight the regions with properties of interest to the user. An example of such an image is given below.As a possible approach, we propose to employ a learning module to train a model (e.g. a classifier) which can then be used to classify parts of the image. The model can be learned by providing examples of parts in the image. Because collecting such training data is a potentially expensive process, we propose an interactive learning setting. The user is actively involved during the learningprocess, by manually removing and adding new examples via an graphical interface, to optimize the model.Another possible approach is to see the system as a computed-aided decision support framework for parameter selection of an given model, according to the image content. The user introduces manually, via a graphical interface, his feedback on the predictions made by the model. Based on this, the learning algorithm can adjust the parameter values of the model by inferring user preferences.  Step 1: literature study on the meaning of the images from a medical point of view, image processing methods and on the two possible approaches. Step 2: decide on the best approach. Step 3: build a graphical interface for example/preference selection and extract relevant features from these and convert them in a chosen representational format. Step 4: build the learning algorithmor preference function, according to the decision taken in step 2. Knowledge or interest in image processing and machine learning. Matlab/C programming skills are an asset. 1. Kapoor, A., Grauman, K., Urtasun, R., Darrell, T. (2007). Active learning with Gaussian processes for object categorization. 2. Vincent Martin, Monique Thonnat, Nicolas Maillot: A Learning Approach for Adaptive Image Segmentation (2006).   3. Li Chen , Pearl Pu. Survey of Preference Elicitation Methods (2004).  4. ?Features for histology images?: http://www.google.be/url?sa=t&amp;source=web&amp;cd=6&amp;ved=0CFMQFjAF&amp;url=http%3A%2F%2Fwww.informed.unal.edu.co%2Fjccaicedo%2Fdocs%2Freview.pdf&amp;rct=j&amp;q=About%20features%20in%20optical%20histological%20images&amp;ei=ssu2TefZF8yhOpObrb0P&amp;usg=AFQjCNGD0wwitvXsooaU4toi7GTmft38wg&amp;sig2=MsaDpyEj5g3YqxHPveD4YQ&amp;cad=rja',no_work
'A machine learning assistant for writing good term papers Oleksandr Kolomiyets Sien Moens Steven Bethard Oleksandr Kolomiyets Many students feel challenged when they need to write a term paper.  Good title? Self-expressing abstract? Proper wording? Enough and proper references? These are not the full list of criteria how a paper is evaluated. Wouldn t it be easier to employ a machine that automatically guides the author and provides the hints on what needs to be changed to become a ?good? term paper? The student(s) will study the features common to high quality research papers, implement such features in a machine learning model, use the model to automatically distinguish low and high quality papers, and automatically identify sections of a paper that could be improved. The student(s) will have to: 1) collect a set of research papers either through an existing repository or through web crawling techniques, 2) identify objective measures of "good" and "bad" papers, e.g. high citation count vs. low citation count, or highly-ranked conference  vs. low-ranked workshop, 3) construct a number of distinctive features from the article text, by running existing natural language processing tools, 4) apply "off the shelf" machine learning tools to train a classifier given the features and objective labels, 5) evaluate the classifier based on its ability to predict the quality of new articles, and to explain which features and sections of the document need the most improvement. The student should be proficient in Java or C. The Natural Language Processing or Text Based Information Retrieval courses are recommended.  Kakkonen, T., Myller, N., Sutinen, E., & Timonen, J. (2008).  Comparison of Dimension Reduction Methods for Automated Essay Grading . Educational Technology & Society, 11(3), 275?288.    Sebastian de la Chica, Faisal Ahmad, Tamara Sumner, James H. Martin, and Kirsten Butcher. 2008.  Computational foundations for personalizing instruction with digital libraries . Int. J. Digit. Libr. 9, 1 (August 2008), 3-18.  Jill Burstein, Martin Chodorow, and Claudia Leacock. 2004.  Automated essay evaluation: the criterion online writing service . AI Mag. 25, 3 (September 2004), 27-36.  Hendrik P. Van Dalen and Kene Henkens. 2001.  What makes a scientific article influential? The case of demographers .Scientometrics. Volume 50, Number 3, 455-482.',no_work
'Fast Average Neighborhood Margin Maximization for Text Document Categorization Sien Moens Sien Moens Adhemar Bultheel Juan Carlos Gomez   Average Neighborhood Margin Maximization (ANMM) is an extension of Linear Discriminant Analysis (LDA) where the goal is to reduce the dimensionality of the data by means of a linear transformation, producing a new set of ?transformed features?; then, it is expected to obtain a better separation of the data in this new transformed space. In ANMM the general idea is to reduce the dimensionality of the data by pulling the neighboring points with the same class label towards it as near as possible, while simultaneously pushing the neighboring points with different labels away from it as far as possible. Nevertheless, there exist several drawbacks with this method for being applied in text document categorization, where the number of original features (terms) is large, and the time to perform all the computations is huge.   The idea of this thesis is to propose a framework by developing and implementing efficient and fast techniques to perform the hard computation parts of the method in the scope of text document categorization and to test the efficiency of the features extracted with ANMM in comparison with other features.  There are four main processes to be focused on: the finding of the closest neighbors, the inversion of a matrix, the singular value decomposition and the classification using the ANMM features.The classification task using the ANMM features could be tested using standard corpora like Reuters-21578, 20-Newsgroups, BBC and TechTC-100.  The student must be familiar with Java programming, MatLab programming and some knowledge of numerical analysis; and is interested in numerical analysis, text mining and machine learning. Gomez, J.-C., Boiy, E. & Moens, M.-F. (2011). Highly Discriminative Statistical Features for Email Classification. Knowledge and Information Systems (in press).',no_work
'Augment Japan! Sten Govaerts Bram Vandeputte Erik Duval Sten Govaerts Bram Vandeputte Er bestaat reeds een augmented reality (AR) vertaalapplicatie om Spaans-Engels te vertalen:  Word Lens . We willen dit nu uitbreiden naar andere talen, die niet met het Latijnse alfabet werken, bv. Japans, Koreaans of Chinees. Dergelijke applicaties zijn uiteraard erg handig op reis en aangezien je dikwijls nog meer "lost in translation" bent als je ook het alfabet niet kan lezen, willen we dit proberen. Ideaal gezien loop je met je iPhone of Android door Akihabara (het electronica district in Tokyo) en vindt je m.b.v de vertalingen van jouw applicatie de goedkoopste prijs voor de laatste nieuwe camera of je favoriete sushi op de menukaart in een cosplay restaurant.De keuze van de Aziatische taal is momenteel nog vrij en te bepalen in samenspraak met de begeleiders. Naast een applicatie voor smartphones kan er ook gekozen worden voor het gebruik van  een VR bril . Het doel van deze thesis is het ontwerp, de implementatie en de evaluatie van een mobiele AR applicatie voor de real-time vertaling van een Aziatische taal. De aanpak is tweevoudig. Je zal een literatuurstudie doen, waarin je kennis vergaart over karakterherkenning, bestaande libraries voor karakterherkenning, vertalingslibraries, etc. Er zal ook gekeken worden naar bestaande AR applicaties, hun UI en usability. Dit zal dienen als voedingsbodem voor je eigen ontwerp en implementatie. Het is de bedoeling om in de mate van het mogelijke bestaande libraries aan te wenden om tot een oplossing te komen. Er is al behoorlijk wat onderzoek gedaan naar karakterherkenning voor Chinees en Japans (dit is ook bv standaard beschikbaar op de iPhone voor het schrijven van Chinese en Japanse karakters). De vertaling kan gebeuren via online vertaalservices (bv.  Google Translate ). De evaluatie zal gebeuren op 2 niveaus: de karakterherkenning en vertaling kan geevalueerd worden door een corpus van vertaalde zinnen en de usability van de uiteindelijke applicatie zal geevalueerd worden met gebruikers. De focus van de oplossing kan gekozen worden in samenspraak met je begeleiders, bv. een focus op de gebruikersinterface. Interesse voor talen, usability en design is gewenst.   Richard Romero, Robert Berger, Robert Thibadeau, and Dave Touretsky, Neural Network Classifiers for Optical Chinese Character Recognition,  link .  Word Lens demo',no_work
'Evolutionary Feature Selection in Text Document Categorization Sien Moens Sien Moens Adhemar Bultheel Juan Carlos Gomez   In Feature Selection (FS), given a set d of features and a dataset, the aim is to find out a subset l of the most representative features of the dataset according to some objective function or a given criterion. There are several well known FS methods like Chi-square and Information Gain, which are effective for selecting features in order to separate classes of text documents.   The goal of this thesis is to create a framework for FS by using an Evolutionary Algorithm (EA) in charge of evolving into a set of features which better describes a dataset and discriminates between its classes, given an objective (fitness) function. The idea is to create populations (sets) of selected features (in combination with other FS methods) which are tested in text document categorization using an automatic classifier in order to know whether a given set is better than other. As a result, we will obtain a set of features with an efficient classification performance. The classification tests to evaluate the performance of a given set of features could be tested using standard corpora like Reuters-21578, 20-Newsgroups, BBC and TechTC-100.  The student must be familiar with Java programming and MatLab programming; and is interested in evolutionary computation, text mining and machine learning.',no_work
'Visualisatie van muziekaanbevelingen Katrien Verbert Joris Klerkx Erik Duval Erik Duval Katrien Verbert Joris Klerkx Katrien Verbert Joris Klerkx De laatste jaren werd er al aardig wat onderzoek verricht naar recommender systemen. Last.fm en Pandora.com zijn enkele bekende voorbeelden. Er zijn verschillende technieken die gebruikt worden om suggesties te genereren. Drie aanpakken die onderzocht en geimplementeerd worden zijn collaborative filtering, content-gebaseerde recommender technieken en combinaties van beide technieken. De collaborative filtering aanpak gebruikt informatie over gebruikers om suggesties te genereren op basis van muziekkeuzes van gebruikers met gelijkaardige interesses. Een tweede aanpak vergelijkt eigenschappen van muziek, zoals ritme, jaar en genre, om suggesties te genereren. Een dergelijke content-gebaseerde aanpak vergelijkt muzieknummers en suggereert muziek op basis van andere muzieknummers die een gebruiker goed vindt. Dit eindwerk is gericht op het verhogen van de aanvaarding en het vertrouwen van muzieksuggesties. Meer specifiek zal onderzocht worden hoe grafische voorstellingen de gebruiker inzicht kunnen geven over de rationale achter aanbevelingen. Sociale visualisaties kunnen bijvoorbeeld helpen de resultaten van een collaborative filtering algoritme te verklaren door expliciet relaties tussen de muzieknummers en mensen voor te stellen.Daarnaast zal onderzocht worden hoe gebruikers het aanbevelingsproces kunnen bijsturen, bijvoorbeeld door feedback te geven over huidige interesses. Het doel van deze thesis is het ontwerp, de implementatie en de evaluatie van visualisatie- en interactietechnieken die de gebruiker inzicht geven in het aanbevelingsproces en de gebruiker ook toelaten om dat proces bij te sturen.  Je zal eerst een literatuurstudie naar gepaste technieken voor het visualiseren van muzieksuggesties uitvoeren. Je zal onderzoeken hoe je de rationale van recommender technieken visueel kan voorstellen en hoe je interacties van gebruikers met recommenders kan ondersteunen. Dergelijke visualisaties bieden de basis voor het exploreren van muzieksuggesties en zijn bedoeld om onder meer het vertrouwen in een recommender systeem te verhogen. Daarna kan je visualisaties van muziekrecommenders ontwerpen en implementeren. We werken samen met een firma, Aristo Music, die muziek en beschrijvingen van muziek aanbiedt: die gegevens kan je gebruiken. De evaluatie van visualisatie- en interactietechnieken en het meten van de impact van de integratie van dergelijke technieken in vergelijking met de traditionele  black-box  aanpak van bestaande recommender systemen is een belangrijk aspect van de thesis. De cursus gebruikersinterfaces is vereist.    J.L. Herlocker, J.A. Konstan,and J. Riedl. Explaining collaborative filtering recommendations. Proceedings of CSCW00: ACM conference on Computer supported cooperative work, pages:241?250, 2000.  B. Gretarsson, J. O?Donovan, S. Bostandjiev, C. Hall, and T. H?llerer. SmallWorlds: Visualizing Social Recommendations. Computer Graphics Forum, 29(3):833?842, 2010  K. Seyerlehner, P. Knees, D. Schnitzer and G. Widmer. Browsing Music Recommendation Networks. International Conference on Music Information Retrieval (ISMIR), 2009, Kobe, Japan.',no_work
'Text-2-Music Sten Govaerts Gert-Jan Poulisse Erik Duval Sien Moens Sten Govaerts Gert-Jan Poulisse  Voor deze thesis werken we samen met  Aristo Music . De K.U. Leuven heeft samen met Aristo Music technologie ontwikkeld die op basis van een beschrijving door de gebruiker de juiste muziek aanbiedt voor een bepaalde situatie. We noemen deze beschrijving een muzikale context en ze is gebaseerd op metadata, o.a. de sfeer, muzikale parameters en gelegenheidsinformatie. Aristo Music beschikt tegenwoordig over meer dan 100.000 met metadata geannoteerde liedjes. Momenteel kan een gebruiker op basis van deze metadatavelden een beschrijving voor zijn gewenste muziek creeren. Op basis van de beschrijving van een muzikale context kan een playlist gegenereerd worden. De technologie is beschikbaar online onder de naam  Tunify .  Dit eindwerk richt zich op de vereenvoudiging van de muzikale contextcreatie door de gebruiker de mogelijkheid te bieden een beschrijving in natuurlijke taal op te geven aan het systeem. Concreet kan een gebruiker opgeven welke muziek hij wenst. Mogelijke voorbeelden zijn: "upbeat muziek voor een barbecue op een regenachtige dag" of "start met wat stevige house en evolueer naar experimentele electro". Afhankelijk van de interesse van de student kan er met een tekst of speech interface gewerkt worden. We hopen op deze manier gebruikers eenvoudiger muzikale contexten te laten aanmaken.  Het doel van deze thesis is het ontwerp, de implementatie en de evaluatie van een tekstuele (en/of speech) query interface voor het genereren van muziekplaylists.  De aanpak is tweevoudig. Je zal enerzijds een literatuurstudie doen, waarin je kennis vergaart over gepaste technieken voor het begrijpen van natuurlijke taal (oa. synoniemen kunnen belangrijk zijn), andere bestaande applicaties met gelijkaardige functionaliteiten en het metadataschema en de technologie van Aristo Music. Anderzijds zal er een implementatie gemaakt worden. De natuurlijke taal zal moeten gemapt worden op de metadatavelden. Op basis hiervan kan er dan een muzikale context gegenereerd worden en uiteindelijk een playlist gegenereerd worden. Het resultaat dient ook geevalueerd te worden. Dit kan op 2 niveaus: men kan kijken naar de correctheid van de uiteindelijke muzikale context beschrijving of de gegenereerde playlist kan geevalueerd worden met mensen.  De oplossing kan uitgewerkt worden als een tekstinterface voor de desktop of een spraakinterface voor mobiele toepassingen bv. op iPhone of Android.De queries in natuurlijke taal zouden ook kunnen gebruikt worden om de metadata te verbeteren. Als blijkt dat bijvoorbeeld "hip" een veel gebruikte term is door gebruikers en dit kan niet gemapt worden op de metadatataxonomie, dan is dit interessante informatie voor Aristo Music om hun metadatataxonomie te verbeteren. Dit zou eventueel kunnen geautomatiseerd worden in de thesis.  Een gezonde interesse voor NLP is nuttig. Daarnaast kan het ook nuttig zijn om het vak Gebruikersinterfaces of Multimedia gevolgd te hebben. Govaerts, Sten; Corthaut, Nik; Duval, Erik, Moody tunes: the rockanango project, Lemstr?m, Kjell; Tindale, Adam; Dannenberg, Roger (eds.), International Conference on Music Information Retrieval, ISMIR, Victoria, BC, 8-12 October 2006, International Conference on Music Information Retrieval, ISMIR, pages 308-313, University of Victoria',no_work
'Semigesuperviseerde extractie van opinies in een multilinguale context Sien Moens Sien Moens Wim DeSmet Het herkennen van opinies in blogs, tweets en andere boodschappen is een belangrijk tool voor business intelligence, omdat een bedrijf steeds interesse heeft te weten of mensen positieve of negatieve opinies hebben over hun producten. Onderzoek naar het herkennen van opinies in tekst is vooral beperkt tot de Engelse taal, voornamelijk omdat hulpmiddelen zoals geannoteerde voorbeelden of woordenboeken met opiniewoorden nauwelijks bestaan voor talen verschillend van het Engels.   We willen technieken van transfer learning gebruiken om geleerde extractiepatronen te porteren naar andere talen, waarbij we focussen op latente klasmodellen.   1. Literatuurstudie over probabilistische modellen met latente variabelen in een multilinguale context. 2. Ontwerp en implementatie van een model voor opinieherkenning dat van genoemde technieken gebruik maakt.  3. Evaluatie op een Engels/Nederlands dataset. De student programmeert in Java, C of Matlab en heeft interesse in text mining en probabilistische modellen.  He, Y. (2011). Latent Sentiment Model for Weakly-Supervised Cross-Lingual Sentiment Classification. In Proceedings ECIR 2011. Springer: Berlin.',no_work
'Deciphering a Foreign Language  Sien Moens Sien Moens Ivan Vulic Archaeologists and linguists are often concerned in deciphering a foreign script and their decipherment is usually based on the presence of texts with similar content in a known language. In many cases we only have texts in the known and the unknown language which contain similar content, i.e., not an exact translation of each other, making the task quite difficult. In this thesis we frame the machine translation problem as a decipherment task, treating the foreign text as a cipher for English and develop methods for training translation models from non-parallel text. Intuitively, we try to construct translation model tables which, when applied to observed foreign text, consistently yield sensible English. This is essentially the same approach taken by cryptanalysts and epigraphers when they deal with source texts.    We solve the simpler problem of word substitution. In a word substitution cipher, every word in the natural language (plaintext) sequence is substituted by a cipher token. Our probabilistic decipherment model follows a noisy-channel approach incorporating statistical word n-gram models, and more specifically an iterative expectation maximization algorithm and Bayesian inference. We take into account scalability when dealing with large word vocabularies. Possibly Gibbs sampling will be used for training the Bayesian model and it can be parallelized in a MapReduce framework. We work with comparable English-Dutch corpora such as WikiNews. If interest, we can compile bilingual data sets that include English (or Dutch) and an ancient language.  Work outline: 1. Perform a literature study on probabilistic models in machine translation. 2. Design, motivate and implement an algorithm for word substitution.  3. Evaluate the algorithm on multilingual datasets.  The student must be familiar with Java or C programming; and is interested in statistical inference and language technologies. Ravi, S. & Knight, K. (2011). Deciphering Foreign Language. In Proceedings of ACL 2011. ACL.',no_work
'Comparing dependently-typed programming languages Dave Clarke Dave Clarke Dave Clarke The type systems of typed programming languages are becoming more and more sophisticated in order to express useful properties of programs statically, including the absence of various kinds of errors (null pointer exceptions, array bounds errors, etc), resource usage, and security properties. The most sophisticated family is dependently-typed programming languages, whose type systems border closely with the logic underlying theorem provers. Such programming languages are safer than languages such as Haskell or Java, but they come at the cost of having an undecidable type checking problem. Nevertheless, a number of programming languages have been developed and these are becoming more and more useful when high security and safety assurance is required. The aim of this thesis is to compare a number of dependently-typed programming languages by developing programs in each language and determining the relative strengths, weaknesses and general limitations of the languages. Languages will be compared from a number of dimensions: the underlying type system s logic, the tool-suite and libraries, the language constructs, features available to help programmers, and so forth. The student will perform the following activities:  Download, install and familiarise oneself with Coq, Epigram, Agda, and possibly other dependently typed programming languages   Devise criteria to test each language   Devise a suite of programs to test each language   Implement programs in each language and evaluate frameworks  If time permits, perform more detailed study of one or more dependently typed languages     A strong student with an interest in programming languages.     Epigram      Agda      Coq      Programming with Dependent Types: Passing Fad or Useful Tool      Epigram: Practical Programming with Dependent Types    Security-Typed Programming within Dependently-Typed Programming    Dependently typed programming in Agda',no_work
'Tune that radio! Sten Govaerts Erik Duval Sten Govaerts  Voor deze thesis werken we samen met  Aristo Music . De K.U. Leuven heeft samen met Aristo Music technologie ontwikkeld die op basis van een beschrijving door de gebruiker de juiste muziek aanbiedt voor een bepaalde situatie. We noemen deze beschrijving een muzikale context en ze is gebaseerd op metadata, o.a. de sfeer, muzikale parameters en gelegenheidsinformatie. Aristo Music beschikt tegenwoordig over meer dan 100.000 met metadata geannoteerde liedjes. Momenteel kan een gebruiker op basis van deze metadatavelden een beschrijving voor zijn gewenste muziek creeren. Op basis van de beschrijving van een muzikale context kan een playlist gegenereerd worden. De technologie is beschikbaar online onder de naam  Tunify .  Dit eindwerk richt zich om op een eenvoudige maar toch voldoende uitgebreide wijze een playlist (al dan niet gegenereerd door een muzikale context) snel aan te passen of bij te sturen op een mobiele applicatie (bv op iPhone of Android) zonder uitgebreide gebruikersinteracties. Een mogelijk design zou toelaten om via bijvoorbeeld een reeks icoontjes een parameter bij te stellen waardoor ogenblikkelijk de muziek aangepast wordt. Het is uiteraard de bedoeling om veel verder te gaan dan een like/dislike, wat bv last.fm nu al aanbiedt.  Het doel van deze thesis is het ontwerp, de implementatie en de evaluatie van mobiele applicatie om op efficiente en eenvoudige wijze een muziek stream aan te passen.  De aanpak is tweevoudig. Je zal enerzijds een literatuurstudie doen, waarin je kennis vergaart over andere bestaande applicaties met gelijkaardige functionaliteiten en het metadataschema en de technologie van Aristo Music. Anderzijds zal er een implementatie gemaakt worden. Hierbij zal er een sterke focus liggen op de design van je applicatie en de usability. Het resultaat dient ook geevalueerd te worden. Dit zal gebeuren door iteratieve gebruikerstesten lopende doorheen de design en implementatie periode.  De oplossing dient uitgewerkt te worden op een mobiel toestel. Dit legt extra interessante vereisten op. Men wil bijvoorbeeld geen 10 minuten besteden om een playlist bij te schaven wanneer men met de auto rijdt.  Interesse voor design en usability is gewenst. Daarnaast kan het ook nuttig zijn om het vak Gebruikersinterfaces of Multimedia gevolgd te hebben. Govaerts, Sten; Corthaut, Nik; Duval, Erik, Moody tunes: the rockanango project, Lemstr?m, Kjell; Tindale, Adam; Dannenberg, Roger (eds.), International Conference on Music Information Retrieval, ISMIR, Victoria, BC, 8-12 October 2006, International Conference on Music Information Retrieval, ISMIR, pages 308-313, University of Victoria',no_work
'Cross-Media Clustering for better Exploration of Search Results Sien Moens Sien Moens Karl Gyllstrom Clustering the results of a Web search is a common way to present the user the search results, where the clustering provides an overview of the answers, and a cluster can be selected to further explore its content. The results of a Web search is often a mixture of multiple types of objects (texts, image, video, links, etc.). Although clustering of homogeneous data has been studied over decades, clustering of heterogeneous data has not been addressed until recently. The major difficulty is the definition and calculation of similarity between each pair of objects.  The aim of the master thesis is to explore different similarity functions and algorithms for clustering heterogeneous objects by implementing objective functions based on which the clustering is iteratively updated. Methods for finding an optimal number of clusters might be explored.     1.Perform a literature study on clustering with heterogeneous objects; get acquainted with software for preprocessing the data.  2. Design, motivate and implement the clustering algorithms.   3. Evaluate the algorithms on multimedia data in terms of correctness and scalability. The multimedia data are obtained in the context of the EU PuppyIr project.  The student is familiar with Java or Matlab programming, and is interested in text and multimedia mining.',no_work
'Applying Machine Learning to Sports Analytics Albrecht Zimmermann Jesse Davis Albrecht Zimmermann Sports Analytics has become a major research field in recent (and not-so-recent) years. Professional (and college) sports are a multi-billion dollar business and sports betting adds another layer of business activity to it. This has gone so far that there is currently a complete  conference dedicated to this topic at MIT . A basic and very important setting is that of predicting  whether  a team will win a match or  which  of two teams will win a match. There is quite a bit of work on this topic but basically all of it has been limited to regression analysis so far, either directly ( Factors Associated with Success Among NBA Teams ) or by estimating the coefficients used in the  Pythagorean expectation . We are going to use data from NCAA (college) basketball with a two-fold purpose: 1) building a model for estimating the win probabilities of teams in a given match, 2) learning how to quantify home field advantage, since this is currently done with a fixed value for all teams, no matter their tendencies. The following results are expected: 1) processing the data so that it can be used by a variety of machine learning technique, 2) using existing techniques to model winning probability, 3) isolating and quantifying the home field advantage factor empirically. The student is expected to know at least one programming/scripting language and have the ability to pick up other ones, and have an interest in Machine Learning. The supervision will be in English. In addition to the literature mentioned above:  Ratings explanation  on Ken Pomeroy s site  Explanation of the log5 formula',no_work
'Learning to Rank Web Search Answers for Relevance, Freshness and Diversity Sien Moens Sien Moens Jan DeBelder Learning to rank algorithms typically use labeled data, for example, query-URL pairs that have been assigned one of several levels of relevance by human judges. However, most of the research on learning to rank has focused on optimizing the relevance (or another criterion) of search results. This quest for accuracy can lead to very complex models. The question is whether this kind of models can be deployed in a real world ranking system where latency is an important factor. In web search, for instance, there are stringent requirements on the execution time: the document ranking phase should typically not exceed 50 milliseconds. For this reason, there is a recent effort in trying to build models which have a reduced execution time, for instance, by the use of fast linear ranking functions, feature selection, and partial evaluation of the classification models. These ideas can be combined with using a cascade architecture, where early classifiers in the cascade use only cheap features, while classifiers later in the cascade are allowed to use more expensive features. But combined with early exits, the latter expensive classifiers would not be evaluated for a large number of documents.  The aim of the thesis is to implement an efficient cascaded learning to rank algorithm making use of state-of-the-art classifiers. The ranking  algorithm can be optimized according to different criteria such as relevance, freshness and diversity, where simple metrics for computing freshness and diversity will be taken into account.   1. Literature study on learning to rank algorithms. 2. Design and implementation of the models. 3. The obtained ranking algorithm will be tested on the WT2g/WT10g web collections.  The student is familiar with Java or C programming and is interested in information retrieval and Web search.   Dai,N., Shokouhi, M & Davison, B.D. (2011) Learning to Rank for Freshness and Relevance. In Proceedings SIGIR 2011.   Chapelle, O. & Chang, Y. (2011). Future Directions in Learning to Rank. In JMLR, Workshop and Conference Proceedings 14, 91-100.',no_work
'Exploring collaboration using mobile and tabletop devices Bram Vandeputte Gonzalo Parra Erik Duval Bram Vandeputte Gonzalo Parra With the development of multi-touch devices (mobiles, tabletops), new ways of interaction are emerging. This thesis aims to explore the combined use of mobile devices and tabletops to enhance the collaboration and interaction between users.   Analyse, design, develop and evaluate a collaborative tool using mobile and tabletop devices.  Example scenarios include:    Innovative ways of discovering and sharing content : A couple of friends are collaboratively planning a citytrip. The users come together around a tabletop, bringing their devices with content they have gathered beforehand. The relevant stuff is shared on the tabletop, and put together in a comprehensive planning for the whole trip. The same can be done afterwards for collaboratively making a photo or video album of the trip they made.   Reading, sharing and discussing scientific publications : Fellow researchers come together around a tabletop to share and discuss publications they found interesting. The publications and the comments are shared on the tabletop, and put together on a working area around the publication.  Cool and fun use of a tabletop to compose a music playlist to put on your mobile device : A music enthousiast comes to the tabletop with his music collection and makes a selection for a playlist. Afterwards, the generated playlist is put on the mobile device.   Having a research meeting around a tabletop, where each user brings her own mobile device to the table.    The thesis will start with a literature study of collaborative applications on tabletops and mobile devices. Then the student will define a concrete scenario that can benefit from the combination of these existing technologies. This idea will be worked out in an iterative process of paper protyping, implementations and evaluations. If approperiate, the developed prototype will be compared against existing tools.  The student followed the Multimedia and/or User interfaces courses. The student is interested in user studies and rapid prototyping.   Researchtable  The cruiser project  Roomware  Work of Norbert A. Streitz  Tom Cuypers, Jan Schneider, Johannes Taelman, Kris Luyten, and Philippe Bekaert. 2008. Eunomia: toward a framework for multi-touch information displays in public spaces. In Proceedings of the 22nd British CHI Group Annual Conference on HCI 2008: People and Computers XXII: Culture, Creativity, Interaction - Volume 2 (BCS-HCI  08), Vol.2. British Computer Society, Swinton, UK, UK, 31-34.',no_work
'Drill and practice applied on mobile devices  Gonzalo Parra Erik Duval Gonzalo Parra With the increased availability of multi-touch mobile devices (smartphones, tablets), new ways of interaction and content consumption are emerging. Due to the specific characteristics of these devices, different activities can be enriched with their use. Learning is one of the human activities where the information interaction has a direct effect on the result of the activity. This thesis aims to explore the drill and practice learning principle applied through a mobile device.  Analyse, design, develop and evaluate a drill and practice application for a mobile device.  The thesis will start with a literature study of existing drill and practice applications (mobile or not). The student will propose a drill and practice mobile application for a learning enviroment (school or university). This idea will be worked out in an iterative process of paper protyping, implementations and evaluations. If approperiate, the developed prototype will be compared against existing tools.    Creative student with a strong affinity for usability and graphic design. Also, a large part of this thesis relies on implementing an application for a mobile device.   The student followed the Multimedia and/or User intefaces courses.      Vazquez-Abad, J., & LaFleur, M. (1990). Design of a performance-responsive drill and practice algorithm for computer based training. Computers and Education. 14(1), 43-52.  Link  Wilson, T. (2004). An Implementation of a Drill and Practice System to Assist in the Teaching of Basic Music Theory. Link  Mobile learning: Context and prospects. EDUCAUSE. Link  A mobile learning application:  Mobl21',no_work
'Alamire Erik Duval Erik Duval Joris Klerkx De Alamire stichting (http://www.alamirefoundation.org/) is een met de K.U.Leuven verbonden internationaal centrum voor de studie van de muziek in de Lage Landen - zo genoemd naar Petrus Alamire (1470-1536), samensteller van schitterende, uiterst kostbare koorboeken. Via zijn atelier wist hij de polyfonie uit de Lage Landen over heel West-Europa te verspreiden. Bedoeling van deze thesis is om, in samenwerking met de Alamire stichting, de zeer kostbare en internationaal vermaarde collectie te ontsluiten. Er is reeds een omvangrijk digitalisatie-project opgezet en het is nu zaak om de resultaten van dat project te valoriseren op innovatieve wijze. Voor deze thesis zijn nog erg veel vrijheidsgraden beschikbaar: zo kan aan een web-toepassing gedacht worden, maar even goed aan een toepassing voor onze multitouch tafel, of voor een mobiel toestel.In ieder geval zal de student relevante toepassingen voor het digitale erfgoed bestuderen, uitgebreid overleggen met de Alamire stichting en uiteindelijk een of meer toepassingen ontwerpen, implementeren en intensief evalueren. Geinteresseerd in muziek, met feeling voor design en gebruikersaspecten.Volgt of volgde de cursus gebruikersinterfaces.',no_work
'Google for researchers Bram Vandeputte Erik Duval Bram Vandeputte Steven Bethard Existing literature is a source of information for researchers in different stages of their work. Being up to speed with the current state-of-the-art is very important for a researcher when working out new ideas or writing up findings of executed research. On the other hand, a researcher can just be widening his/her horizon by looking for interesting papers of a certain topic. All these scenarios can benefit from tailored tools for assisting in this search. The student will identify common search scenarios for researchers, analyze how well existing literature search systems address each scenario, and develop a prototype search application that better accommodates the user needs. The student will : 1) Do a literature study on "search in research" 2) Build up an existing or new categorization of search scenarios in research 3) build a simple index of research articles and their metadata 4) develop a custom search interface that streamlines search over the research articles for several common research scenarios, potentially using a mashup approach for lightweight integration of metadata sources 5) Do a comparative study of how the developed tool performs compared to existing tools in specific search scenarios. This thesis requires a student with an interest in science and a strong affinity for usability and design.  Proceedings of the 2nd International Workshop on Research 2.0. At the 5th European Conference on Technology Enhanced Learning: Sustaining TEL.  J. T. Yao and Y. Y. Yao. 2003.   Web-Based Information Retrieval Support Systems: Building Research Tools for Scientists in the New Information Age . In Proceedings of the 2003 IEEE/WIC International Conference on Web Intelligence (WI  03). IEEE Computer Society, Washington, DC, USA, 570-. Howard D. White, Barry Wellman, and Nancy Nazer. 2004.  Does citation reflect social structure?: longitudinal evidence from the "Globenet" interdisciplinary research group . J. Am. Soc. Inf. Sci. Technol. 55, 2 (January 2004), 111-126. Jimmy Lin, Michael DiCuccio, Vahan Grigoryan, and W. John Wilbur. 2008.  Navigating information spaces: A case study of related article search in PubMed . Inf. Process. Manage. 44, 5 (September 2008), 1771-1783. Steven Bethard and Dan Jurafsky. 2010.  Who should I cite: learning literature search models from citation behavior . In Proceedings of the 19th ACM international conference on Information and knowledge management (CIKM  10). ACM, New York, NY, USA, 609-618.  existing systems such as :   Researchtable  Mendeley  Google Scholar  BibSonomy  CiteSeer',no_work
'Improving k-NN in class boundary regions Albrecht Zimmermann Luc DeRaedt Albrecht Zimmermann Joaquin Vanschoren The  k -nearest neighbor algorithm classifies unseen data points by collecting the  k  most similar training points and assigning the majority label. This is intuitively appealing, similar points get similar labels, allows to give guarantees, and makes learning easy. It also has pitfalls, however: since there s a fixed  k , "nearest" becomes a relative term. For a data point that is not close to other data points with the same class label, the nearest points might be pretty dissimilar. Also, increasing  k  (e.g. from 2 to 3) can lead to points from another class being included, as shown in the figure.   This problem is known in  k -NN and attempts have been made to address it, for instance by weighted  k -NN, i.e. "close" points get more say than far ones.  A straight-forward modification would lie in replacing the fixed  k  with a fixed maximum distance -- points that are further away do not get to vote. Different strategies for setting this maximum distance come to mind, with different advantages and drawbacks. Instead, one could exploit distance information  directly  to identify points in the boundary region and adjust the  k  accordingly. In outlier detection, for instance, the distance of a test instance to its neighbors could be traded off against the average distance of all these neighbors to each other. Once the neighbors themselves become too dissimilar, we have exceeded a useful  k . Alternatively (or additionally), we could use measures that assess how `hard  it is to classify a data point. If similar instances have different label, we have a `hard  point for kNN to classify. This can be measured with metrics such as  class variation , which measures the variability of class labels in the region around a given data point: the more the class labels differ in a small `shell  around the data point, the higher it will be. As such, we can detect points in boundary regions that may need special attention. The goal of this thesis is the experimental evaluation of alternative techniques for adapting  k -NN to class boundary regions. The following results are expected: 1) Implementation of different  k -NN adaptations, 2) Large-scale experimental evaluation and comparison, 3) Potential improvements of the techniques derived from the empirical results The student knows at least one programming language and has an interest in Machine Learning. The supervision would be mainly in English. see above',no_work
'ReseachPad Bram Vandeputte Erik Duval Bram Vandeputte Gonzalo Parra Met Science2.0 wordt verwezen naar het gebruik van Web2.0-toepassingen door onderzoekers. De idee is dat op die manier meer efficient en doelgericht onderzoek kan verricht worden. Toepassingen zoals  mendeley.com ,  academia.edu  of  academic.research.microsoft.com  beginnen de mogelijkheden op dit domein te verkennen.   Nieuwe apparaten zoals bijvoorbeeld tablet-toestellen vereisen een nieuw soort gebruikersinterfaces: dit levert mooie mogelijkheden tot innovatie voor de communicatie tussen mens en machine, waarbij ook locatie, orientatie en andere context-informatie kan aangewend worden. Je zal in deze thesis een toepassing ontwerpen, ontwikkelen en evalueren voor gebruik door onderzoekers. Die toepassing zal waarschijnlijk een mash-up-aanpak volgen en dus eerder bestaande toepassingen integreren dan compleet nieuwe toepassingen te ontwikkelen.   Daarenboven zal deze toepassing focussen op mobiel gebruik in meetings, onderweg (vliegtuig, auto, openbaar vervoer), op conferenties en in sociale contexten waarbij meerdere gebruikers ieder dezelfde toepassing gebruiken op hun eigen apparaat. In deze thesis analyseer je eerst de behoeften van het doelpubliek en hoe bestaande toepassingen daarop inspelen. Daarna ontwerp je een toepassing die je in opeenvolgende prototypes evalueert. Uiteindelijk is het de bedoeling een reeel werkende toepassing te ontwikkelen. Ons STELLAR  network of excellence  zal daarbij een testpubliek van onderzoekers op het vlak van  technology enhanced learning  aanleveren. Deze thesis vereist een student met interesse voor wetenschap en een sterke affiniteit voor usability en mobiele toepassingen.  More! Parra, G. Duval, E.: More! A Social Discovery Tool for Researchers. ED-MEDIA 2010-World Conference on Educational Multimedia, Hypermedia & Telecommunications. (2010).   Ben Shneiderman,  Science2.0 , Science, Vol.319,  The lives and technologies of early career researchers. Caret, University of Cambridge & The Open University  Proceedings of the 2nd International Workshop on Research 2.0. At the 5th European Conference on Technology Enhanced Learning: Sustaining TEL.',no_work
'Augmenting your reality  Bram Vandeputte Erik Duval Bram Vandeputte Gonzalo Parra Advances in augmented reality and portable projecting devices, called eyewear, allow for new ways of interaction, give to users the possibility to have real time information at their fingertips, and give developers the ability to know more (context) information about the user. This thesis aims to explore the use and interaction of augmented reality and mobile devices to enhance the user experience of ubiquitous information retrieval tools.   Analyse, design, develop and evaluate a mobile augmented reality information retrieval tool. Example scenarios include:   Walking in a building and discovering : That at level two someone is giving a lecture on topic X. That the person you meet in the hall has the same sea-diving hobby as you do, ...   Augmented tours : Location based services and applications are a new trend. By exploring and capturing the different geolocated data sources (like cultural heritage resources, restaurants, university offices, etc.) and expose them through a mobile device (by taking advantage of the location and orientation capabilities), the experience of the user can be enhanced while searching for information.    The thesis will start with a literature study of augmented reality tools. Then the student will define a concrete scenario that can benefit from the use of this technology. This idea will be worked out in an iterative process of paper protyping, implementations and evaluations. If approperiate, the developed prototype will be compared against existing tools.  The student followed the Multimedia and/or User interfaces courses and is a creative student with a strong affinity for usability and graphic design.    A Survey of Augmented Reality.  Link  Azuma, Ronald T. A Survey of Augmented Reality. Presence: Teleoperators and Virtual Environments 6, 4 (August 1997), 355 - 385. Earlier version appeared in Course Notes',no_work
'All of me JoseLuis Santos Erik Duval JoseLuis Santos Many people interact with different social networks such as blogs, social and professional personal networks, emails, short messages, etc. This creates a fragmented communication environment. Aggregators allow the user to unify the different networks in one application, so that the information can be visualized in an integrated way and filter actions can be defined irrespective of the conduit of the information.OpenSocial (by Google) offers an API to interact between the different social networks that support it. Moreover, widget technologies allow users to configure their own environment, based on what services they want to consume. Based on both concepts, we can build up a unified social environment. To design, build and evaluate an application to access all social information, enabling users to access all relevant information in an integrated way. The student will evaluate the current status of social aggregation technologies. He will use OpenSocial to interact with existing services that support this technology, and will extend OpenSocial if needed to work with other non-compatible services.The application will make use of widgets technologies like the W3C widget technology, Apache Shindig and Wookie. Student interested on social profiling and mashup of services. Open Social: http://code.google.com/apis/opensocial/ OpenSocial: From Social Networks to Social Ecosystem. Mitchell-Wong, J.; Kowalczyk, R.; Roshelova, A.; Joy, B.; Tsai, H.; Swinburne Univ., Hawthorn http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4233733&amp;tag=1 Wookie: http://incubator.apache.org/wookie/',no_work
'Quantified learning  JoseLuis Santos Erik Duval JoseLuis Santos Based on a Quantified Self approach (see http://quantifiedself.com/ or http://totalrecallbook.com/), the student will design, develop and evaluate an application to track learning activities, including feedback on how well the experience went. Moreover, using the capabilities of mobile devices, other contextual information will be captured such as time or geo-location.The user will be able to share this information with his friends and to access a dashboard where all this information is visualized in a way, that enables the user to see when and where he was more productive and organize his time better.Our behavior and performance is context-dependent. Different psychological studies point out that our environment influences our learning performance: the moment of the day, the temperature of the environment, the time, the location,... are important factors in these processes. The knowledge of when and why our performance is better, is important for achieving our goals.Inspiring examples include:- Mappiness (http://www.mappiness.org.uk/): helps through visual analytics to understand where and when you are happier; - Nike+ (http://nikerunning.nike.com/nikeplus/) or runkeeper (http://runkeeper.com/): oriented to jogging activities, these applications visualize your sport performance and position the user in a social context of a like-minded community. The purpose of this thesis is the design, implementation, and evaluation of a mobile application that will help to improve your learning performance. To this end, the student will have to explore what kind of relevant information can be captured by or at least on a mobile device, whether this information is useful, and how this information can be visualized to provide useful feedback for a student The student will design, develop and evaluate a mobile application.In parallel, the student will study similar applications from other fields and analyze how these can inspire the context of learning. Student interested in user centered applications and mobile device programming. Mappiness - http://www.mappiness.org.uk/ Nike+ - http://www.nikeplus.com/ Total recall book - http://totalrecallbook.com/ The Quantified self - http://quantifiedself.com/Petra Sundstr?m, Anna St?hl, Kristina H??k. In situ informants exploring an emotional mobile messaging system in their everyday practice, International Journal of Human-Computer Studies, Volume 65, Issue 4, April 2007, Pages 388-403',no_work
'Verbeteren van heuristieken voor zoekproblemen Broes DeCat Marc Denecker Broes DeCat Het IDP systeem is een modelexpansiesysteem voor de taal FO(.): gegeven een formele specificatie in FO(.) zoekt het systeem oplossingen die aan de specificatie voldoen. Een voorbeeld hiervan is een specificatie over het plannen van uurroosters, waarbij de oplossingen dan concrete uurroosters zullen zijn. Concreet komt een oplossing naar op een verzameling variabelen waarvoor een toekenning wordt gezocht. Het genereren van oplossingen gebeurt dan enerzijds door iteratief een vrije variabele te kiezen en er een van de overgebleven waarden aan toe te kennen. Anderzijds door telkens na een keuze, de gevolgende van deze toekenning te propageren naar de andere variabelen. Wordt er een conflict gevonden, dan worden een minimaal aantal keuzes ongedaan gemaakt en wordt er bijkomende kennis geleerd uit het conflict, waarna het algoritme verder zoekt tot een oplossing gevonden wordt (of er gevonden wordt dat er geen oplossing bestaat). Een cruciaal onderdeel bij dergelijke zoekalgoritmes is de heuristiek waarmee de keuzes gemaakt worden: de keuze van welke variabele een toekenning krijgt en de keuze van welke waarde wordt toegekend. Hoe beter de heuristiek, hoe sneller oplossingen kunnen worden gevonden (of hoe sneller uitgevonden wordt dat er geen oplossing is). Omdat tijdens het zoeken doorgaans heel veel keuzes gemaakt worden, is de snelheid van het bepalen van een keuze ook van belang. Het huidige zoekalgoritme dat gebruikt wordt in het IDP systeem is dat van de SAT-solver  Minisat . Het is een state-of-the-art zoekalgoritme voor problemen waarbij de probleemstructuur niet gekend is, maar het heeft ook een aantal nadelen: - als er wel een duidelijke probleemstructuur is, herkent het zoekalgoritme die niet altijd. - een expert kent vaak een goede heuristiek om een probleem aan te pakken en het zou nuttig zijn om die te kunnen combineren met het automatische algoritme. - de initialisatie van het algoritme is erg willekeurig, waardoor het zeer snel verdwaalt in grotere problemen (weinig schaalbaar). In deze thesis zal dan een verbeterd zoekalgoritme worden uitgewerkt om deze nadelen aan te pakken. Hiervoor zal gekeken worden naar het domein van Constraint Programming, waarin het mogelijk is om zelf een zoekheuristiek te specifieren, en heuristieken die afhankelijk zijn van de probleemstructuur, bijvoorbeeld heuristieken toegespitst op planningsproblemen. Versnellen van modelexpansie van FO(.) door het uitbuiten van de structuur van een probleem. Enerzijds door nieuwe structuur-afhankelijke heuristieken te onderzoeken en te implementeren, anderzijds door een menselijke expert toe te laten om heuristieken op een declaratieve manier te specifieren. De student maakt zichzelf eerst vertrouwd met het IDP systeem en met het huidige zoekalgoritme (een SAT-solver met VSIDS zoekheuristiek). Vervolgens wordt er gekozen om ofwel nieuwe automatische heuristieken te implementeren of uit te werken hoe een menselijke expert op een declaratieve manier heuristieken kan specifieren (of beide). In het eerste geval zullen eerst een aantal gekende heuristieken worden geimplementeerd om daarna zelf nieuwe heuristieken te onderzoeken. In het tweede geval zal de student de invoertaal uitbreiden en het zoekalgoritme aanpassen om om te gaan met "custom" heuristieken te gebruiken. Er zal ook onderzocht worden hoe verschillende heuristieken efficient gecombineerd kunnen worden. Experimenten worden uitgevoerd aan de hand van een aantal realistische toepassingen, zie bijvoorbeeld de  asp-competitie  en de  planningscompetitie . Een mogelijke uitbreiding is het gebruik van een machine-learning techniek om te leren wanneer welke heuristiek best gebruikt wordt. Omdat het bepalen van de keuze in een zoekalgoritme vaak wordt uitgevoerd, is ook de algoritmische complexiteit van de algoritmes van belang, zowel theoretisch als in praktijk. Interesse in declaratieve paradigma s voor problem solving.Interesse in zoekalgoritmes  Heuristieken voor planningsproblemen  Heuristieken binnen constraint programming: Principles of Constraint Programming door Krzysztof R. Apt',no_work
'Another step for centroid-based classification Albrecht Zimmermann Luc DeRaedt Albrecht Zimmermann Joaquin Vanschoren The  k -nearest neighbor algorithm classifies unseen data points by collecting the $k$ most similar training points and assigning the majority label.  Classification by centroids , in contrast, creates a centroid, i.e. a prototype, for each class and assign a label to an unseen instance according to the closest centroid.There has been work that integrated prototypes and  k -NN to varying degrees, typically either by combining potentially similar future "neighbors" into a single prototype or by replacing  k -neighborhoods by their prototypes and using several of those for the vote.Additionally,  this work  showed that removing outliers improves  k -NN to better accuracy than centroid-based classification for document data and  Vilalta et al  showed that decomposing classes into coherent subclasses can improve classification.Consider, e.g., the following figure that shows data that is clearly separated into subclasses:   Based on this, two improvements to the centroid-based classification framework seem straight-forward:  Remove outliers  Cluster the remaining instances per class into (several) cluster(s) and create centroids  Do  k -NN using the centroids, perhaps using a modification such as "almost" closest  The following figure gives an impression how the data shown before would be transformed and used:   This is however only a general framework and there remain several open questions that would be explored in the thesis. The goal of this thesis is the experimental evaluation of the proposed improvements to centroid-based classification. The following results are expected: 1) acquisition or implementation of the used techniques, e.g. centroid-based classification, clustering algorithm (e.g. Autoclass), 2) experimental evaluation of the proposed techniques, 3) evaluation and solution for the question of what constitutes "almost" equally close. The student is expected to know at least one programming or scripting language and have the ability to pick up others, and have an interest in Machine Learning. The supervision would be mainly in English see above',no_work
'Injecteren van architecturale patronen in applicatiemodellen  Stefan VanBaelen Yolande Berbers Wouter Joosen Stefan VanBaelen Architecturale patronen beschrijven welgedefineerde oplossingen voor architecturale problemen die je bij de ontwikkeling van een software applicatie moet aanpakken. Model-gedreven ontwikkeling stelt modellen centraal in het ontwikkelingsproces, welke gradueel via modeltransformaties worden verfijnd met allerlei relevante aspecten. Dit eindwerk wil beide aanpakken combineren door een modeltransformator te bouwen die een architecturaal patronen kan selecteren en injecteren in een bestaand model.  Het doel van deze thesis is om een modeltransformator te ontwikkelen die een software ontwikkelaar in staat moet stellen om vanuit een hoog-niveau applicatiemodel, een beschrijving van de systeemvereisten en de te behalen kwaliteitsattributen (Quality Attributes) (semi-)automatisch een geschikte software architectuur te selecteren en te injecteren in het applicatiemodel. Hiervoor is het nodig om een aantal bestaande architecturale patronen (patterns) te selecteren die matchen met de vereisten voor het te ontwikkelen systeem. Het verfijnd applicatiemodel, gegenereerd door de injectie van een software architectuur, is het basismodel waarop de software ontwikkelaar kan steunen om zijn ontwerp verder te ontwikkelen en te detailleren.   Deze thesis omvat:   Literatuurstudie omtrent architecturale patronen, met hierbij focus op communicatiegerelateerde architectuurpatronen.  Ontwikkelen van een repository die de pattern-modellen en eigenschappen van bestaande architecturale patronen kan bevatten.   Ontwikkelen van een modeltransformator in ATL die op basis van (1) een hoog-niveau applicatiemodel in UML, (2) de systeemvereisten en kwaliteitsattributen in URN (User Requirements Notation), en (3) de ontwikkelde architecturale repository, een nieuw UML model kan genereren dat een verrijking van het originele model met een gekozen software architectuur bevat.  Validatie van de modeltransformator door het toepassen op een aantal case studies.   Je bent geinteresseerd en hebt al enige achtergrond in software architectuur, modelleren en UML. Software architectuurpatronen, URN (User Requirements Notation,  http://www.usecasemaps.org/urn ), modeltransformaties, ATL.',no_work
'Vergelijking van en transformatie tussen URN (User Requirements Notation) en UML Stefan VanBaelen Yolande Berbers Wouter Joosen Stefan VanBaelen URN (User Requirements Notation) is een requirements modelleertaal die gestandardizeerd is door het ITU-T. UML is een software modelleertaal gestandardizeerd door de OMG. Dit eindwerk wil de vereistenaspecten in beide modelleertalen vergelijken, en transformaties tussen URN en UML realizeren. Het doel van deze thesis is om een vergelijking te maken tussen URN en UML. De User Requirements Notation (URN) is een modelleertaal die toelaat om use case maps te modelleren, een meer formelere manier om use cases te beschrijven. Daarenboven bevat het ook een Goal-Oriented Requirement Language (GRL).UML daarentegen is meer gefocused op modellen gedurende de gehele software ontwikkelingscyclus, en heeft een meer pragmatischere aanpak voor vereistenmodellering.Op basis van deze vergelijken zal je een transformator ontwikkelen die een URN-model kan transformeren in een UML-model. Deze thesis omvat:   Literatuurstudie omtrent URN en Use Case Maps, en de bijbehorende ondersteunende tools.  Vergelijking en mapping tussen URN-concepten en UML-concepten.   Ontwikkelen van een modeltransformator in ATL die op basis van een URN model een UML model kan generen die zoveel mogelijke relevante informatie uit eht URN model.  Validatie van de modeltransformator door het toepassen op een aantal case studies.   Je bent geinteresseerd en hebt al enige achtergrond in requirements, software modelleren en UML. URN (User Requirements Notation, http://www.usecasemaps.org/urn), UML, modeltransformaties, ATL.',no_work
'A Constraint Programming System that Learns. Tias Guns Guido Tack Luc DeRaedt Tias Guns Guido Tack Siegfried Nijssen Constraint Programming is a general purpose technique for solving constraint satisfaction problems. This technique is successfully used to solve puzzles as well as many real-life applications, such as scheduling, rostering, planning, resource allocation, load balancing and so forth. CP can be summarized with the following tag-line: Constraint Programming = Model + Search. To solve a problem, one first models it in terms of variables and constraints. This model, or problem specification, is then fed into a solver that uses the constraints as effectively as possible during search.  The modeling phase is in principle declarative, i.e., one only has to specify what to solve, not how to solve it. In practice, however, the efficiency of the solver depends heavily on choices made in the model. The choice of search heuristics and other parameters are known to have a huge influence on the runtime efficiency of the solvers.There is no single best choice for these parameters. Yet, the wrong choice of parameters can lead to prohibitive runtimes and suboptimal results. Making the right choices is considered to require expertise and a trial-and-error approach.  Machine Learning has proven to be good at solving such expert problems. The challenge in this thesis is to leverage the power of Machine Learning for Constraint Programming. The goal is to use machine learning techniques to automatically learn the best modeling choices, given a CP model and multiple instances (data) of it. The student will first become more acquinted with constraint programming by playing with example problems and solving problems with different modeling choices. The research will start with a literature study of previous combinations of machine learning and constraint programming.   From the Machine Learning perspective, there are a number of question that will need investigation, namely:   What features to use during learning  What learning algorithm to use Depending on your interest, more or less time can be spent on this aspect.  On the constraint programming side, the goal is to create a system that optimizes the usage of existing systems. The CP models will be specified in MiniZinc[1], a standardized solver input language. Multiple solvers exist that can use this language. Given a number of problem instances (data for a MiniZinc model), the goal will be to learn which parameters best to supply to the underlying solver. The underlying solver could be Gecode[2] or any other solver. Initially, the work will focus on predicting the parameters that lead to the shortest runtime. However, this can be modelled as a machine learning problem in several ways:   As a binary classification task (for each parameter/value combination, whether it will be the best or not)  As multi-valued classification (which value is best for a parameter)  As regression (what will be the runtime of this parameter/value combination)  ... The binary classification task approach has been studied before[3] and will be used as a starting point. Interested in machine learning and constraint programming. The research involves explorative research and will require creative thinking. The empirical aspect of the thesis will involve a fairly large number of experiments. Relevante literatuur:  [1] http://www.g12.cs.mu.oz.au/minizinc/ [2] http://www.gecode.org/flatzinc.html [3] Online Heuristic Selection in Constraint Programming. A. Arbelez, Y. Hamadi, M. Sebag (2009) [*] Machine learning for constraint solver design. I. Gent, L. Kotthoff, I. Miguel, P. Nightingale (2010) [*] Performance prediction and automated tuning of randomized and parametric algorithms. Hutter, F., Hamadi, Y., Hoos, H., Leyton-Brown, K. (2006)',no_work
'Learning Constraint Specifications  Tias Guns Siegfried Nijssen Luc DeRaedt Tias Guns Siegfried Nijssen In Constraint Programming (CP), one models a satisfaction or optimisation problem using constraints. This technique has been extensively applied on puzzles, as well as industrial applications such as timetabling, scheduling, resource allocation and more.  Despite its success in solving hard combinatorial problems, the creation of a constraint specification is considered a non-trivial task requiring expertise in both CP and the problem at hand. Modelling a problem in CP involves choosing decision variables, choosing constraints on the variables, and considering alternative formulations to increase efficiency.  Ideally, a domain expert should simply be able to generate a constraint specification using positive and negative examples of similar problems. In the field of machine learning, Inductive Logic Programming (ILP) has similarly been successfully used to find constraints and relations that explains biological phenomena or natural language observations. Recent work[1] has succeeded in applying ILP techniques to find constraint specifications. However, a large number of challenges remain; this thesis is about solving some of these challenges. The goal is to learn complex constraint specifications using positive and negative examples of related (sub) problems. The student will first become more acquinted with constraint programming by playing with example problems and solving problems in different ways. The research will start with a literature study of recent advancements in using ILP to learn constraint specifications.  In our group, we have extensive experience with ILP. A first step will be to discover some of the limitations of applying (our) ILP systems to the task of learning constraint specifications. This will involve applying it on different problems of different size, complexity and types of constraints involved.  After identifying a number of limitations, the focus of this thesis will be on overcoming some of these limitations by adapting the existing algorithms, or by creating new ones. Possible challenges include the addition of more complex constraints, such as aggregates, without increasing the runtime too much. Ideally, one would be able to learn arbitrary constraint specifications in an expressive language such as MiniZinc[4]. Interested in constraint programming and machine learning/relational learning/inductive logic programming. The thesis involves explorative research and will require algorithmic thinking to create and implement new algorithms. [1] On Learning Constraint Problems. A. Lallouet, M. Lopez, L. Marting, and C. Vrain (2010) [*] Constraint acquisition as semi-automatic modeling. R. Coletta, C. Bessiere, B. O Sullivan, E.C. Freuder, S. O Connell, and J. Quinqueton. (2003) [*] Automatic Generation of Propagation Rules for Finite Domains. Slim Abdennadher and Christophe Rigotti. (2000) [4] http://www.g12.cs.mu.oz.au/minizinc/',no_work
'GUI-generatie van de toekomst Broes DeCat Stef DePooter Marc Denecker Broes DeCat Stef DePooter  Er is steeds meer interesse voor kennisgebaseerde vormen van softwareontwikkeling. Het basisprincipe is dat domeinkennis in een toepassing expliciet wordt voorgesteld door een formele specificatie in een kennisbank en dat softwaretaken kunnen worden uitgevoerd door een gepaste inferentietechniek toe te passen op die kennisbank. Denk bijvoorbeeld aan een schedulingsprobleem waarbij we alle elementen, beperkingen en andere gegevens verzamelen in een kennisbank en dan een passend schema opstellen door er een algoritme op los te laten. Een dergelijke manier van softwareontwikkeling kan leiden tot grote voordelen op het gebied van ontwikkelingstijd, correctheid en onderhoudbaarheid.  Een veelbelovende inferentietechniek is propagatie van partiele informatie uit de kennisbank. Deze techniek komt van pas bij het oplossen van configuratieproblemen, waarbij een gebruiker een configuratie wil opstellen onder bepaalde, mogelijk complexe en sterk interagerende, beperkingen. Propagatie controleert de consistentie van gemaakte keuzes in de configuratie en berekent de implicaties voor het verdere verloop van het configuratieproces. Een voorbeeld van een dergelijk systeem voor het opstellen van studieprogramma s werd gezien in de cursus Modellering van complexe systemen.  In deze thesis willen we kennisgebaseerde methodologieen en inferentietechnieken onderzoeken en uitbouwen in de context van een dergelijke configuratieprobleem. De KRR-onderzoeksgroep doet onderzoek naar inferentietechnieken in de context van een expressieve specificatietaal FO(.) gebaseerd op klassieke logica. Er worden allerlei tools en propagatietechnieken ontwikkeld om kennisgebaseerde toepassingen te bouwen. Het is dan ook de bedoeling dat van deze technieken gebruik wordt gemaakt bij de implementatie in dit project.  Het specifieke toepassingsdomein is in essentie onbelangrijk. Interessante domeinen waar al rond gewerkt wordt in de KRR-groep zijn:  interactief plannen van lessen en oefenzittingen,  interactief opstellen van studieprogramma s voor studenten,  een gezondheidzorgtoepassing van Agfa Healthcare.  Het is ook mogelijk om zelf een configuratietoepassing voor te stellen. In de cursus Modellering van complexe systemen werden nog meer interessante problemen behandeld. Om inspiratie op te doen kan je ook gaan kijken naar toepassingen van kennisgebaseerde softwareontwikkeling in de industrie zoals ConfigIT en Prover.   De essentie van het onderzoek zit in de verschillende elementen die nodig zijn om een dergelijke toepassing te bouwen.   We willen een generische, configureerbare GUI-generator ontwikkelen voor het bouwen van kennisgebaseerde configuratietoepassingen. Een GUI voor een dergelijk systeem moet taken kunnen uitvoeren zoals:  Visualiseren van logische atomen uit de kennisbank, bvb. in de vorm van checkboxes die aangeven of een bepaald atoom waar is.  Synchroon houden van scherm en kennisbank, oa. door de kennisbank te informeren van keuzes van de gebruiker, en de gebruiker te informeren van resultaten van inferenties op de kennisbank.  Oproepen van inferentietools op vraag van de gebruiker.  Eventueel openen van nieuwe vensters, getriggered door acties van de gebruiker of door resultaten van inferentietaken.  ...  Merk op dat dit allemaal taken zijn die onafhankelijk zijn van een specifiek configuratiedomein.  Het doel van de thesis is om een interface-generator te ontwikkelen die dergelijke GUI s kan opbouwen. De generator krijgt als invoer bijvoorbeeld een verzameling van te visualiseren logische atomen uit de kennisbank (e.g., "StudentKiest(ModelleringVanComplexeSystemen)"), informatie van hoe en waar deze getoond moeten worden, en eventueel enkele acties die aan bepaalde knoppen geassocieerd zijn, en genereert een interface die een scherm toont, en het dan synchroon houdt met de kennisbank.  Er is ondertussen al heel wat technologie beschikbaar om dit project te verwezenlijken. In de KRR-groep werd zopas een (nog zeer eenvoudig) prototype van een dergelijke generator ontwikkeld, waarmee bijvoorbeeld de studieprogrammatoepassing in enkele uren ontwikkeld kan worden. Bovendien wordt er in de onderzoeksafdeling van Agfa Healthcare ook gewerkt aan dergelijke technologie. De bedoeling van de thesis is deze systeem verder uit te bouwen en ermee te experimenteren.   Het project start met een verkenning van de technologieen die beschikbaar zijn bij de KRR-groep en onderzoeksafdeling van Agfa Healthcare. Bekijk de mogelijkheden en beperkingen van deze systemen, en bestudeer hoe we ze kunnen combineren in een werkend systeem.  Daarna zijn er heel wat topics die uitgewerkt en geimplementeerd kunnen worden in dit project:   Een specificatiemethode om de attributen van de GUI te beschrijven (bvb. hoe, wat, en eventueel waar gegevens getoond moeten worden, en welke logische acties er kunnen uitgevoerd worden).  Een specificatiemethode om GUI s met meerdere vensters te beschrijven (inhoud van de diverse schermen, beschrijven van de overgangen tussen schermen, enz.).  Algoritmen om de vensters te genereren, (mogelijk op basis van bestaande software zoals NetBeans en Swing).  Algoritmen om de GUI en de logische kennisbank te synchroniseren, acties op te roepen ten gepaste tijde, uitvoer van de kennisbank te visualiseren, enz.  Eventueel bepaalde nieuwe inferentie-mechanismen toevoegen, of bestaande verbeteren.  De software evalueren in de context van een of meerdere toepassingen.   Het idee is om in overleg met de student een toepassing te kiezen en die gaandeweg uit te werken.  Interesse in formele talen en hun praktische toepassingen',no_work
'Klinische beslissingsondersteunende systemen Stef DePooter Marc Denecker Stef DePooter  Maar weinig commerciele informatiesystemen in de gezondheidszorg bieden een uitgebreide proactieve ondersteuning voor besluitvorming. In deze thesis willen we onderzoeken wat de methoden uit het onderzoek rond kennisrepresentatie kunnen betekenen bij het toepassen van medische kennis om aanbevelingen van artsen te ondersteunen.   Alleen wanneer zowel de pati?ntgegevens als de klinische kennis in een formele beschrijving opgenomen zijn in het systeem, kan dat systeem aanvullende ondersteuning bieden aan klinisch personeel bij het nemen van beslissingen. Bijvoorbeeld, geencodeerde medische kennis over de betekenis en het belang van veranderingen in resultaten van laboratoriumtests zou een systeem kunnen toelaten om alarm te slaan. Dit is een actieve functie, in aanvulling op de passieve functie om gegevens op te halen. Of ook, als het systeem de context van de patient kan matchen met relevante klinische richtlijnen, dan kan het mogelijke aanbevelingen aanbieden die overeenkomen met deze richtlijnen.  De arts is verantwoordelijk voor de uiteindelijke beslissing, maar het systeem kan actief mogelijkheden en verklaringen aanbieden. Dit kan de efficientie van de arts verhogen en overeenkomst met aanvaarde praktijkrichtlijnen verbeteren.   De thesis is een samenwerkingsproject tussen de KRR-groep en de onderzoeksafdeling van Agfa Healthcare. De bedoeling is om de expertise en technologie van deze twee onderzoeksgroepen te combineren om informatiesysteem te ontwikkelen om klinisch personeel te ondersteunen bij het nemen van beslissingen.   Interesse in formele talen en hun praktische toepassingen',no_work
'Video Event Classification in Sport Games Laura Antanas Guy VandenBroeck Jesse Davis Laura Antanas Guy VandenBroeck Sport games forecasting is very popular for fans, team managers, sponsors and lately it has become an industry on its own. The purpose of these tools is to predict the outcome of a game (e.g. soccer, basketball, football) in terms of win/draw/lose, the final score or championship rankings. The information they use is mostly statistics about current status of the players, their records from previous matches and across championships, the teams they belong to. However, when the level of performance of both teams is high, prediction based on solely this information is difficult. It is often the case that the evolution of the players in specific games, team strategies in key moments of these games become also important in the prediction task. For example, in a soccer game it is relevant to analyse the number of goal positions of a team in the first 30 minutes of the game and the score at that stage or if the team adopts an attack strategy when it is in disadvantage. In this thesis our goal is to automatically extract such information from videos of matches. More specifically, given a sequence of key frames in a match video, our aim is to answer, based on positions of the players, questions such as: was there a goal position? is there an attack strategy? if yes by which team?  The first task is to do a literature study on current approaches tackling such problems from video data. The second task is to translate the video information into a symbolic representation containing simple qualitative spatial and temporal relations between players. This can be done with the help of online annotation tools for computer vision or directly from existing ground truth annotations (when these are already available). The last task is to use this data to learn how to answer meaningful questions as the ones above.  For this purpose videos of basketball and soccer matches are available for training and testing. Interested in computer vision and machine learning. Programming skills in Prolog and some knowledge of C/C++  1) L. Ballan, M. Bertini, A. Del Bimbo, and G. Serra, Video Event Classification Using Bag of Words and String Kernels, in Proc. of International Conference on Image Analysis and Processing (ICIAP), Salerno, Italy, 2009  2)Yi Ding and Guoliang Fan, Event detection in sports video based on generative-discriminative models  3) Chris Poppe, Sarah De Bruyne and Sarah De Bruyne, Generic architecture for event detection in broadcast sports video  4) Video Annotation Tool and basketball dataset [  Vatic  ]   5) J Wallgr?n, L Frommberger, D Wolter, Qualitative spatial representation and reasoning in the SparQ-toolbox',no_work
'Visualiseren van Muziek Erik Duval Joris Klerkx Erik Duval Joris Klerkx Ares Lagae Er zijn verschillende manieren om muzieknummers te visualiseren. Je kan bijvoorbeeld puur naar de lyrics kijken om het nummer te visualiseren. Voorbeelden zijn terug te vinden op LucidChart.com waar ze op een nummer flow charts genereren doorheen de tijd. Een flow chart van Hey Jude van de Beatles kan je  hier  terugvinden.  Een  ander voorbeeld  uit onze onderzoeksgroep zelf is het visualiseren van de emotie van het nummer obv de lyrics.  Nog andere voorbeelden zijn puur gebaseerd op het muziektimbre of het gevoel die de muziek creeert. Een voorbeeld hiervan is de videoclip van het nummer Lj?si? van Olafur Arnalds dat je kan terugvinden op  youtube .  Dat er nog vele andere manieren bestaan, wordt duidelijk uit   blog waar de auteurs in de context van een conferentie vele voorbeelden beschreven hebben. Het doel van deze thesis is het ontwerp en de implementatie van een proof-of-concept systeem dat een muzieknummer als invoer gebruikt om een visualisatie te maken van het nummer. Technieken uit de domeinen van muziek, informatie visualisatie en computer graphics zullen aan bod kunnen komen.  Hiervoor zal een literatuurstudie (zowel in informatie visualisatie als in Computer Graphics) nodig zijn. Vervolgens wordt in samenspraak met de begeleiders en de promotor een keuze in de toepassing die ontwikkeld zal worden. Deze zal uitdagend maar toch haalbaar moeten zijn.  De cursussen Computer Graphics en gebruikersinterfaces zijn vereist.  http://visualizingmusic.com/    http://www.slideshare.net/plamere/using-visualizations-for-music-discovery    http://visualizingmusic.com/2009/09/11/visualizing-emotion-in-lyrics/',no_work
'Accessing Learning Material in the Web of Data  Joris Klerkx Erik Duval Joris Klerkx With the growing population of Open Education Resources (OER) initiatives, we have now collected nearly 1.2 million educational resources inside the GLOBE repository. The term "Linked Data" refers to a set of best practices for publishing and connecting structured data on the Web. These best practices have been adopted by an increasing number of data providers over the last three years, leading to the creation of a global data space containing billions of assertions - the Web of Data. Client tools can make use of a SPARQL end point to access the resources of our GLOBE repository. SPARQL is the primary query language of RDF-based repositories and is based on queries using graph patterns. This master thesis sets out to create a mashup application that blends together this repository with existing information in other locations such as dbpedia, slideshare, youtube, etc., resulting in a personalized learning environment for finding and using these resources.  First of all, a literature study will be performed to get the student up-to-speed in the fields of OER, open linked data and user interface design. After this step, a mash-up application will be designed and implemented by following a case based design methodology with frequent iterations of prototype design, implementation and evaluation. Together with the promotor, the student can decide the platform (e.g desktop, ipad, iphone, etc. ) on which the application will be running.  Practical student with a feel for user interface design. The course user interfaces is a must.   http://en.wikipedia.org/wiki/Open_educational_resources    http://www.mendeley.com/research/linked-datathe-story-so-far-2   http://www.globe-info.org"   http://www.w3.org/TR/rdf-sparql-query',no_work
'Music generation using Hidden Markov Model variations Danny DeSchreye colin.nicholson+cs.kuleuven.be Danny DeSchreye Adhemar Bultheel colin.nicholson+cs.kuleuven.be APOPCALEAPS is a music generation program written in the probabilistic CHRiSM language.  A unique song is createdby the system after a user sets parameters for how many measures the song should be, what key the song should be in, etc.  Right now the note generation is done using a simple Markov chain: the system looks at the current note,then generates a new note based on pre-set probabilities for note transitions.  It is possible that there are betterways to handle note generation than just a simple Markov chain, more advanced methods may give us abilities togenerate the notes in more elaborate ways.  Many variations on Hidden Markov Models exist (Hierarchical Hidden Markov Models, Layered Hidden Markov Models, etc).  The testing of Hidden Markov Model variations on the note generation system of APOPCALEAPS.  The work consists of:-Understanding the current APOPCALEAPS system and the CHRiSM language-Literature study of Hidden Markov Model variations-Literature study on how others have used HMMs in music generation programs-Implementation of note generation in CHRiSM using HMM variations-Evaluation of each HMM variation and how it helps/hurts the current system The student should be familiar with Prolog and not dislike it, becauseCHRiSM is a follow-up logic programming language and most of the development will be done in CHRiSM.There will be a lot of experimentation and some implementation in this thesis. http://people.cs.kuleuven.be/~jon.sneyers/papers/chrism_music.pdfhttp://people.cs.kuleuven.be/~jon.sneyers/presentations/iclp10-chrism.pdfMachine Learning, Tom Mitchell, Boston: McGraw-Hill, 1997.',no_work
'Improving the efficiency of constraint-based termination analysis. Paolo Pilozzi Danny DeSchreye Paolo Pilozzi In termination analysis of declarative programs, conditions on theprogram are verified which imply termination of the program for itsintended use. To verify these conditions, several approaches have beenconceived. One important approach is called the constraint-basedapproach, deriving a constraint problem of which satisfaction impliesprogram termination.Since the constraint problems can become rather large, and thereforesolving them can become rather slow, it is useful to regard approaches,tuned to the termination problem, that improve the efficiency of findingsolutions to the constraint problems that we obtain for terminationanalysis. The goel is to develop new solvers, specifically tuned for thisapplication.Especially in the context of Constraint Handling Rules,  but also forLogic Programming, there are motivations for incremental constraintsolvers. However, there can also be other optimizations that could beapplied. It would also be interesting to consider different kinds ofconstraint solvers, such as those based no SAT solvers and SMTsolvers. The student needs to get familiar with the application and with the solvers that are currently applied.Then he/she will looks at related solvers and see how they couldbe useful for the application.Experimentation with different solvers will be necessary.It is likely that some tuning of the solvers will be needed to finda good solution. Involves investigating the kinds of constraint problems that are derivedfor termination.Involves testing with different solvers.Involves attempting optimizations of the constraint problems.Involves proposing improved constraint-based approaches. Paolo Pilozzi, Danny De Schreye: Automating Termination Proofs for CHR. ICLP 2009: 504-508.Manh Thang Nguyen, Danny De Schreye: Polynomial Interpretations as a Basis for Termination Analysis of Logic Programs. ICLP 2005: 311-325.',no_work
'Logica: revolutie in computerwetenschappen Marc Denecker Marc Denecker Broes DeCat Hanne Vlaeminck Stef DePooter   Logica is de wetenschap van kennis, informatie, en het gebruik ervan voor het oplossen van taken en problemen door middel van inferentie. Het zijn onderwerpen van centraal belang in de informatica. Daarmee heeft logica en logische inferentie een fundamentele rol in computerwetenschappen, wat op dit ogenblik nog maar weinigen zich realiseren. De vraag is niet zozeer of logica en logische inferentiesystemen een rol zullen spelen in de informatica van de toekomst, wel wanneer ze dat zullen doen.   Hoe het ook zij, de evolutie in logica-gebaseerde verificatie, specificatie, problem solving en AI-tools gaat tegenwoordig enorm snel. In de komende 10, 15 jaar zal logica ongetwijfeld een steeds prominenter rol gaan spelen in software engineering.   De KRR groep werkt rond rijke uitbreidingen van klassieke logica (FO(.) genoemd) en rond inferentie-tools en nieuwsoortige toepassingen ervan. We bouwen er inferentie-tools voor (zoals het IDP-systeem) en onderzoeken nieuwsoortige toepassingen (zoals bv. het interactief configuratie-systeem voor het kiezen van een studieprogramma). Dit zijn uiteraard ambitieuze, toekomst- en onderzoeksgerichte doelstellingen. Gemotiveerde thesisstudenten kunnen hieraan een waardevolle bijdrage doen.  Een thesis rond logica, logische inferentie en/of toepassingen in de KRR groep. Dit thesisonderwerp is een overzicht van verschillende potentiele thema s en onderwerpen over logica, logische inferentie en/of toepassingen in de KRR-groep. Sommige onderwerpen zijn nieuw, andere vind je al op de webpagina met thesisonderwerpen of zijn varianten ervan. Wie interesse heeft of meer wil weten of zelf een onderwerp wil aanbrengen kan contact opnemen met Prof. Marc Denecker. Interesse in logica.  Logica: revolutie in computerwetenschappen',no_work
'MDA transformaties Jan Wirix Adhemar Bultheel jwirix+everyware.be Jan Wirix For today s companies flexibility and fast time to market are important to survive in a rapidly changing environment.  Information technology has to become an enabler of change.  However, business process automation and development of business support systems  remains costly in terms of time and resources spent with results that are often below expectations.Sometimes companies try to reduce costs by looking for cheap labor.  Another approach with much more potential is to make the software development process more efficient.  In this respect, Model Driven Architecture (MDA) has shown promising results : less complexity, shorter projects, less risk, less costs.  In an MDA context, it becomes possible to generate code from specifications.  Code may be interpreted very broadly, it may be input for a larger framework that accepts the business logic that is expressed in the specifications.Translators from platform independent models to target technical frameworks can bring software development automation to a much higher level; thus eliminating a manual software development for a certain class of problems. Complete the design and development of a translator from MERODE to VERSATA.  Basic work started with a thesis in 2010-2011.  The objective in 2011 is to improve the mechanical generation of a user interface, adapt the behavior of the framework to better support automatic transformations and deliver a working translator.    MERODE is a methodology developed at KUL to describe platform independent enterprise models.  VERSATA is a J2EE framework that generates code from higher level business object inputs.     Description of the transformation  Design of a translator  The student is interested in software engineering and its application in business contexts.Skills in technology independent modelling, XML, JAVA, translation syntaxes are recommended.  http://merode.econ.kuleuven.ac.be/  http://kb1.versata.com/  http://www.versata.com  http://engweb.versata.com/docwiki/index.php/Main_Page   Master thesis ?MDA: een transformatie van MERODE naar VERSATA?.',no_work
'Active learning for efficient annotation to build a spatial corpus Parisa Kordjamshidi Sien Moens Luc DeRaedt Parisa Kordjamshidi Martijn VanOtterlo One of the essential functions of natural language is to talk about spatial relationships between objects. Extraction of spatial information? which we call spatial role labeling, is a key task for applications that are required to answer questions about, or have to reason about, spatial relationships. Examples include systems that perform text-to-scene conversion or inversely generate of textual descriptions from visual data, robots that understand directional or navigational instructions, geographical information systems (GIS) and many others.Machine learning methods were only recently applied for the recognition of spatial information in language. Hence there are no publicly available corpora that are appropriate for training the machine learning models. For the English language the available labeled corpora are sparse, domain dependent and of limited size.As a matter of fact labeling data to be used for machine learning is a very expensive task, so that choosing the most informative examples for training is a challenging problem in many applications. Intelligent selection of the examples by the learner is called active learning. This proposal concerns choosing the best examples in the context of spatial information extraction from natural language and efficiently building a corpus efficiently to perform this task. Different criteria will be considered including diversity and redundancy of the selected examples, and uncertainty of a current classifier trained on the labeled data. Linguistic knowledge can give additional guidance in the selection process. The purpose of this thesis is 1) To gather sparse small existing corpora which are fully or partially labeled with spatial concepts. 2) To unify and extend the gathered corpora via active learning models. 3) Formatting the data according to the data encoding standards. ,  1.Perform a literature study on active learning and spatial information extraction. 2.Implement an active learning setting to choose most informative examples based on the existing corpora. 3.Selective sampling and labeling more data using the final implemented active learning model. 4. Formatting the labeled data according to the data encoding standards. Knowledge or interest in machine learning and natural language processing. Strong programming skills. 1. A literature survey of active machine learning in the context of natural language processing, Fredrik Olsson,Swedish Institute of Computer Science, 2009. 2. Active Learning of Event Detection Patterns, Randolf Altmeyer and Ralph Grishman Department of Computer Science, New York University, 2009. 3. Spatial Role Labeling: Task Definition and Annotation Scheme. In Proceedings LREC 2010, KORDJAMSHIDI, Parisa, VAN OTTERLO, Martijn, MOENS, Marie-Francine.',no_work
